{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c862a332",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T18:00:18.047743Z",
     "iopub.status.busy": "2024-11-14T18:00:18.047334Z",
     "iopub.status.idle": "2024-11-14T18:00:19.134916Z",
     "shell.execute_reply": "2024-11-14T18:00:19.134126Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pranav/.local/lib/python3.10/site-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import albumentations as A\n",
    "# with open(\"/home/pranav/DeepLearning/new.txt\",\"w\") as wr:\n",
    "#     wr.write(\"Completed first cell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f9d1d76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T18:00:19.136699Z",
     "iopub.status.busy": "2024-11-14T18:00:19.136425Z",
     "iopub.status.idle": "2024-11-14T18:00:19.448075Z",
     "shell.execute_reply": "2024-11-14T18:00:19.447433Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import random\n",
    "import albumentations as A\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "# with open(\"/home/pranav/DeepLearning/new.txt\",\"a\") as wr:\n",
    "#     wr.write(\"The second\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a8fa630",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T18:00:19.450680Z",
     "iopub.status.busy": "2024-11-14T18:00:19.450087Z",
     "iopub.status.idle": "2024-11-14T18:00:19.456784Z",
     "shell.execute_reply": "2024-11-14T18:00:19.456312Z"
    }
   },
   "outputs": [],
   "source": [
    "transform = A.Compose([\n",
    "    A.RandomCrop(width=4500, height=3000, p=1.0),\n",
    "    A.HorizontalFlip(p=1.0),\n",
    "    A.VerticalFlip(p=1.0),\n",
    "    A.Rotate(limit=[60, 240], p=1.0, interpolation=cv2.INTER_NEAREST),\n",
    "    A.RandomBrightnessContrast(brightness_limit=[-0.2, 0.4], contrast_limit=0.2, p=1.0),\n",
    "    A.OneOf([\n",
    "        A.CLAHE (clip_limit=2.0, tile_grid_size=(8, 8), p=0.5),\n",
    "        A.GridDistortion(p=0.5),\n",
    "        A.OpticalDistortion(distort_limit=1, shift_limit=0.5, interpolation=cv2.INTER_NEAREST, p=0.5),\n",
    "    ], p=1.0),\n",
    "], p=1.0)\n",
    "# with open(\"/home/pranav/DeepLearning/new.txt\",\"a\") as wr:\n",
    "#     wr.write(\"The third\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a111cc1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T18:00:19.458557Z",
     "iopub.status.busy": "2024-11-14T18:00:19.458293Z",
     "iopub.status.idle": "2024-11-14T18:00:19.463951Z",
     "shell.execute_reply": "2024-11-14T18:00:19.463514Z"
    }
   },
   "outputs": [],
   "source": [
    "def visualize(image, mask, original_image=None, original_mask=None):\n",
    "    fontsize = 16\n",
    "\n",
    "    if original_image is None and original_mask is None:\n",
    "        f, ax = plt.subplots(2, 1, figsize=(16, 16), squeeze=True)\n",
    "        f.set_tight_layout(h_pad=5, w_pad=5)\n",
    "\n",
    "        ax[0].imshow(image)\n",
    "        ax[1].imshow(mask)\n",
    "    else:\n",
    "        f, ax = plt.subplots(2, 2, figsize=(16, 16), squeeze=True)\n",
    "        plt.tight_layout(pad=0.2, w_pad=1.0, h_pad=0.01)\n",
    "\n",
    "        ax[0, 0].imshow(original_image)\n",
    "        ax[0, 0].set_title('Original Image', fontsize=fontsize)\n",
    "\n",
    "        ax[1, 0].imshow(original_mask)\n",
    "        ax[1, 0].set_title('Original Mask', fontsize=fontsize)\n",
    "\n",
    "        ax[0, 1].imshow(image)\n",
    "        ax[0, 1].set_title('Transformed Image', fontsize=fontsize)\n",
    "\n",
    "        ax[1, 1].imshow(mask)\n",
    "        ax[1, 1].set_title('Transformed Mask', fontsize=fontsize)\n",
    "        \n",
    "    plt.savefig('sample_augmented_image.png', facecolor= 'w', transparent= False, bbox_inches= 'tight', dpi= 100)\n",
    "# with open(\"/home/pranav/DeepLearning/new.txt\",\"a\") as wr:\n",
    "#     wr.write(\"The fourth\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d29385de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T18:00:19.465585Z",
     "iopub.status.busy": "2024-11-14T18:00:19.465357Z",
     "iopub.status.idle": "2024-11-14T18:00:19.468354Z",
     "shell.execute_reply": "2024-11-14T18:00:19.467939Z"
    }
   },
   "outputs": [],
   "source": [
    "# image = cv2.imread(\"/home/pranav/DeepLearning/semantic_drone_dataset/training_set/images/040.jpg\")\n",
    "# image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "# mask = cv2.imread(\"/home/pranav/DeepLearning/semantic_drone_dataset/training_set/gt/semantic/label_images/040.png\")\n",
    "# mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB\n",
    "#                    )\n",
    "\n",
    "# transformed = transform(image=image, mask=mask)\n",
    "# transformed_image = transformed['image']\n",
    "# transformed_mask = transformed['mask']\n",
    "\n",
    "# cv2.imwrite('./image.png',cv2.cvtColor(transformed_image, cv2.COLOR_BGR2RGB))\n",
    "# cv2.imwrite('./mask.png',cv2.cvtColor(transformed_mask, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "# visualize(transformed_image, transformed_mask, image, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1164e557",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T18:00:19.470011Z",
     "iopub.status.busy": "2024-11-14T18:00:19.469759Z",
     "iopub.status.idle": "2024-11-14T18:00:19.472618Z",
     "shell.execute_reply": "2024-11-14T18:00:19.472193Z"
    }
   },
   "outputs": [],
   "source": [
    "images_dir = '/home/pranav/DeepLearning/train_images'\n",
    "masks_dir = '/home/pranav/DeepLearning/train_masks'\n",
    "# val_images = 'C:/Users/prana/Deep Learning - Segmentation/val_train_images'\n",
    "# masksval = \"C:/Users/prana/Deep Learning - Segmentation/masksvalimages\"\n",
    "# with open(\"/home/pranav/DeepLearning/new.txt\",\"a\") as wr:\n",
    "#     wr.write(\"The third\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8325568",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T18:00:19.474182Z",
     "iopub.status.busy": "2024-11-14T18:00:19.474035Z",
     "iopub.status.idle": "2024-11-14T18:00:19.476594Z",
     "shell.execute_reply": "2024-11-14T18:00:19.476169Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f54275a4-181a-4c95-8525-b3626e679e07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T18:00:19.478268Z",
     "iopub.status.busy": "2024-11-14T18:00:19.478011Z",
     "iopub.status.idle": "2024-11-14T18:00:19.483384Z",
     "shell.execute_reply": "2024-11-14T18:00:19.482950Z"
    }
   },
   "outputs": [],
   "source": [
    "file_names = np.sort(os.listdir(\"/home/pranav/DeepLearning/semantic_drone_dataset/training_set/images\")) \n",
    "file_names = np.char.split(file_names, '.')\n",
    "filenames = np.array([])\n",
    "for i in range(len(file_names)):\n",
    "    filenames = np.append(filenames, file_names[i][0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77a3be44-b1d6-416b-bd47-0f1f20889777",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T18:00:19.484961Z",
     "iopub.status.busy": "2024-11-14T18:00:19.484810Z",
     "iopub.status.idle": "2024-11-14T18:00:19.490532Z",
     "shell.execute_reply": "2024-11-14T18:00:19.490083Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000' '001' '002' '003' '004' '005' '006' '008' '011' '013' '014' '015'\n",
      " '016' '018' '019' '021' '022' '023' '026' '028' '031' '035' '038' '040'\n",
      " '041' '042' '043' '044' '045' '047' '049' '051' '052' '053' '055' '056'\n",
      " '057' '058' '059' '060' '062' '063' '065' '068' '070' '071' '073' '074'\n",
      " '075' '077' '078' '079' '080' '081' '083' '086' '088' '089' '092' '095'\n",
      " '098' '099' '100' '101' '102' '103' '104' '106' '107' '109' '110' '111'\n",
      " '112' '113' '116' '117' '118' '119' '120' '121' '122' '123' '124' '126'\n",
      " '128' '130' '133' '134' '135' '136' '137' '138' '139' '140' '141' '145'\n",
      " '146' '147' '148' '149' '150' '153' '154' '155' '156' '157' '158' '159'\n",
      " '160' '161' '162' '163' '164' '165' '166' '167' '170' '171' '172' '173'\n",
      " '174' '175' '176' '177' '178' '179' '180' '181' '182' '185' '186' '188'\n",
      " '190' '192' '193' '194' '195' '198' '199' '200' '202' '204' '206' '207'\n",
      " '208' '209' '213' '214' '215' '216' '217' '219' '220' '221' '222' '223'\n",
      " '225' '226' '228' '229' '230' '232' '233' '234' '235' '236' '237' '238'\n",
      " '239' '240' '243' '244' '246' '248' '250' '251' '252' '255' '257' '258'\n",
      " '259' '260' '261' '262' '263' '265' '266' '271' '272' '273' '275' '276'\n",
      " '277' '281' '283' '287' '288' '289' '290' '292' '294' '295' '296' '298'\n",
      " '299' '301' '302' '303' '304' '305' '306' '309' '310' '311' '312' '313'\n",
      " '314' '316' '318' '320' '321' '322' '323' '324' '325' '326' '329' '330'\n",
      " '331' '332' '334' '335' '338' '339' '341' '342' '344' '345' '346' '347'\n",
      " '348' '349' '351' '355' '356' '361' '363' '366' '367' '372' '373' '375'\n",
      " '376' '378' '380' '381' '382' '383' '385' '386' '388' '389' '390' '391'\n",
      " '393' '397' '398' '403' '406' '408' '409' '410' '411' '412' '413' '414'\n",
      " '416' '419' '420' '421' '423' '424' '425' '426' '427' '428' '429' '430'\n",
      " '431' '433' '434' '435' '437' '438' '439' '440' '442' '443' '444' '445'\n",
      " '446' '447' '451' '452' '454' '455' '457' '458' '460' '461' '462' '463'\n",
      " '464' '465' '467' '470' '472' '473' '474' '475' '476' '478' '479' '480'\n",
      " '484' '485' '488' '489' '491' '493' '494' '497' '498' '499' '500' '501'\n",
      " '502' '507' '508' '509' '510' '512' '513' '514' '515' '517' '518' '521'\n",
      " '524' '525' '526' '529' '530' '531' '532' '533' '535' '536' '537' '538'\n",
      " '540' '543' '544' '545' '549' '551' '554' '556' '558' '559' '560' '561'\n",
      " '563' '564' '565' '566' '567' '568' '569' '570' '572' '573' '574' '576'\n",
      " '579' '580' '582' '583' '584' '585' '586' '587' '588' '590' '591' '592'\n",
      " '593' '594' '596' '598']\n",
      "000\n",
      "001\n",
      "002\n",
      "003\n",
      "004\n",
      "005\n",
      "006\n",
      "008\n",
      "011\n",
      "013\n",
      "014\n",
      "015\n",
      "016\n",
      "018\n",
      "019\n",
      "021\n",
      "022\n",
      "023\n",
      "026\n",
      "028\n",
      "031\n",
      "035\n",
      "038\n",
      "040\n",
      "041\n",
      "042\n",
      "043\n",
      "044\n",
      "045\n",
      "047\n",
      "049\n",
      "051\n",
      "052\n",
      "053\n",
      "055\n",
      "056\n",
      "057\n",
      "058\n",
      "059\n",
      "060\n",
      "062\n",
      "063\n",
      "065\n",
      "068\n",
      "070\n",
      "071\n",
      "073\n",
      "074\n",
      "075\n",
      "077\n",
      "078\n",
      "079\n",
      "080\n",
      "081\n",
      "083\n",
      "086\n",
      "088\n",
      "089\n",
      "092\n",
      "095\n",
      "098\n",
      "099\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "106\n",
      "107\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "126\n",
      "128\n",
      "130\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "185\n",
      "186\n",
      "188\n",
      "190\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "198\n",
      "199\n",
      "200\n",
      "202\n",
      "204\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "225\n",
      "226\n",
      "228\n",
      "229\n",
      "230\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "243\n",
      "244\n",
      "246\n",
      "248\n",
      "250\n",
      "251\n",
      "252\n",
      "255\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "265\n",
      "266\n",
      "271\n",
      "272\n",
      "273\n",
      "275\n",
      "276\n",
      "277\n",
      "281\n",
      "283\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "292\n",
      "294\n",
      "295\n",
      "296\n",
      "298\n",
      "299\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "316\n",
      "318\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "334\n",
      "335\n",
      "338\n",
      "339\n",
      "341\n",
      "342\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "351\n",
      "355\n",
      "356\n",
      "361\n",
      "363\n",
      "366\n",
      "367\n",
      "372\n",
      "373\n",
      "375\n",
      "376\n",
      "378\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "385\n",
      "386\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "393\n",
      "397\n",
      "398\n",
      "403\n",
      "406\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "416\n",
      "419\n",
      "420\n",
      "421\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "433\n",
      "434\n",
      "435\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "451\n",
      "452\n",
      "454\n",
      "455\n",
      "457\n",
      "458\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "467\n",
      "470\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "478\n",
      "479\n",
      "480\n",
      "484\n",
      "485\n",
      "488\n",
      "489\n",
      "491\n",
      "493\n",
      "494\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "517\n",
      "518\n",
      "521\n",
      "524\n",
      "525\n",
      "526\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "540\n",
      "543\n",
      "544\n",
      "545\n",
      "549\n",
      "551\n",
      "554\n",
      "556\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "572\n",
      "573\n",
      "574\n",
      "576\n",
      "579\n",
      "580\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "596\n",
      "598\n"
     ]
    }
   ],
   "source": [
    "print(filenames)\n",
    "for file in filenames:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4f76120",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T18:00:19.492252Z",
     "iopub.status.busy": "2024-11-14T18:00:19.492000Z",
     "iopub.status.idle": "2024-11-14T18:00:19.496286Z",
     "shell.execute_reply": "2024-11-14T18:00:19.495850Z"
    }
   },
   "outputs": [],
   "source": [
    "def augment_dataset(count):\n",
    "    '''Function for data augmentation\n",
    "        Input:\n",
    "            count - total no. of images after augmentation = initial no. of images * count\n",
    "        Output:\n",
    "            writes augmented images (input images & segmentation masks) to the working directory\n",
    "    '''\n",
    "    i = 0\n",
    "    for i in range(count):\n",
    "        for file in filenames:\n",
    "            img = cv2.imread(\"/home/pranav/DeepLearning/semantic_drone_dataset/training_set/images/\"+file+'.jpg')\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            mask = cv2.imread(\"/home/pranav/DeepLearning/semantic_drone_dataset/training_set/gt/semantic/label_images/\"+file+'.png')\n",
    "            mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
    "            transformed = transform(image=img, mask=mask)\n",
    "            transformed_image = transformed['image']\n",
    "            transformed_mask = transformed['mask']\n",
    "\n",
    "            cv2.imwrite('/home/pranav/DeepLearning/train_images/aug_images/aug_{}_'.format(str(i+1))+file+'.jpg',cv2.cvtColor(transformed_image, cv2.COLOR_BGR2RGB))\n",
    "            cv2.imwrite('/home/pranav/DeepLearning/train_masks/aug_masks/aug_{}_'.format(str(i+1))+file+'.png',cv2.cvtColor(transformed_mask, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10e91429",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T18:00:19.497907Z",
     "iopub.status.busy": "2024-11-14T18:00:19.497760Z",
     "iopub.status.idle": "2024-11-14T18:00:19.499754Z",
     "shell.execute_reply": "2024-11-14T18:00:19.499332Z"
    }
   },
   "outputs": [],
   "source": [
    "# !mkdir aug_images\n",
    "# !mkdir aug_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e748a763",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T18:00:19.501356Z",
     "iopub.status.busy": "2024-11-14T18:00:19.501138Z",
     "iopub.status.idle": "2024-11-14T18:00:19.503516Z",
     "shell.execute_reply": "2024-11-14T18:00:19.503036Z"
    }
   },
   "outputs": [],
   "source": [
    "#augment_dataset(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75a903c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T18:00:19.505130Z",
     "iopub.status.busy": "2024-11-14T18:00:19.504990Z",
     "iopub.status.idle": "2024-11-14T18:00:19.506978Z",
     "shell.execute_reply": "2024-11-14T18:00:19.506551Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install keract\n",
    "# import keract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46922be1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T18:00:19.508582Z",
     "iopub.status.busy": "2024-11-14T18:00:19.508439Z",
     "iopub.status.idle": "2024-11-14T18:00:21.409769Z",
     "shell.execute_reply": "2024-11-14T18:00:21.409214Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 23:30:19.836351: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1731607219.855608 4106011 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1731607219.861365 4106011 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-14 23:30:19.882442: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import keract\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85e0ce88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T18:00:21.411979Z",
     "iopub.status.busy": "2024-11-14T18:00:21.411572Z",
     "iopub.status.idle": "2024-11-14T18:00:21.424603Z",
     "shell.execute_reply": "2024-11-14T18:00:21.424090Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from IPython.display import SVG\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os, re, sys, random, shutil, cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import applications, optimizers\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.utils import model_to_dot, plot_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, CSVLogger, LearningRateScheduler, TensorBoard\n",
    "from tensorflow.keras.layers import Input, Lambda, Activation, Conv2D, MaxPooling2D, BatchNormalization, Add, concatenate, Conv2DTranspose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb4900b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T18:00:21.426626Z",
     "iopub.status.busy": "2024-11-14T18:00:21.426393Z",
     "iopub.status.idle": "2024-11-14T18:00:21.429295Z",
     "shell.execute_reply": "2024-11-14T18:00:21.428846Z"
    }
   },
   "outputs": [],
   "source": [
    "train_images = '/home/pranav/DeepLearning/train_images'\n",
    "train_masks = '/home/pranav/DeepLearning/train_masks'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c39ce3b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T18:00:21.430905Z",
     "iopub.status.busy": "2024-11-14T18:00:21.430651Z",
     "iopub.status.idle": "2024-11-14T18:00:21.436530Z",
     "shell.execute_reply": "2024-11-14T18:00:21.436062Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aug_1_000' 'aug_1_001' 'aug_1_002' 'aug_1_003' 'aug_1_004']\n"
     ]
    }
   ],
   "source": [
    "file_names = np.sort(os.listdir(train_images+\"/aug_images\")) \n",
    "file_names = np.char.split(file_names, '.')\n",
    "filenames = np.array([])\n",
    "for i in range(len(file_names[:5])):\n",
    "    filenames = np.append(filenames, file_names[i][0])\n",
    "print(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc4c7053",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T18:00:21.438209Z",
     "iopub.status.busy": "2024-11-14T18:00:21.438055Z",
     "iopub.status.idle": "2024-11-14T18:00:21.440608Z",
     "shell.execute_reply": "2024-11-14T18:00:21.440176Z"
    }
   },
   "outputs": [],
   "source": [
    "# def show_data(files, original_images_dir, label_images_dir):\n",
    "\n",
    "#     for file in files:\n",
    "#         fig, axs = plt.subplots(1, 2, figsize=(20, 10), constrained_layout=True)\n",
    "\n",
    "#         axs[0].imshow(Image.open(original_images_dir+\"/aug_images/\"+str(file)+'.jpg'))\n",
    "#         axs[0].set_title('Original Image', fontdict = {'fontsize':20})\n",
    "#         axs[0].set_xticks(np.arange(0, 6500, 1000))\n",
    "#         axs[0].set_yticks(np.arange(0, 4500, 1000))\n",
    "#         axs[0].grid(False)\n",
    "#         axs[0].axis(True)\n",
    "\n",
    "#         semantic_label_image = Image.open(label_images_dir+\"/aug_masks/\"+str(file)+'.png')\n",
    "#         semantic_label_image = np.asarray(semantic_label_image)\n",
    "#         axs[1].imshow(semantic_label_image)\n",
    "#         axs[1].set_title('Semantic Segmentation Mask', fontdict = {'fontsize':20})\n",
    "#         axs[1].set_xticks(np.arange(0, 6500, 1000))\n",
    "#         axs[1].set_yticks(np.arange(0, 4500, 1000))\n",
    "#         axs[1].grid(False)\n",
    "#         axs[1].axis(True)\n",
    "\n",
    "#         plt.savefig('image_'+file, facecolor= 'w', transparent= False, bbox_inches= 'tight', dpi= 100)\n",
    "#         plt.show()\n",
    "    \n",
    "# show_data(filenames[:5], train_images, train_masks)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "77b01405",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T18:00:21.442223Z",
     "iopub.status.busy": "2024-11-14T18:00:21.442076Z",
     "iopub.status.idle": "2024-11-14T18:00:21.450699Z",
     "shell.execute_reply": "2024-11-14T18:00:21.450224Z"
    }
   },
   "outputs": [],
   "source": [
    "augmented_files = ['092','118', '228', '277', '376']\n",
    "\n",
    "def show_augmented_images(files, original_images_dir):\n",
    "    for file in files:\n",
    "        fig, axs = plt.subplots(1, 5, figsize=(30, 6), constrained_layout=True)\n",
    "        for i in range(5):\n",
    "            if i == 0:\n",
    "                axs[i].imshow(Image.open(original_images_dir+str(file)+'.jpg'))\n",
    "                axs[i].set_title('Original Image: {}.jpg'.format(file), fontdict = {'fontsize':20})\n",
    "                axs[i].set_xticks(np.arange(0, 6500, 1000))\n",
    "                axs[i].set_yticks(np.arange(0, 4500, 1000))\n",
    "                axs[i].grid(False)\n",
    "                axs[i].axis(True)\n",
    "            else:\n",
    "                axs[i].imshow(Image.open(\"C:/Users/prana/Deep Learning - Segmentation/aug_images/\"+'aug_'+str(i)+'_'+str(file)+'.jpg'))\n",
    "                axs[i].set_title('Augmented Image: aug_'+str(i)+'_'+str(file)+'.jpg', fontdict = {'fontsize':20})\n",
    "                axs[i].set_xticks(np.arange(0, 4500, 1000))\n",
    "                axs[i].set_yticks(np.arange(0, 3001, 1000))\n",
    "                axs[i].grid(False)\n",
    "                axs[i].axis(True)\n",
    "\n",
    "        plt.savefig('aug_image_'+file, facecolor= 'w', transparent= False, bbox_inches= 'tight', dpi= 100)\n",
    "        plt.show()\n",
    "    \n",
    "def show_augmented_masks(files, label_images_dir):\n",
    "    for file in files:\n",
    "        fig, axs = plt.subplots(1, 5, figsize=(30, 6), constrained_layout=True)\n",
    "        for i in range(5):\n",
    "            if i == 0:\n",
    "                axs[i].imshow(Image.open(label_images_dir+str(file)+'.png'))\n",
    "                axs[i].set_title('Original Mask: {}.png'.format(file), fontdict = {'fontsize':20})\n",
    "                axs[i].set_xticks(np.arange(0, 6500, 1000))\n",
    "                axs[i].set_yticks(np.arange(0, 4500, 1000))\n",
    "                axs[i].grid(False)\n",
    "                axs[i].axis(True)\n",
    "            else:\n",
    "                axs[i].imshow(Image.open(\"C:/Users/prana/Deep Learning - Segmentation/aug_masks/\"+\"aug_\"+str(i)+'_'+str(file)+'.png'))\n",
    "                axs[i].set_title('Augmented Mask: aug_'+str(i)+'_'+str(file)+'.png', fontdict = {'fontsize':20})\n",
    "                axs[i].set_xticks(np.arange(0, 4500, 1000))\n",
    "                axs[i].set_yticks(np.arange(0, 3001, 1000))\n",
    "                axs[i].grid(False)\n",
    "                axs[i].axis(True)\n",
    "\n",
    "        plt.savefig('aug_mask_'+file, facecolor= 'w', transparent= False, bbox_inches= 'tight', dpi= 100)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8150d615",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T18:00:21.452530Z",
     "iopub.status.busy": "2024-11-14T18:00:21.452237Z",
     "iopub.status.idle": "2024-11-14T18:00:21.454661Z",
     "shell.execute_reply": "2024-11-14T18:00:21.454230Z"
    }
   },
   "outputs": [],
   "source": [
    "# show_augmented_images(augmented_files, train_images)\n",
    "# show_augmented_masks(augmented_files, train_masks)\n",
    "# print(train_images)\n",
    "# print(train_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8eac3e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T18:00:21.456339Z",
     "iopub.status.busy": "2024-11-14T18:00:21.456087Z",
     "iopub.status.idle": "2024-11-14T18:00:21.462959Z",
     "shell.execute_reply": "2024-11-14T18:00:21.462506Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       unlabeled\n",
      "1      paved-area\n",
      "2            dirt\n",
      "3           grass\n",
      "4          gravel\n",
      "5           water\n",
      "6           rocks\n",
      "7            pool\n",
      "8      vegetation\n",
      "9            roof\n",
      "10           wall\n",
      "11         window\n",
      "12           door\n",
      "13          fence\n",
      "14     fence-pole\n",
      "15         person\n",
      "16            dog\n",
      "17            car\n",
      "18        bicycle\n",
      "19           tree\n",
      "20      bald-tree\n",
      "21      ar-marker\n",
      "22       obstacle\n",
      "23    conflicting\n",
      "Name: name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "class_dict_df = pd.read_csv(\"/home/pranav/DeepLearning/semantic_drone_dataset/training_set/gt/semantic/class_dict.csv\", index_col=False, skipinitialspace=True)\n",
    "print(class_dict_df[\"name\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6244d9b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T18:00:21.464684Z",
     "iopub.status.busy": "2024-11-14T18:00:21.464455Z",
     "iopub.status.idle": "2024-11-14T18:00:21.470536Z",
     "shell.execute_reply": "2024-11-14T18:00:21.470058Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(np.int64(0), np.int64(0), np.int64(0)),\n",
       "  (np.int64(128), np.int64(64), np.int64(128)),\n",
       "  (np.int64(130), np.int64(76), np.int64(0)),\n",
       "  (np.int64(0), np.int64(102), np.int64(0)),\n",
       "  (np.int64(112), np.int64(103), np.int64(87))],\n",
       " ['unlabeled', 'paved-area', 'dirt', 'grass', 'gravel'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_names= list(class_dict_df.name)\n",
    "label_codes = []\n",
    "r= np.asarray(class_dict_df.r)\n",
    "g= np.asarray(class_dict_df.g)\n",
    "b= np.asarray(class_dict_df.b)\n",
    "\n",
    "for i in range(len(class_dict_df)):\n",
    "    label_codes.append(tuple([r[i], g[i], b[i]]))\n",
    "    \n",
    "label_codes[:5], label_names[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9dec177c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T18:00:21.472235Z",
     "iopub.status.busy": "2024-11-14T18:00:21.471972Z",
     "iopub.status.idle": "2024-11-14T18:00:21.476676Z",
     "shell.execute_reply": "2024-11-14T18:00:21.476159Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(np.int64(0), np.int64(0), np.int64(0)),\n",
       "  (np.int64(128), np.int64(64), np.int64(128)),\n",
       "  (np.int64(130), np.int64(76), np.int64(0)),\n",
       "  (np.int64(0), np.int64(102), np.int64(0)),\n",
       "  (np.int64(112), np.int64(103), np.int64(87)),\n",
       "  (np.int64(28), np.int64(42), np.int64(168)),\n",
       "  (np.int64(48), np.int64(41), np.int64(30)),\n",
       "  (np.int64(0), np.int64(50), np.int64(89)),\n",
       "  (np.int64(107), np.int64(142), np.int64(35)),\n",
       "  (np.int64(70), np.int64(70), np.int64(70)),\n",
       "  (np.int64(102), np.int64(102), np.int64(156)),\n",
       "  (np.int64(254), np.int64(228), np.int64(12)),\n",
       "  (np.int64(254), np.int64(148), np.int64(12)),\n",
       "  (np.int64(190), np.int64(153), np.int64(153)),\n",
       "  (np.int64(153), np.int64(153), np.int64(153)),\n",
       "  (np.int64(255), np.int64(22), np.int64(96)),\n",
       "  (np.int64(102), np.int64(51), np.int64(0)),\n",
       "  (np.int64(9), np.int64(143), np.int64(150)),\n",
       "  (np.int64(119), np.int64(11), np.int64(32)),\n",
       "  (np.int64(51), np.int64(51), np.int64(0)),\n",
       "  (np.int64(190), np.int64(250), np.int64(190)),\n",
       "  (np.int64(112), np.int64(150), np.int64(146)),\n",
       "  (np.int64(2), np.int64(135), np.int64(115)),\n",
       "  (np.int64(255), np.int64(0), np.int64(0))],\n",
       " ['unlabeled',\n",
       "  'paved-area',\n",
       "  'dirt',\n",
       "  'grass',\n",
       "  'gravel',\n",
       "  'water',\n",
       "  'rocks',\n",
       "  'pool',\n",
       "  'vegetation',\n",
       "  'roof',\n",
       "  'wall',\n",
       "  'window',\n",
       "  'door',\n",
       "  'fence',\n",
       "  'fence-pole',\n",
       "  'person',\n",
       "  'dog',\n",
       "  'car',\n",
       "  'bicycle',\n",
       "  'tree',\n",
       "  'bald-tree',\n",
       "  'ar-marker',\n",
       "  'obstacle',\n",
       "  'conflicting'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_codes, label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "550fd76a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T18:00:21.478386Z",
     "iopub.status.busy": "2024-11-14T18:00:21.478125Z",
     "iopub.status.idle": "2024-11-14T18:00:21.481104Z",
     "shell.execute_reply": "2024-11-14T18:00:21.480665Z"
    }
   },
   "outputs": [],
   "source": [
    "code2id = {v:k for k,v in enumerate(label_codes)}\n",
    "id2code = {k:v for k,v in enumerate(label_codes)}\n",
    "\n",
    "name2id = {v:k for k,v in enumerate(label_names)}\n",
    "id2name = {k:v for k,v in enumerate(label_names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e692a82b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T18:00:21.482812Z",
     "iopub.status.busy": "2024-11-14T18:00:21.482557Z",
     "iopub.status.idle": "2024-11-14T18:00:21.486821Z",
     "shell.execute_reply": "2024-11-14T18:00:21.486378Z"
    }
   },
   "outputs": [],
   "source": [
    "def rgb_to_onehot(rgb_image, colormap = id2code):\n",
    "    '''Function to one hot encode RGB mask labels\n",
    "        Inputs: \n",
    "            rgb_image - image matrix (eg. 256 x 256 x 3 dimension numpy ndarray)\n",
    "            colormap - dictionary of color to label id\n",
    "        Output: One hot encoded image of dimensions (height x width x num_classes) where num_classes = len(colormap)\n",
    "    '''\n",
    "    num_classes = len(colormap)\n",
    "    shape = rgb_image.shape[:2]+(num_classes,)\n",
    "    encoded_image = np.zeros( shape, dtype=np.int8 )\n",
    "    for i, cls in enumerate(colormap):\n",
    "        encoded_image[:,:,i] = np.all(rgb_image.reshape( (-1,3) ) == colormap[i], axis=1).reshape(shape[:2])\n",
    "    return encoded_image\n",
    "\n",
    "\n",
    "def onehot_to_rgb(onehot, colormap = id2code):\n",
    "    '''Function to decode encoded mask labels\n",
    "        Inputs: \n",
    "            onehot - one hot encoded image matrix (height x width x num_classes)\n",
    "            colormap - dictionary of color to label id\n",
    "        Output: Decoded RGB image (height x width x 3) \n",
    "    '''\n",
    "    single_layer = np.argmax(onehot, axis=-1)\n",
    "    output = np.zeros( onehot.shape[:2]+(3,) )\n",
    "    for k in colormap.keys():\n",
    "        output[single_layer==k] = colormap[k]\n",
    "    return np.uint8(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2201c24f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T18:00:21.488423Z",
     "iopub.status.busy": "2024-11-14T18:00:21.488274Z",
     "iopub.status.idle": "2024-11-14T18:00:21.491035Z",
     "shell.execute_reply": "2024-11-14T18:00:21.490592Z"
    }
   },
   "outputs": [],
   "source": [
    "# Normalizing only frame images, since masks contain label info\n",
    "data_gen_args = dict(rescale=1./255)\n",
    "mask_gen_args = dict()\n",
    "\n",
    "train_frames_datagen = ImageDataGenerator(**data_gen_args)\n",
    "train_masks_datagen = ImageDataGenerator(**mask_gen_args)\n",
    "val_frames_datagen = ImageDataGenerator(**data_gen_args)\n",
    "val_masks_datagen = ImageDataGenerator(**mask_gen_args)\n",
    "# Seed defined for aligning images and their masks\n",
    "seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2e7a8657",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T18:00:21.492664Z",
     "iopub.status.busy": "2024-11-14T18:00:21.492440Z",
     "iopub.status.idle": "2024-11-14T18:00:21.498752Z",
     "shell.execute_reply": "2024-11-14T18:00:21.498290Z"
    }
   },
   "outputs": [],
   "source": [
    "def TrainAugmentGenerator(train_images_dir, train_masks_dir, seed = 1, batch_sizess = 8, target_sizess = (512, 512)):\n",
    "    '''Train Image data generator\n",
    "        Inputs: \n",
    "            seed - seed provided to the flow_from_directory function to ensure aligned data flow\n",
    "            batch_size - number of images to import at a time\n",
    "            train_images_dir - train images directory\n",
    "            train_masks_dir - train masks directory\n",
    "            target_size - tuple of integers (height, width)\n",
    "            \n",
    "        Output: Decoded RGB image (height x width x 3) \n",
    "    '''\n",
    "    train_image_generator = train_frames_datagen.flow_from_directory(\n",
    "   train_images_dir,\n",
    "    batch_size= batch_sizess, \n",
    "    seed = seed, \n",
    "    target_size = target_sizess)\n",
    "\n",
    "    train_mask_generator = train_masks_datagen.flow_from_directory(\n",
    "    train_masks_dir,\n",
    "    batch_size = batch_sizess, \n",
    "    seed = seed, \n",
    "    target_size = target_sizess)\n",
    "\n",
    "    while True:\n",
    "        X1i = next(train_image_generator)\n",
    "        X2i = next(train_mask_generator)\n",
    "        \n",
    "        #One hot encoding RGB images\n",
    "        mask_encoded = [rgb_to_onehot(X2i[0][x,:,:,:], id2code) for x in range(X2i[0].shape[0])]\n",
    "        if(X1i[0] is None or mask_encoded is None):\n",
    "            print(\"I am sending Null object to you\")\n",
    "        yield X1i[0], np.asarray(mask_encoded)\n",
    "\n",
    "def ValAugmentGenerator(val_images_dr, masksvaldr, seed = 1, batch_sizess = 8, target_sizess = (512, 512)):\n",
    "    '''Train Image data generator\n",
    "        Inputs: \n",
    "            seed - seed provided to the flow_from_directory function to ensure aligned data flow\n",
    "            batch_size - number of images to import at a time\n",
    "            train_images_dir - train images directory\n",
    "            train_masks_dir - train masks directory\n",
    "            target_size - tuple of integers (height, width)\n",
    "            \n",
    "        Output: Decoded RGB image (height x width x 3) \n",
    "    '''\n",
    "    val_image_generator = val_frames_datagen.flow_from_directory(\n",
    "   val_images_dr,\n",
    "    batch_size= batch_sizess, \n",
    "    seed = seed, \n",
    "    target_size = target_sizess)\n",
    "\n",
    "    val_mask_generator = val_masks_datagen.flow_from_directory(\n",
    "    masksvaldr,\n",
    "    batch_size = batch_sizess, \n",
    "    seed = seed, \n",
    "    target_size = target_sizess)\n",
    "\n",
    "    while True:\n",
    "        X1i = next(val_image_generator)\n",
    "        X2i = next(val_mask_generator)\n",
    "        \n",
    "        #One hot encoding RGB images\n",
    "        mask_encoded = [rgb_to_onehot(X2i[0][x,:,:,:], id2code) for x in range(X2i[0].shape[0])]\n",
    "        if(X1i[0] is None or mask_encoded is None):\n",
    "            print(\"I am sending Null object to you\")\n",
    "        yield X1i[0], np.asarray(mask_encoded)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "80e04025",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T18:00:21.500413Z",
     "iopub.status.busy": "2024-11-14T18:00:21.500263Z",
     "iopub.status.idle": "2024-11-14T18:00:21.502360Z",
     "shell.execute_reply": "2024-11-14T18:00:21.501919Z"
    }
   },
   "outputs": [],
   "source": [
    "# !mkdir pretrained_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f4effbf4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T18:00:21.504100Z",
     "iopub.status.busy": "2024-11-14T18:00:21.503762Z",
     "iopub.status.idle": "2024-11-14T18:00:21.509286Z",
     "shell.execute_reply": "2024-11-14T18:00:21.508835Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps_per_epoch:  1.0\n",
      "/home/pranav/DeepLearning/train_images\n",
      "/home/pranav/DeepLearning/train_masks\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "batch_size = 8\n",
    "num_train_samples = len(np.sort(os.listdir(train_images)))\n",
    "steps_per_epoch = np.ceil(float(num_train_samples) / float(batch_size))\n",
    "print('steps_per_epoch: ', steps_per_epoch)\n",
    "print(train_images)\n",
    "print(train_masks)\n",
    "with open(\"/home/pranav/DeepLearning/new.txt\",\"a\") as wr:\n",
    "    wr.write(\"The sixth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a10b8670-a352-4db7-8844-cdc15416f40f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T18:00:21.511004Z",
     "iopub.status.busy": "2024-11-14T18:00:21.510778Z",
     "iopub.status.idle": "2024-11-14T18:00:21.513132Z",
     "shell.execute_reply": "2024-11-14T18:00:21.512695Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e5d57208",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T18:00:21.514920Z",
     "iopub.status.busy": "2024-11-14T18:00:21.514747Z",
     "iopub.status.idle": "2024-11-14T18:00:21.533424Z",
     "shell.execute_reply": "2024-11-14T18:00:21.532881Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPooling2D\n",
    "from tensorflow.keras.layers import Conv2DTranspose, concatenate, DepthwiseConv2D, Add\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# def dice_score(y_true, y_pred, smooth=1e-6):\n",
    "#     # Convert y_pred from probabilities to class predictions\n",
    "#      tf.print(y_true_f.shape)\n",
    "#     tf.print(y_pred_f.shape)\n",
    "#     y_pred_classes = tf.argmax(y_pred, axis=-1)\n",
    "\n",
    "#     # Convert y_true to the same type and shape as y_pred_classes\n",
    "#     y_true = tf.cast(y_true, tf.int64)\n",
    "#     print(y_true)\n",
    "#     print(y_pred_classes)\n",
    "#     # Ensure both y_true and y_pred_classes have the same shape (flatten them)\n",
    "#     y_true_f = tf.reshape(y_true, [-1])\n",
    "#     y_pred_f = tf.reshape(y_pred_classes, [-1])\n",
    "\n",
    "#     # Calculate the Dice score\n",
    "#     intersection = tf.reduce_sum(tf.cast(y_true_f == y_pred_f, tf.float32))\n",
    "#     dice = (2. * intersection + smooth) / (tf.reduce_sum(tf.cast(y_true_f != -1, tf.float32)) + \n",
    "#                                             tf.reduce_sum(tf.cast(y_pred_f != -1, tf.float32)) + smooth)\n",
    "#     print(y_true_f.shape)\n",
    "#     print(y_pred_f.shape)\n",
    "#     return dice\n",
    "# def simplemetric(y_true, y_pred):\n",
    "#     return tf.constant(0.5)  \n",
    "def dice_coef(y_true, y_pred):\n",
    "    return (2. * K.sum(y_true * y_pred) + 1.) / (K.sum(y_true) + K.sum(y_pred) + 1.)\n",
    "\n",
    "# class SimpleMetric(tf.keras.metrics.Metric):\n",
    "#     def __init__(self, name='simple_constant_metric', **kwargs):\n",
    "#         super(SimpleConstantMetric, self).__init__(name=name, **kwargs)\n",
    "#         self.value = self.add_weight(name=\"value\", initializer=\"zeros\")\n",
    "\n",
    "#     def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "#         # Update state with the constant value (0.5)\n",
    "#         self.value.assign(0.5)\n",
    "\n",
    "#     def result(self):\n",
    "#         # Return the current value of the metric\n",
    "#         return self.value\n",
    "\n",
    "#     def reset_states(self):\n",
    "#         # Reset metric state\n",
    "#         self.value.assign(0.0)\n",
    "class DiceCoefficient(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='dice_coefficient', smooth=1e-6, **kwargs):\n",
    "        super(DiceCoefficient, self).__init__(name=name, **kwargs)\n",
    "        self.smooth = smooth\n",
    "        self.intersection = self.add_weight(name='intersection', initializer='zeros')\n",
    "        self.union = self.add_weight(name='union', initializer='zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        # Flatten the tensors to calculate the Dice coefficient\n",
    "        y_true_f = tf.cast(tf.reshape(y_true, [-1]), tf.float32)\n",
    "        y_pred_f = tf.cast(tf.reshape(y_pred, [-1]), tf.float32)\n",
    "        \n",
    "        # Calculate the intersection (true positives)\n",
    "        intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
    "        \n",
    "        # Calculate the union (sum of both sets)\n",
    "        union = tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f)\n",
    "        \n",
    "        # Update the total intersection and union state\n",
    "        self.intersection.assign_add(intersection)\n",
    "        self.union.assign_add(union)\n",
    "\n",
    "    def result(self):\n",
    "        # Return the Dice coefficient\n",
    "        dice = (2. * self.intersection + self.smooth) / (self.union + self.smooth)\n",
    "        return dice  # This will return a 'tf.Tensor' (EagerTensor in eager mode)\n",
    "\n",
    "    def reset_states(self):\n",
    "        # Reset the intersection and union for the next epoch\n",
    "        self.intersection.assign(0.0)\n",
    "        self.union.assign(0.0)\n",
    "    def get_config(self):  # Renamed from `get_config()` to `get_dice_config()`\n",
    "        dt = super(DiceCoefficient, self).get_config()\n",
    "        dt.update({\n",
    "            \"smooth\": self.smooth,\n",
    "        })\n",
    "        return dt   \n",
    "class TimeHistory(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, file_path=\"epoch_times.txt\"):\n",
    "        super(TimeHistory, self).__init__()\n",
    "        self.file_path = file_path  # Custom file path for saving the times\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.epoch_times = []  # Initialize a list to store times for each epoch\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.start_time = time.time()  # Record the start time of the epoch\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        epoch_duration = time.time() - self.start_time  # Calculate the duration of the epoch\n",
    "        self.epoch_times.append(epoch_duration)  # Append to the list\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        # Ensure the directory exists\n",
    "        os.makedirs(os.path.dirname(self.file_path), exist_ok=True)\n",
    "        \n",
    "        # Store the epoch times list in the specified file path\n",
    "        with open(self.file_path, \"w\") as file:\n",
    "            file.write(str(self.epoch_times))\n",
    "        print(f\"Epoch times saved to '{self.file_path}'.\")        \n",
    "def conv_block(inputs, filters, alpha=1.0, kernel=(3, 3), strides=(1, 1)):\n",
    "    \"\"\"Basic conv block for MobileNet\"\"\"\n",
    "    filters = int(filters * alpha)\n",
    "    x = Conv2D(filters, kernel, padding='same', use_bias=False, strides=strides)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    return Activation('relu')(x)\n",
    "\n",
    "def depthwise_conv_block(inputs, pointwise_conv_filters, alpha=1.0, strides=(1, 1)):\n",
    "    \"\"\"Depthwise separable conv block for MobileNet\"\"\"\n",
    "    pointwise_conv_filters = int(pointwise_conv_filters * alpha)\n",
    "    \n",
    "    x = DepthwiseConv2D((3, 3), padding='same', strides=strides, use_bias=False)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(pointwise_conv_filters, (1, 1), padding='same', use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    return Activation('relu')(x)\n",
    "\n",
    "def MobileUNet(input_shape=(512, 512, 3), num_classes=24, alpha=1.0, lr_init=0.001):\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    # Encoder path\n",
    "    # Block 1 - (512x512 -> 256x256)\n",
    "    x = conv_block(inputs, 32, alpha, strides=(2, 2))\n",
    "    block1_out = depthwise_conv_block(x, 64, alpha)  # 256x256x64\n",
    "\n",
    "    # Block 2 - (256x256 -> 128x128)\n",
    "    x = depthwise_conv_block(block1_out, 128, alpha, strides=(2, 2))\n",
    "    block2_out = depthwise_conv_block(x, 128, alpha)  # 128x128x128\n",
    "\n",
    "    # Block 3 - (128x128 -> 64x64)\n",
    "    x = depthwise_conv_block(block2_out, 256, alpha, strides=(2, 2))\n",
    "    block3_out = depthwise_conv_block(x, 256, alpha)  # 64x64x256\n",
    "\n",
    "    # Block 4 - (64x64 -> 32x32)\n",
    "    x = depthwise_conv_block(block3_out, 512, alpha, strides=(2, 2))\n",
    "    block4_out = depthwise_conv_block(x, 512, alpha)  # 32x32x512\n",
    "\n",
    "    # Block 5 - (32x32 -> 16x16)\n",
    "    x = depthwise_conv_block(block4_out, 1024, alpha, strides=(2, 2))\n",
    "    encoded = depthwise_conv_block(x, 1024, alpha)  # 16x16x1024\n",
    "\n",
    "    # Decoder path\n",
    "    # UP 1 (16x16 -> 32x32)\n",
    "    x = Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(encoded)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = concatenate([x, block4_out])  # Now both are 32x32\n",
    "    x = depthwise_conv_block(x, 512, alpha)\n",
    "    x = depthwise_conv_block(x, 512, alpha)\n",
    "\n",
    "    # UP 2 (32x32 -> 64x64)\n",
    "    x = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = concatenate([x, block3_out])  # Now both are 64x64\n",
    "    x = depthwise_conv_block(x, 256, alpha)\n",
    "    x = depthwise_conv_block(x, 256, alpha)\n",
    "\n",
    "    # UP 3 (64x64 -> 128x128)\n",
    "    x = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = concatenate([x, block2_out])  # Now both are 128x128\n",
    "    x = depthwise_conv_block(x, 128, alpha)\n",
    "    x = depthwise_conv_block(x, 128, alpha)\n",
    "\n",
    "    # UP 4 (128x128 -> 256x256)\n",
    "    x = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = concatenate([x, block1_out])  # Now both are 256x256\n",
    "    x = depthwise_conv_block(x, 64, alpha)\n",
    "    x = depthwise_conv_block(x, 64, alpha)\n",
    "\n",
    "    # Final upsampling (256x256 -> 512x512)\n",
    "    x = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # Output layer\n",
    "    outputs = Conv2D(num_classes, (1, 1), activation='softmax', padding='same')(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer=Adam(learning_rate=lr_init),\n",
    "                 loss='categorical_crossentropy',\n",
    "                 metrics=[DiceCoefficient()])  # Add your DiceCoefficient here if needed\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0bf6e407",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T18:00:21.535216Z",
     "iopub.status.busy": "2024-11-14T18:00:21.535013Z",
     "iopub.status.idle": "2024-11-14T18:00:28.176609Z",
     "shell.execute_reply": "2024-11-14T18:00:28.176106Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)                  </span><span style=\"font-weight: bold\"> Output Shape              </span><span style=\"font-weight: bold\">         Param # </span><span style=\"font-weight: bold\"> Connected to               </span>\n",
       "\n",
       " input_layer_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                          \n",
       "\n",
       " conv2d_152 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">864</span>  input_layer_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        \n",
       "\n",
       " batch_normalization_320        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>  conv2d_152[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                                  \n",
       "\n",
       " activation_320 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_320[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " depthwise_conv2d_136           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>  activation_320[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)                                                                                     \n",
       "\n",
       " batch_normalization_321        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>  depthwise_conv2d_136[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                                  \n",
       "\n",
       " activation_321 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_321[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " conv2d_153 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span>  activation_321[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "\n",
       " batch_normalization_322        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>  conv2d_153[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                                  \n",
       "\n",
       " activation_322 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_322[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " depthwise_conv2d_137           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>  activation_322[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)                                                                                     \n",
       "\n",
       " batch_normalization_323        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>  depthwise_conv2d_137[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                                  \n",
       "\n",
       " activation_323 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_323[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " conv2d_154 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span>  activation_323[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "\n",
       " batch_normalization_324        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>  conv2d_154[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                                  \n",
       "\n",
       " activation_324 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_324[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " depthwise_conv2d_138           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">1,152</span>  activation_324[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)                                                                                     \n",
       "\n",
       " batch_normalization_325        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>  depthwise_conv2d_138[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                                  \n",
       "\n",
       " activation_325 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_325[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " conv2d_155 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">16,384</span>  activation_325[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "\n",
       " batch_normalization_326        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>  conv2d_155[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                                  \n",
       "\n",
       " activation_326 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_326[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " depthwise_conv2d_139           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,152</span>  activation_326[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)                                                                                     \n",
       "\n",
       " batch_normalization_327        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>  depthwise_conv2d_139[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                                  \n",
       "\n",
       " activation_327 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_327[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " conv2d_156 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">32,768</span>  activation_327[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "\n",
       " batch_normalization_328        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span>  conv2d_156[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                                  \n",
       "\n",
       " activation_328 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_328[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " depthwise_conv2d_140           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,304</span>  activation_328[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)                                                                                     \n",
       "\n",
       " batch_normalization_329        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span>  depthwise_conv2d_140[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                                  \n",
       "\n",
       " activation_329 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_329[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " conv2d_157 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">65,536</span>  activation_329[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "\n",
       " batch_normalization_330        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span>  conv2d_157[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                                  \n",
       "\n",
       " activation_330 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_330[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " depthwise_conv2d_141           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,304</span>  activation_330[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)                                                                                     \n",
       "\n",
       " batch_normalization_331        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span>  depthwise_conv2d_141[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                                  \n",
       "\n",
       " activation_331 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_331[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " conv2d_158 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">131,072</span>  activation_331[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "\n",
       " batch_normalization_332        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span>  conv2d_158[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                                  \n",
       "\n",
       " activation_332 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_332[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " depthwise_conv2d_142           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">4,608</span>  activation_332[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)                                                                                     \n",
       "\n",
       " batch_normalization_333        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span>  depthwise_conv2d_142[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                                  \n",
       "\n",
       " activation_333 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_333[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " conv2d_159 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">262,144</span>  activation_333[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "\n",
       " batch_normalization_334        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span>  conv2d_159[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                                  \n",
       "\n",
       " activation_334 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_334[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " depthwise_conv2d_143           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">4,608</span>  activation_334[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)                                                                                     \n",
       "\n",
       " batch_normalization_335        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span>  depthwise_conv2d_143[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                                  \n",
       "\n",
       " activation_335 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_335[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " conv2d_160 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">524,288</span>  activation_335[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "\n",
       " batch_normalization_336        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span>  conv2d_160[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                                  \n",
       "\n",
       " activation_336 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_336[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " depthwise_conv2d_144           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">9,216</span>  activation_336[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)                                                                                     \n",
       "\n",
       " batch_normalization_337        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span>  depthwise_conv2d_144[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                                  \n",
       "\n",
       " activation_337 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_337[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " conv2d_161 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">1,048,576</span>  activation_337[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "\n",
       " batch_normalization_338        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span>  conv2d_161[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                                  \n",
       "\n",
       " activation_338 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_338[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " conv2d_transpose_40            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              <span style=\"color: #00af00; text-decoration-color: #00af00\">2,097,664</span>  activation_338[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)                                                                                     \n",
       "\n",
       " batch_normalization_339        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span>  conv2d_transpose_40[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                                  \n",
       "\n",
       " activation_339 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_339[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " concatenate_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  activation_339[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      \n",
       "                                                                            activation_334[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "\n",
       " depthwise_conv2d_145           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">9,216</span>  concatenate_32[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)                                                                                     \n",
       "\n",
       " batch_normalization_340        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span>  depthwise_conv2d_145[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                                  \n",
       "\n",
       " activation_340 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_340[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " conv2d_162 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">524,288</span>  activation_340[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "\n",
       " batch_normalization_341        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span>  conv2d_162[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                                  \n",
       "\n",
       " activation_341 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_341[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " depthwise_conv2d_146           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">4,608</span>  activation_341[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)                                                                                     \n",
       "\n",
       " batch_normalization_342        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span>  depthwise_conv2d_146[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                                  \n",
       "\n",
       " activation_342 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_342[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " conv2d_163 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">262,144</span>  activation_342[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "\n",
       " batch_normalization_343        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span>  conv2d_163[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                                  \n",
       "\n",
       " activation_343 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_343[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " conv2d_transpose_41            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">524,544</span>  activation_343[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)                                                                                     \n",
       "\n",
       " batch_normalization_344        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span>  conv2d_transpose_41[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                                  \n",
       "\n",
       " activation_344 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_344[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " concatenate_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  activation_344[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      \n",
       "                                                                            activation_330[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "\n",
       " depthwise_conv2d_147           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">4,608</span>  concatenate_33[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)                                                                                     \n",
       "\n",
       " batch_normalization_345        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span>  depthwise_conv2d_147[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                                  \n",
       "\n",
       " activation_345 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_345[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " conv2d_164 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">131,072</span>  activation_345[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "\n",
       " batch_normalization_346        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span>  conv2d_164[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                                  \n",
       "\n",
       " activation_346 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_346[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " depthwise_conv2d_148           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,304</span>  activation_346[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)                                                                                     \n",
       "\n",
       " batch_normalization_347        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span>  depthwise_conv2d_148[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                                  \n",
       "\n",
       " activation_347 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_347[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " conv2d_165 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">65,536</span>  activation_347[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "\n",
       " batch_normalization_348        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span>  conv2d_165[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                                  \n",
       "\n",
       " activation_348 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_348[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " conv2d_transpose_42            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              <span style=\"color: #00af00; text-decoration-color: #00af00\">131,200</span>  activation_348[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)                                                                                     \n",
       "\n",
       " batch_normalization_349        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>  conv2d_transpose_42[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                                  \n",
       "\n",
       " activation_349 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_349[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " concatenate_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  activation_349[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      \n",
       "                                                                            activation_326[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "\n",
       " depthwise_conv2d_149           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">2,304</span>  concatenate_34[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)                                                                                     \n",
       "\n",
       " batch_normalization_350        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span>  depthwise_conv2d_149[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                                  \n",
       "\n",
       " activation_350 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_350[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " conv2d_166 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">32,768</span>  activation_350[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "\n",
       " batch_normalization_351        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>  conv2d_166[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                                  \n",
       "\n",
       " activation_351 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_351[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " depthwise_conv2d_150           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">1,152</span>  activation_351[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)                                                                                     \n",
       "\n",
       " batch_normalization_352        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>  depthwise_conv2d_150[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                                  \n",
       "\n",
       " activation_352 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_352[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " conv2d_167 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">16,384</span>  activation_352[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "\n",
       " batch_normalization_353        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>  conv2d_167[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                                  \n",
       "\n",
       " activation_353 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_353[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " conv2d_transpose_43            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">32,832</span>  activation_353[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)                                                                                     \n",
       "\n",
       " batch_normalization_354        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>  conv2d_transpose_43[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                                  \n",
       "\n",
       " activation_354 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_354[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " concatenate_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  activation_354[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      \n",
       "                                                                            activation_322[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "\n",
       " depthwise_conv2d_151           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">1,152</span>  concatenate_35[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)                                                                                     \n",
       "\n",
       " batch_normalization_355        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>  depthwise_conv2d_151[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                                  \n",
       "\n",
       " activation_355 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_355[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " conv2d_168 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span>  activation_355[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "\n",
       " batch_normalization_356        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>  conv2d_168[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                                  \n",
       "\n",
       " activation_356 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_356[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " depthwise_conv2d_152           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>  activation_356[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)                                                                                     \n",
       "\n",
       " batch_normalization_357        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>  depthwise_conv2d_152[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                                  \n",
       "\n",
       " activation_357 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_357[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " conv2d_169 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span>  activation_357[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "\n",
       " batch_normalization_358        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>  conv2d_169[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                                  \n",
       "\n",
       " activation_358 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_358[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " conv2d_transpose_44            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">8,224</span>  activation_358[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)                                                                                     \n",
       "\n",
       " batch_normalization_359        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>  conv2d_transpose_44[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                                  \n",
       "\n",
       " activation_359 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_359[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " conv2d_170 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">792</span>  activation_359[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " input_layer_8 (\u001b[38;5;33mInputLayer\u001b[0m)     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m3\u001b[0m)                      \u001b[38;5;34m0\u001b[0m  -                          \n",
       "\n",
       " conv2d_152 (\u001b[38;5;33mConv2D\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m32\u001b[0m)                   \u001b[38;5;34m864\u001b[0m  input_layer_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        \n",
       "\n",
       " batch_normalization_320        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m32\u001b[0m)                   \u001b[38;5;34m128\u001b[0m  conv2d_152[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " activation_320 (\u001b[38;5;33mActivation\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m32\u001b[0m)                     \u001b[38;5;34m0\u001b[0m  batch_normalization_320[\u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " depthwise_conv2d_136           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m32\u001b[0m)                   \u001b[38;5;34m288\u001b[0m  activation_320[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       " (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)                                                                                     \n",
       "\n",
       " batch_normalization_321        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m32\u001b[0m)                   \u001b[38;5;34m128\u001b[0m  depthwise_conv2d_136[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " activation_321 (\u001b[38;5;33mActivation\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m32\u001b[0m)                     \u001b[38;5;34m0\u001b[0m  batch_normalization_321[\u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " conv2d_153 (\u001b[38;5;33mConv2D\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)                 \u001b[38;5;34m2,048\u001b[0m  activation_321[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "\n",
       " batch_normalization_322        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)                   \u001b[38;5;34m256\u001b[0m  conv2d_153[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " activation_322 (\u001b[38;5;33mActivation\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)                     \u001b[38;5;34m0\u001b[0m  batch_normalization_322[\u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " depthwise_conv2d_137           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)                   \u001b[38;5;34m576\u001b[0m  activation_322[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       " (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)                                                                                     \n",
       "\n",
       " batch_normalization_323        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)                   \u001b[38;5;34m256\u001b[0m  depthwise_conv2d_137[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " activation_323 (\u001b[38;5;33mActivation\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)                     \u001b[38;5;34m0\u001b[0m  batch_normalization_323[\u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " conv2d_154 (\u001b[38;5;33mConv2D\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)                \u001b[38;5;34m8,192\u001b[0m  activation_323[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "\n",
       " batch_normalization_324        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)                  \u001b[38;5;34m512\u001b[0m  conv2d_154[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " activation_324 (\u001b[38;5;33mActivation\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)                    \u001b[38;5;34m0\u001b[0m  batch_normalization_324[\u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " depthwise_conv2d_138           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)                \u001b[38;5;34m1,152\u001b[0m  activation_324[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       " (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)                                                                                     \n",
       "\n",
       " batch_normalization_325        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)                  \u001b[38;5;34m512\u001b[0m  depthwise_conv2d_138[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " activation_325 (\u001b[38;5;33mActivation\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)                    \u001b[38;5;34m0\u001b[0m  batch_normalization_325[\u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " conv2d_155 (\u001b[38;5;33mConv2D\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)               \u001b[38;5;34m16,384\u001b[0m  activation_325[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "\n",
       " batch_normalization_326        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)                  \u001b[38;5;34m512\u001b[0m  conv2d_155[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " activation_326 (\u001b[38;5;33mActivation\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)                    \u001b[38;5;34m0\u001b[0m  batch_normalization_326[\u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " depthwise_conv2d_139           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)                  \u001b[38;5;34m1,152\u001b[0m  activation_326[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       " (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)                                                                                     \n",
       "\n",
       " batch_normalization_327        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)                    \u001b[38;5;34m512\u001b[0m  depthwise_conv2d_139[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " activation_327 (\u001b[38;5;33mActivation\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)                      \u001b[38;5;34m0\u001b[0m  batch_normalization_327[\u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " conv2d_156 (\u001b[38;5;33mConv2D\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 \u001b[38;5;34m32,768\u001b[0m  activation_327[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "\n",
       " batch_normalization_328        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)                  \u001b[38;5;34m1,024\u001b[0m  conv2d_156[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " activation_328 (\u001b[38;5;33mActivation\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)                      \u001b[38;5;34m0\u001b[0m  batch_normalization_328[\u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " depthwise_conv2d_140           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)                  \u001b[38;5;34m2,304\u001b[0m  activation_328[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       " (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)                                                                                     \n",
       "\n",
       " batch_normalization_329        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)                  \u001b[38;5;34m1,024\u001b[0m  depthwise_conv2d_140[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " activation_329 (\u001b[38;5;33mActivation\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)                      \u001b[38;5;34m0\u001b[0m  batch_normalization_329[\u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " conv2d_157 (\u001b[38;5;33mConv2D\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 \u001b[38;5;34m65,536\u001b[0m  activation_329[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "\n",
       " batch_normalization_330        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)                  \u001b[38;5;34m1,024\u001b[0m  conv2d_157[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " activation_330 (\u001b[38;5;33mActivation\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)                      \u001b[38;5;34m0\u001b[0m  batch_normalization_330[\u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " depthwise_conv2d_141           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)                  \u001b[38;5;34m2,304\u001b[0m  activation_330[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       " (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)                                                                                     \n",
       "\n",
       " batch_normalization_331        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)                  \u001b[38;5;34m1,024\u001b[0m  depthwise_conv2d_141[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " activation_331 (\u001b[38;5;33mActivation\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)                      \u001b[38;5;34m0\u001b[0m  batch_normalization_331[\u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " conv2d_158 (\u001b[38;5;33mConv2D\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)                \u001b[38;5;34m131,072\u001b[0m  activation_331[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "\n",
       " batch_normalization_332        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)                  \u001b[38;5;34m2,048\u001b[0m  conv2d_158[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " activation_332 (\u001b[38;5;33mActivation\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)                      \u001b[38;5;34m0\u001b[0m  batch_normalization_332[\u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " depthwise_conv2d_142           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)                  \u001b[38;5;34m4,608\u001b[0m  activation_332[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       " (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)                                                                                     \n",
       "\n",
       " batch_normalization_333        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)                  \u001b[38;5;34m2,048\u001b[0m  depthwise_conv2d_142[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " activation_333 (\u001b[38;5;33mActivation\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)                      \u001b[38;5;34m0\u001b[0m  batch_normalization_333[\u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " conv2d_159 (\u001b[38;5;33mConv2D\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)                \u001b[38;5;34m262,144\u001b[0m  activation_333[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "\n",
       " batch_normalization_334        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)                  \u001b[38;5;34m2,048\u001b[0m  conv2d_159[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " activation_334 (\u001b[38;5;33mActivation\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)                      \u001b[38;5;34m0\u001b[0m  batch_normalization_334[\u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " depthwise_conv2d_143           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)                  \u001b[38;5;34m4,608\u001b[0m  activation_334[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       " (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)                                                                                     \n",
       "\n",
       " batch_normalization_335        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)                  \u001b[38;5;34m2,048\u001b[0m  depthwise_conv2d_143[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " activation_335 (\u001b[38;5;33mActivation\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)                      \u001b[38;5;34m0\u001b[0m  batch_normalization_335[\u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " conv2d_160 (\u001b[38;5;33mConv2D\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m1024\u001b[0m)               \u001b[38;5;34m524,288\u001b[0m  activation_335[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "\n",
       " batch_normalization_336        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                 \u001b[38;5;34m4,096\u001b[0m  conv2d_160[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " activation_336 (\u001b[38;5;33mActivation\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                     \u001b[38;5;34m0\u001b[0m  batch_normalization_336[\u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " depthwise_conv2d_144           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                 \u001b[38;5;34m9,216\u001b[0m  activation_336[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       " (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)                                                                                     \n",
       "\n",
       " batch_normalization_337        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                 \u001b[38;5;34m4,096\u001b[0m  depthwise_conv2d_144[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " activation_337 (\u001b[38;5;33mActivation\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                     \u001b[38;5;34m0\u001b[0m  batch_normalization_337[\u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " conv2d_161 (\u001b[38;5;33mConv2D\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m1024\u001b[0m)             \u001b[38;5;34m1,048,576\u001b[0m  activation_337[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "\n",
       " batch_normalization_338        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                 \u001b[38;5;34m4,096\u001b[0m  conv2d_161[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " activation_338 (\u001b[38;5;33mActivation\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                     \u001b[38;5;34m0\u001b[0m  batch_normalization_338[\u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " conv2d_transpose_40            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)              \u001b[38;5;34m2,097,664\u001b[0m  activation_338[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       " (\u001b[38;5;33mConv2DTranspose\u001b[0m)                                                                                     \n",
       "\n",
       " batch_normalization_339        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)                  \u001b[38;5;34m2,048\u001b[0m  conv2d_transpose_40[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " activation_339 (\u001b[38;5;33mActivation\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)                      \u001b[38;5;34m0\u001b[0m  batch_normalization_339[\u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " concatenate_32 (\u001b[38;5;33mConcatenate\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                     \u001b[38;5;34m0\u001b[0m  activation_339[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      \n",
       "                                                                            activation_334[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "\n",
       " depthwise_conv2d_145           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                 \u001b[38;5;34m9,216\u001b[0m  concatenate_32[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       " (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)                                                                                     \n",
       "\n",
       " batch_normalization_340        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                 \u001b[38;5;34m4,096\u001b[0m  depthwise_conv2d_145[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " activation_340 (\u001b[38;5;33mActivation\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                     \u001b[38;5;34m0\u001b[0m  batch_normalization_340[\u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " conv2d_162 (\u001b[38;5;33mConv2D\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)                \u001b[38;5;34m524,288\u001b[0m  activation_340[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "\n",
       " batch_normalization_341        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)                  \u001b[38;5;34m2,048\u001b[0m  conv2d_162[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " activation_341 (\u001b[38;5;33mActivation\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)                      \u001b[38;5;34m0\u001b[0m  batch_normalization_341[\u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " depthwise_conv2d_146           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)                  \u001b[38;5;34m4,608\u001b[0m  activation_341[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       " (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)                                                                                     \n",
       "\n",
       " batch_normalization_342        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)                  \u001b[38;5;34m2,048\u001b[0m  depthwise_conv2d_146[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " activation_342 (\u001b[38;5;33mActivation\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)                      \u001b[38;5;34m0\u001b[0m  batch_normalization_342[\u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " conv2d_163 (\u001b[38;5;33mConv2D\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)                \u001b[38;5;34m262,144\u001b[0m  activation_342[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "\n",
       " batch_normalization_343        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)                  \u001b[38;5;34m2,048\u001b[0m  conv2d_163[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " activation_343 (\u001b[38;5;33mActivation\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)                      \u001b[38;5;34m0\u001b[0m  batch_normalization_343[\u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " conv2d_transpose_41            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)                \u001b[38;5;34m524,544\u001b[0m  activation_343[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       " (\u001b[38;5;33mConv2DTranspose\u001b[0m)                                                                                     \n",
       "\n",
       " batch_normalization_344        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)                  \u001b[38;5;34m1,024\u001b[0m  conv2d_transpose_41[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " activation_344 (\u001b[38;5;33mActivation\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)                      \u001b[38;5;34m0\u001b[0m  batch_normalization_344[\u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " concatenate_33 (\u001b[38;5;33mConcatenate\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)                      \u001b[38;5;34m0\u001b[0m  activation_344[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      \n",
       "                                                                            activation_330[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "\n",
       " depthwise_conv2d_147           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)                  \u001b[38;5;34m4,608\u001b[0m  concatenate_33[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       " (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)                                                                                     \n",
       "\n",
       " batch_normalization_345        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)                  \u001b[38;5;34m2,048\u001b[0m  depthwise_conv2d_147[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " activation_345 (\u001b[38;5;33mActivation\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)                      \u001b[38;5;34m0\u001b[0m  batch_normalization_345[\u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " conv2d_164 (\u001b[38;5;33mConv2D\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)                \u001b[38;5;34m131,072\u001b[0m  activation_345[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "\n",
       " batch_normalization_346        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)                  \u001b[38;5;34m1,024\u001b[0m  conv2d_164[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " activation_346 (\u001b[38;5;33mActivation\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)                      \u001b[38;5;34m0\u001b[0m  batch_normalization_346[\u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " depthwise_conv2d_148           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)                  \u001b[38;5;34m2,304\u001b[0m  activation_346[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       " (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)                                                                                     \n",
       "\n",
       " batch_normalization_347        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)                  \u001b[38;5;34m1,024\u001b[0m  depthwise_conv2d_148[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " activation_347 (\u001b[38;5;33mActivation\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)                      \u001b[38;5;34m0\u001b[0m  batch_normalization_347[\u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " conv2d_165 (\u001b[38;5;33mConv2D\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 \u001b[38;5;34m65,536\u001b[0m  activation_347[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "\n",
       " batch_normalization_348        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)                  \u001b[38;5;34m1,024\u001b[0m  conv2d_165[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " activation_348 (\u001b[38;5;33mActivation\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)                      \u001b[38;5;34m0\u001b[0m  batch_normalization_348[\u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " conv2d_transpose_42            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)              \u001b[38;5;34m131,200\u001b[0m  activation_348[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       " (\u001b[38;5;33mConv2DTranspose\u001b[0m)                                                                                     \n",
       "\n",
       " batch_normalization_349        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)                  \u001b[38;5;34m512\u001b[0m  conv2d_transpose_42[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " activation_349 (\u001b[38;5;33mActivation\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)                    \u001b[38;5;34m0\u001b[0m  batch_normalization_349[\u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " concatenate_34 (\u001b[38;5;33mConcatenate\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)                    \u001b[38;5;34m0\u001b[0m  activation_349[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      \n",
       "                                                                            activation_326[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "\n",
       " depthwise_conv2d_149           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)                \u001b[38;5;34m2,304\u001b[0m  concatenate_34[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       " (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)                                                                                     \n",
       "\n",
       " batch_normalization_350        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)                \u001b[38;5;34m1,024\u001b[0m  depthwise_conv2d_149[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " activation_350 (\u001b[38;5;33mActivation\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)                    \u001b[38;5;34m0\u001b[0m  batch_normalization_350[\u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " conv2d_166 (\u001b[38;5;33mConv2D\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)               \u001b[38;5;34m32,768\u001b[0m  activation_350[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "\n",
       " batch_normalization_351        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)                  \u001b[38;5;34m512\u001b[0m  conv2d_166[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " activation_351 (\u001b[38;5;33mActivation\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)                    \u001b[38;5;34m0\u001b[0m  batch_normalization_351[\u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " depthwise_conv2d_150           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)                \u001b[38;5;34m1,152\u001b[0m  activation_351[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       " (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)                                                                                     \n",
       "\n",
       " batch_normalization_352        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)                  \u001b[38;5;34m512\u001b[0m  depthwise_conv2d_150[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " activation_352 (\u001b[38;5;33mActivation\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)                    \u001b[38;5;34m0\u001b[0m  batch_normalization_352[\u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " conv2d_167 (\u001b[38;5;33mConv2D\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)               \u001b[38;5;34m16,384\u001b[0m  activation_352[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "\n",
       " batch_normalization_353        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)                  \u001b[38;5;34m512\u001b[0m  conv2d_167[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " activation_353 (\u001b[38;5;33mActivation\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)                    \u001b[38;5;34m0\u001b[0m  batch_normalization_353[\u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " conv2d_transpose_43            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)                \u001b[38;5;34m32,832\u001b[0m  activation_353[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       " (\u001b[38;5;33mConv2DTranspose\u001b[0m)                                                                                     \n",
       "\n",
       " batch_normalization_354        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)                   \u001b[38;5;34m256\u001b[0m  conv2d_transpose_43[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " activation_354 (\u001b[38;5;33mActivation\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)                     \u001b[38;5;34m0\u001b[0m  batch_normalization_354[\u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " concatenate_35 (\u001b[38;5;33mConcatenate\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)                    \u001b[38;5;34m0\u001b[0m  activation_354[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      \n",
       "                                                                            activation_322[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "\n",
       " depthwise_conv2d_151           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)                \u001b[38;5;34m1,152\u001b[0m  concatenate_35[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       " (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)                                                                                     \n",
       "\n",
       " batch_normalization_355        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)                  \u001b[38;5;34m512\u001b[0m  depthwise_conv2d_151[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " activation_355 (\u001b[38;5;33mActivation\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)                    \u001b[38;5;34m0\u001b[0m  batch_normalization_355[\u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " conv2d_168 (\u001b[38;5;33mConv2D\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)                 \u001b[38;5;34m8,192\u001b[0m  activation_355[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "\n",
       " batch_normalization_356        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)                   \u001b[38;5;34m256\u001b[0m  conv2d_168[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " activation_356 (\u001b[38;5;33mActivation\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)                     \u001b[38;5;34m0\u001b[0m  batch_normalization_356[\u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " depthwise_conv2d_152           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)                   \u001b[38;5;34m576\u001b[0m  activation_356[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       " (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)                                                                                     \n",
       "\n",
       " batch_normalization_357        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)                   \u001b[38;5;34m256\u001b[0m  depthwise_conv2d_152[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " activation_357 (\u001b[38;5;33mActivation\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)                     \u001b[38;5;34m0\u001b[0m  batch_normalization_357[\u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " conv2d_169 (\u001b[38;5;33mConv2D\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)                 \u001b[38;5;34m4,096\u001b[0m  activation_357[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "\n",
       " batch_normalization_358        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)                   \u001b[38;5;34m256\u001b[0m  conv2d_169[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " activation_358 (\u001b[38;5;33mActivation\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)                     \u001b[38;5;34m0\u001b[0m  batch_normalization_358[\u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " conv2d_transpose_44            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m32\u001b[0m)                 \u001b[38;5;34m8,224\u001b[0m  activation_358[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       " (\u001b[38;5;33mConv2DTranspose\u001b[0m)                                                                                     \n",
       "\n",
       " batch_normalization_359        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m32\u001b[0m)                   \u001b[38;5;34m128\u001b[0m  conv2d_transpose_44[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " activation_359 (\u001b[38;5;33mActivation\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m32\u001b[0m)                     \u001b[38;5;34m0\u001b[0m  batch_normalization_359[\u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " conv2d_170 (\u001b[38;5;33mConv2D\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m24\u001b[0m)                   \u001b[38;5;34m792\u001b[0m  activation_359[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,034,296</span> (23.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,034,296\u001b[0m (23.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,009,016</span> (22.92 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,009,016\u001b[0m (22.92 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,280</span> (98.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m25,280\u001b[0m (98.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vgg16_unet = MobileUNet(num_classes = 24, input_shape = (512, 512, 3), lr_init = 0.0001)\n",
    "\n",
    "vgg16_unet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "54c25878",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T18:00:28.178387Z",
     "iopub.status.busy": "2024-11-14T18:00:28.178189Z",
     "iopub.status.idle": "2024-11-14T18:00:28.182386Z",
     "shell.execute_reply": "2024-11-14T18:00:28.181957Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 512, 512, 24)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg16_unet.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "75280939",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T18:00:28.184021Z",
     "iopub.status.busy": "2024-11-14T18:00:28.183771Z",
     "iopub.status.idle": "2024-11-14T18:00:28.186012Z",
     "shell.execute_reply": "2024-11-14T18:00:28.185576Z"
    }
   },
   "outputs": [],
   "source": [
    "# pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2b52be92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T18:00:28.187571Z",
     "iopub.status.busy": "2024-11-14T18:00:28.187324Z",
     "iopub.status.idle": "2024-11-14T18:00:28.189436Z",
     "shell.execute_reply": "2024-11-14T18:00:28.189018Z"
    }
   },
   "outputs": [],
   "source": [
    "# pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "18c01c1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T18:00:28.191054Z",
     "iopub.status.busy": "2024-11-14T18:00:28.190810Z",
     "iopub.status.idle": "2024-11-14T18:00:28.193023Z",
     "shell.execute_reply": "2024-11-14T18:00:28.192602Z"
    }
   },
   "outputs": [],
   "source": [
    "# from IPython.display import SVG\n",
    "# from tensorflow.keras.utils import model_to_dot\n",
    "\n",
    "# SVG(model_to_dot(vgg16_unet).create(prog='dot', format='svg'))\n",
    "# plot_model(vgg16_unet, to_file='vgg16_unet_plot.png', show_shapes=True, show_layer_names=True, expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f04ac0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "02be711c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T18:00:28.194804Z",
     "iopub.status.busy": "2024-11-14T18:00:28.194445Z",
     "iopub.status.idle": "2024-11-14T18:00:28.203330Z",
     "shell.execute_reply": "2024-11-14T18:00:28.202897Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "class DebugBatchCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__()  # Initialize the base Callback class\n",
    "    \n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        # Safely get the 'loss' and 'accuracy' with a default value\n",
    "        loss = logs.get('loss', 'N/A')\n",
    "        accuracy = logs.get('accuracy', 'N/A')\n",
    "        \n",
    "        # Check if loss and accuracy are floats before formatting\n",
    "        if isinstance(loss, float):\n",
    "            loss_str = f\"{loss:.4f}\"\n",
    "        else:\n",
    "            loss_str = str(loss)\n",
    "            print(\"h\")\n",
    "\n",
    "        if isinstance(accuracy, float):\n",
    "            accuracy_str = f\"{accuracy:.4f}\"\n",
    "        else:\n",
    "            accuracy_str = str(accuracy)\n",
    "        \n",
    "\n",
    "        # Print batch number, loss, and accuracy (if available)\n",
    "        print(f\"Batch {batch + 1} - Loss: {loss_str}, Accuracy: {accuracy_str}\")\n",
    "        \n",
    "        # Example of accessing the model (if needed)\n",
    "        first_layer_weights = self.model.layers[0].get_weights()\n",
    "        print(f\"    - First layer weights shape: {first_layer_weights[0].shape}\")\n",
    "db=DebugBatchCallback()        \n",
    "def exponential_decay(lr0, s):\n",
    "    def exponential_decay_fn(epoch):\n",
    "        return lr0 * 0.1 **(epoch / s)\n",
    "    return exponential_decay_fn\n",
    "\n",
    "exponential_decay_fn = exponential_decay(0.0001, 20)\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(\n",
    "    exponential_decay_fn,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath = 'vgg16_unet_model.keras',\n",
    "    save_best_only = True, \n",
    "#     save_weights_only = False,\n",
    "    monitor = 'loss', \n",
    "    mode = 'auto', \n",
    "    verbose = 1\n",
    ")\n",
    "\n",
    "earlystop = EarlyStopping(\n",
    "    monitor = 'loss', \n",
    "    min_delta = 0.001, \n",
    "    patience = 6, \n",
    "    mode = 'auto', \n",
    "    verbose = 1,\n",
    "    restore_best_weights = True\n",
    ")\n",
    "\n",
    "\n",
    "csvlogger = CSVLogger(\n",
    "    filename= \"model_training_csv.log\",\n",
    "    separator = \",\",\n",
    "    append = False\n",
    ")\n",
    "class timeshistory(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, file_path=\"epoch_times.txt\"):\n",
    "        super(timeshistory, self).__init__()\n",
    "        self.file_path = file_path  # Custom file path for saving the times\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.epoch_times = []  # Initialize a list to store times for each epoch\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.start_time = time.time()  # Record the start time of the epoch\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        epoch_duration = time.time() - self.start_time  # Calculate the duration of the epoch\n",
    "        self.epoch_times.append(epoch_duration)  # Append to the list\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        # Ensure the directory exists\n",
    "        os.makedirs(os.path.dirname(self.file_path), exist_ok=True)\n",
    "        \n",
    "        # Store the epoch times list in the specified file path\n",
    "        with open(self.file_path, \"w\") as file:\n",
    "            file.write(str(self.epoch_times))\n",
    "        print(f\"Epoch times saved to '{self.file_path}'.\")\n",
    "times_callback = timeshistory(file_path='/home/pranav/DeepLearning/mobilenettimes.txt')\n",
    "callbacks = [checkpoint, earlystop, csvlogger, lr_scheduler,times_callback]\n",
    "with open(\"/home/pranav/DeepLearning/new.txt\",\"a\") as wr:\n",
    "    wr.write(\"The eigth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "92839967",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T18:00:28.204968Z",
     "iopub.status.busy": "2024-11-14T18:00:28.204747Z",
     "iopub.status.idle": "2024-11-14T18:00:28.207518Z",
     "shell.execute_reply": "2024-11-14T18:00:28.207087Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/pranav/DeepLearning/train_images\n",
      "/home/pranav/DeepLearning/train_masks\n"
     ]
    }
   ],
   "source": [
    "print(train_images)\n",
    "print(train_masks)\n",
    "# print(val_images)\n",
    "# print(masksval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9c17400d-6d95-4611-ad46-c18dd8288e91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T18:00:28.209102Z",
     "iopub.status.busy": "2024-11-14T18:00:28.208855Z",
     "iopub.status.idle": "2024-11-14T18:00:28.211468Z",
     "shell.execute_reply": "2024-11-14T18:00:28.211050Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ho\n"
     ]
    }
   ],
   "source": [
    "print(\"ho\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "be6014e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T18:00:28.213070Z",
     "iopub.status.busy": "2024-11-14T18:00:28.212784Z",
     "iopub.status.idle": "2024-11-15T07:44:10.861541Z",
     "shell.execute_reply": "2024-11-15T07:44:10.860761Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1600 images belonging to 1 classes.\n",
      "Found 1600 images belonging to 1 classes.\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1731607248.882831 4106216 service.cc:148] XLA service 0x7f74b400a280 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1731607248.882881 4106216 service.cc:156]   StreamExecutor device (0): NVIDIA A100-SXM4-80GB, Compute Capability 8.0\n",
      "I0000 00:00:1731607248.882888 4106216 service.cc:156]   StreamExecutor device (1): NVIDIA A100-SXM4-80GB, Compute Capability 8.0\n",
      "I0000 00:00:1731607248.882892 4106216 service.cc:156]   StreamExecutor device (2): NVIDIA A100-SXM4-80GB, Compute Capability 8.0\n",
      "I0000 00:00:1731607248.882895 4106216 service.cc:156]   StreamExecutor device (3): NVIDIA A100-SXM4-80GB, Compute Capability 8.0\n",
      "I0000 00:00:1731607248.882900 4106216 service.cc:156]   StreamExecutor device (4): NVIDIA A100-SXM4-80GB, Compute Capability 8.0\n",
      "I0000 00:00:1731607248.882903 4106216 service.cc:156]   StreamExecutor device (5): NVIDIA A100-SXM4-80GB, Compute Capability 8.0\n",
      "I0000 00:00:1731607248.882907 4106216 service.cc:156]   StreamExecutor device (6): NVIDIA A100-SXM4-80GB, Compute Capability 8.0\n",
      "I0000 00:00:1731607248.882909 4106216 service.cc:156]   StreamExecutor device (7): NVIDIA A100-SXM4-80GB, Compute Capability 8.0\n",
      "2024-11-14 23:30:49.297562: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1731607251.094018 4106216 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "Could not load symbol cuFuncGetName. Error: /lib/x86_64-linux-gnu/libcuda.so.1: undefined symbol: cuFuncGetName\n",
      "E0000 00:00:1731607252.944553 4106216 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1731607253.156468 4106216 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1731607253.801816 4106216 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1731607253.989644 4106216 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1731607254.442845 4106216 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1731607254.628859 4106216 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1731607255.170347 4106216 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1731607255.346654 4106216 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1731607255.794238 4106216 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1731607255.969926 4106216 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1731607256.551127 4106216 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1731607256.722247 4106216 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1731607257.294008 4106216 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1731607257.464491 4106216 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1731607259.319470 4106216 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1731607259.519608 4106216 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1731607260.569182 4106216 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1731607260.780063 4106216 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1731607262.090252 4106216 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1731607262.324504 4106216 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1731607264.309927 4106216 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1731607264.600694 4106216 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1731607265.694312 4106216 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1731607265.910052 4106216 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1731607268.247011 4106216 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1731607268.418348 4106216 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1731607268.923675 4106216 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1731607269.099741 4106216 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1731607269.727386 4106216 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1731607269.915217 4106216 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1731607270.877685 4106216 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1731607271.094610 4106216 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2024-11-14 23:31:22.854564: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng48{k0=1,k2=3,k5=2,k14=2} for conv (f32[128,1,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[8,128,256,256]{3,2,1,0}, f32[8,128,256,256]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, feature_group_count=128, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2024-11-14 23:31:23.285627: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.431886731s\n",
      "Trying algorithm eng48{k0=1,k2=3,k5=2,k14=2} for conv (f32[128,1,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[8,128,256,256]{3,2,1,0}, f32[8,128,256,256]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, feature_group_count=128, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  2/200\u001b[0m \u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 83ms/step - dice_coefficient: 0.0377 - loss: 3.6653   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1731607297.122553 4106216 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.0442 - loss: 3.3583\n",
      "Epoch 1: loss improved from inf to 3.15192, saving model to vgg16_unet_model.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m884s\u001b[0m 4s/step - dice_coefficient: 0.0442 - loss: 3.3573 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 8.912509381337456e-05.\n",
      "Epoch 2/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.0930 - loss: 2.6632\n",
      "Epoch 2: loss improved from 3.15192 to 2.55168, saving model to vgg16_unet_model.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m841s\u001b[0m 4s/step - dice_coefficient: 0.0931 - loss: 2.6627 - learning_rate: 8.9125e-05\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 7.943282347242815e-05.\n",
      "Epoch 3/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.1597 - loss: 2.2787\n",
      "Epoch 3: loss improved from 2.55168 to 2.22631, saving model to vgg16_unet_model.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m842s\u001b[0m 4s/step - dice_coefficient: 0.1598 - loss: 2.2785 - learning_rate: 7.9433e-05\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 7.07945784384138e-05.\n",
      "Epoch 4/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.2109 - loss: 2.0414\n",
      "Epoch 4: loss improved from 2.22631 to 2.02033, saving model to vgg16_unet_model.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m840s\u001b[0m 4s/step - dice_coefficient: 0.2109 - loss: 2.0413 - learning_rate: 7.0795e-05\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 6.309573444801933e-05.\n",
      "Epoch 5/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.2507 - loss: 1.9002\n",
      "Epoch 5: loss improved from 2.02033 to 1.87450, saving model to vgg16_unet_model.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m840s\u001b[0m 4s/step - dice_coefficient: 0.2508 - loss: 1.9001 - learning_rate: 6.3096e-05\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 5.623413251903491e-05.\n",
      "Epoch 6/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.2897 - loss: 1.7752\n",
      "Epoch 6: loss improved from 1.87450 to 1.75872, saving model to vgg16_unet_model.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m826s\u001b[0m 4s/step - dice_coefficient: 0.2897 - loss: 1.7751 - learning_rate: 5.6234e-05\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 5.011872336272724e-05.\n",
      "Epoch 7/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.3180 - loss: 1.6958\n",
      "Epoch 7: loss improved from 1.75872 to 1.67373, saving model to vgg16_unet_model.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m829s\u001b[0m 4s/step - dice_coefficient: 0.3180 - loss: 1.6957 - learning_rate: 5.0119e-05\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 4.4668359215096314e-05.\n",
      "Epoch 8/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.3455 - loss: 1.6199\n",
      "Epoch 8: loss improved from 1.67373 to 1.61220, saving model to vgg16_unet_model.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m839s\u001b[0m 4s/step - dice_coefficient: 0.3455 - loss: 1.6198 - learning_rate: 4.4668e-05\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 3.981071705534973e-05.\n",
      "Epoch 9/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.3663 - loss: 1.5673\n",
      "Epoch 9: loss improved from 1.61220 to 1.55403, saving model to vgg16_unet_model.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m836s\u001b[0m 4s/step - dice_coefficient: 0.3663 - loss: 1.5672 - learning_rate: 3.9811e-05\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 3.548133892335755e-05.\n",
      "Epoch 10/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.3826 - loss: 1.5296\n",
      "Epoch 10: loss improved from 1.55403 to 1.51320, saving model to vgg16_unet_model.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m868s\u001b[0m 4s/step - dice_coefficient: 0.3826 - loss: 1.5295 - learning_rate: 3.5481e-05\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 3.1622776601683795e-05.\n",
      "Epoch 11/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.3977 - loss: 1.4879\n",
      "Epoch 11: loss improved from 1.51320 to 1.48058, saving model to vgg16_unet_model.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m867s\u001b[0m 4s/step - dice_coefficient: 0.3977 - loss: 1.4879 - learning_rate: 3.1623e-05\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 2.818382931264454e-05.\n",
      "Epoch 12/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.4100 - loss: 1.4623\n",
      "Epoch 12: loss improved from 1.48058 to 1.45184, saving model to vgg16_unet_model.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m839s\u001b[0m 4s/step - dice_coefficient: 0.4100 - loss: 1.4622 - learning_rate: 2.8184e-05\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 2.51188643150958e-05.\n",
      "Epoch 13/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.4157 - loss: 1.4363\n",
      "Epoch 13: loss improved from 1.45184 to 1.43326, saving model to vgg16_unet_model.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m838s\u001b[0m 4s/step - dice_coefficient: 0.4157 - loss: 1.4363 - learning_rate: 2.5119e-05\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 2.2387211385683396e-05.\n",
      "Epoch 14/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.4216 - loss: 1.4363\n",
      "Epoch 14: loss improved from 1.43326 to 1.40154, saving model to vgg16_unet_model.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m838s\u001b[0m 4s/step - dice_coefficient: 0.4217 - loss: 1.4361 - learning_rate: 2.2387e-05\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 1.99526231496888e-05.\n",
      "Epoch 15/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.4454 - loss: 1.3588\n",
      "Epoch 15: loss improved from 1.40154 to 1.37754, saving model to vgg16_unet_model.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m831s\u001b[0m 4s/step - dice_coefficient: 0.4454 - loss: 1.3588 - learning_rate: 1.9953e-05\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 1.778279410038923e-05.\n",
      "Epoch 16/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.4368 - loss: 1.4040\n",
      "Epoch 16: loss did not improve from 1.37754\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m837s\u001b[0m 4s/step - dice_coefficient: 0.4368 - loss: 1.4039 - learning_rate: 1.7783e-05\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 1.5848931924611134e-05.\n",
      "Epoch 17/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.4457 - loss: 1.3673\n",
      "Epoch 17: loss improved from 1.37754 to 1.34177, saving model to vgg16_unet_model.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m835s\u001b[0m 4s/step - dice_coefficient: 0.4457 - loss: 1.3672 - learning_rate: 1.5849e-05\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 1.4125375446227545e-05.\n",
      "Epoch 18/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.4563 - loss: 1.3284\n",
      "Epoch 18: loss improved from 1.34177 to 1.33165, saving model to vgg16_unet_model.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m839s\u001b[0m 4s/step - dice_coefficient: 0.4563 - loss: 1.3284 - learning_rate: 1.4125e-05\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 1.2589254117941673e-05.\n",
      "Epoch 19/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.4592 - loss: 1.3281\n",
      "Epoch 19: loss did not improve from 1.33165\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m836s\u001b[0m 4s/step - dice_coefficient: 0.4592 - loss: 1.3282 - learning_rate: 1.2589e-05\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 1.1220184543019637e-05.\n",
      "Epoch 20/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.4632 - loss: 1.3091\n",
      "Epoch 20: loss improved from 1.33165 to 1.31124, saving model to vgg16_unet_model.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m846s\u001b[0m 4s/step - dice_coefficient: 0.4632 - loss: 1.3091 - learning_rate: 1.1220e-05\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 1e-05.\n",
      "Epoch 21/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.4722 - loss: 1.2895\n",
      "Epoch 21: loss improved from 1.31124 to 1.29567, saving model to vgg16_unet_model.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m858s\u001b[0m 4s/step - dice_coefficient: 0.4722 - loss: 1.2896 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 8.912509381337456e-06.\n",
      "Epoch 22/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.4764 - loss: 1.2809\n",
      "Epoch 22: loss improved from 1.29567 to 1.28631, saving model to vgg16_unet_model.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m857s\u001b[0m 4s/step - dice_coefficient: 0.4764 - loss: 1.2810 - learning_rate: 8.9125e-06\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 7.943282347242815e-06.\n",
      "Epoch 23/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.4733 - loss: 1.2938\n",
      "Epoch 23: loss did not improve from 1.28631\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m862s\u001b[0m 4s/step - dice_coefficient: 0.4733 - loss: 1.2937 - learning_rate: 7.9433e-06\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 7.079457843841382e-06.\n",
      "Epoch 24/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.4759 - loss: 1.2929\n",
      "Epoch 24: loss improved from 1.28631 to 1.28015, saving model to vgg16_unet_model.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m863s\u001b[0m 4s/step - dice_coefficient: 0.4759 - loss: 1.2928 - learning_rate: 7.0795e-06\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 6.309573444801933e-06.\n",
      "Epoch 25/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.4870 - loss: 1.2522\n",
      "Epoch 25: loss improved from 1.28015 to 1.27148, saving model to vgg16_unet_model.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m892s\u001b[0m 4s/step - dice_coefficient: 0.4869 - loss: 1.2523 - learning_rate: 6.3096e-06\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 5.623413251903491e-06.\n",
      "Epoch 26/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.4751 - loss: 1.3013\n",
      "Epoch 26: loss did not improve from 1.27148\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m855s\u001b[0m 4s/step - dice_coefficient: 0.4751 - loss: 1.3013 - learning_rate: 5.6234e-06\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 5.011872336272723e-06.\n",
      "Epoch 27/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.4877 - loss: 1.2511\n",
      "Epoch 27: loss improved from 1.27148 to 1.26933, saving model to vgg16_unet_model.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m853s\u001b[0m 4s/step - dice_coefficient: 0.4877 - loss: 1.2512 - learning_rate: 5.0119e-06\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 4.466835921509631e-06.\n",
      "Epoch 28/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.4883 - loss: 1.2566\n",
      "Epoch 28: loss did not improve from 1.26933\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m849s\u001b[0m 4s/step - dice_coefficient: 0.4883 - loss: 1.2567 - learning_rate: 4.4668e-06\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 3.981071705534973e-06.\n",
      "Epoch 29/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.4831 - loss: 1.2802\n",
      "Epoch 29: loss improved from 1.26933 to 1.25546, saving model to vgg16_unet_model.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m853s\u001b[0m 4s/step - dice_coefficient: 0.4831 - loss: 1.2801 - learning_rate: 3.9811e-06\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 3.5481338923357555e-06.\n",
      "Epoch 30/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.4830 - loss: 1.2730\n",
      "Epoch 30: loss did not improve from 1.25546\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m858s\u001b[0m 4s/step - dice_coefficient: 0.4830 - loss: 1.2730 - learning_rate: 3.5481e-06\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 3.16227766016838e-06.\n",
      "Epoch 31/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.4922 - loss: 1.2283\n",
      "Epoch 31: loss improved from 1.25546 to 1.24610, saving model to vgg16_unet_model.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m840s\u001b[0m 4s/step - dice_coefficient: 0.4922 - loss: 1.2284 - learning_rate: 3.1623e-06\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 2.818382931264454e-06.\n",
      "Epoch 32/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.4823 - loss: 1.2780\n",
      "Epoch 32: loss improved from 1.24610 to 1.23866, saving model to vgg16_unet_model.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m827s\u001b[0m 4s/step - dice_coefficient: 0.4824 - loss: 1.2778 - learning_rate: 2.8184e-06\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 2.5118864315095797e-06.\n",
      "Epoch 33/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.4888 - loss: 1.2491\n",
      "Epoch 33: loss did not improve from 1.23866\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m827s\u001b[0m 4s/step - dice_coefficient: 0.4888 - loss: 1.2492 - learning_rate: 2.5119e-06\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 2.2387211385683405e-06.\n",
      "Epoch 34/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.4847 - loss: 1.2738\n",
      "Epoch 34: loss did not improve from 1.23866\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m835s\u001b[0m 4s/step - dice_coefficient: 0.4847 - loss: 1.2737 - learning_rate: 2.2387e-06\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 1.99526231496888e-06.\n",
      "Epoch 35/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.4967 - loss: 1.2286\n",
      "Epoch 35: loss did not improve from 1.23866\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m837s\u001b[0m 4s/step - dice_coefficient: 0.4967 - loss: 1.2287 - learning_rate: 1.9953e-06\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 1.7782794100389231e-06.\n",
      "Epoch 36/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.4890 - loss: 1.2571\n",
      "Epoch 36: loss did not improve from 1.23866\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m838s\u001b[0m 4s/step - dice_coefficient: 0.4890 - loss: 1.2571 - learning_rate: 1.7783e-06\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 1.5848931924611134e-06.\n",
      "Epoch 37/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.4955 - loss: 1.2275\n",
      "Epoch 37: loss improved from 1.23866 to 1.23725, saving model to vgg16_unet_model.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m840s\u001b[0m 4s/step - dice_coefficient: 0.4955 - loss: 1.2276 - learning_rate: 1.5849e-06\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 1.4125375446227544e-06.\n",
      "Epoch 38/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.4941 - loss: 1.2478\n",
      "Epoch 38: loss did not improve from 1.23725\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m824s\u001b[0m 4s/step - dice_coefficient: 0.4941 - loss: 1.2478 - learning_rate: 1.4125e-06\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 1.2589254117941678e-06.\n",
      "Epoch 39/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.4971 - loss: 1.2292\n",
      "Epoch 39: loss did not improve from 1.23725\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m829s\u001b[0m 4s/step - dice_coefficient: 0.4971 - loss: 1.2293 - learning_rate: 1.2589e-06\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 1.1220184543019637e-06.\n",
      "Epoch 40/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.4948 - loss: 1.2351\n",
      "Epoch 40: loss improved from 1.23725 to 1.23453, saving model to vgg16_unet_model.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m818s\u001b[0m 4s/step - dice_coefficient: 0.4948 - loss: 1.2351 - learning_rate: 1.1220e-06\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 41/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.4977 - loss: 1.2284\n",
      "Epoch 41: loss did not improve from 1.23453\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m816s\u001b[0m 4s/step - dice_coefficient: 0.4977 - loss: 1.2285 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 8.912509381337461e-07.\n",
      "Epoch 42/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.4943 - loss: 1.2459\n",
      "Epoch 42: loss did not improve from 1.23453\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m817s\u001b[0m 4s/step - dice_coefficient: 0.4943 - loss: 1.2460 - learning_rate: 8.9125e-07\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 7.943282347242815e-07.\n",
      "Epoch 43/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.5002 - loss: 1.2124\n",
      "Epoch 43: loss improved from 1.23453 to 1.23154, saving model to vgg16_unet_model.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m818s\u001b[0m 4s/step - dice_coefficient: 0.5002 - loss: 1.2125 - learning_rate: 7.9433e-07\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 7.079457843841381e-07.\n",
      "Epoch 44/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.4963 - loss: 1.2291\n",
      "Epoch 44: loss did not improve from 1.23154\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m816s\u001b[0m 4s/step - dice_coefficient: 0.4963 - loss: 1.2292 - learning_rate: 7.0795e-07\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 6.309573444801931e-07.\n",
      "Epoch 45/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.4961 - loss: 1.2390\n",
      "Epoch 45: loss did not improve from 1.23154\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m825s\u001b[0m 4s/step - dice_coefficient: 0.4961 - loss: 1.2389 - learning_rate: 6.3096e-07\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 5.623413251903492e-07.\n",
      "Epoch 46/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.4914 - loss: 1.2597\n",
      "Epoch 46: loss did not improve from 1.23154\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m824s\u001b[0m 4s/step - dice_coefficient: 0.4914 - loss: 1.2596 - learning_rate: 5.6234e-07\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 5.011872336272726e-07.\n",
      "Epoch 47/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.5012 - loss: 1.2218\n",
      "Epoch 47: loss did not improve from 1.23154\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m826s\u001b[0m 4s/step - dice_coefficient: 0.5012 - loss: 1.2218 - learning_rate: 5.0119e-07\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 4.4668359215096306e-07.\n",
      "Epoch 48/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.4973 - loss: 1.2422\n",
      "Epoch 48: loss did not improve from 1.23154\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m817s\u001b[0m 4s/step - dice_coefficient: 0.4973 - loss: 1.2422 - learning_rate: 4.4668e-07\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 3.9810717055349745e-07.\n",
      "Epoch 49/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.4969 - loss: 1.2323\n",
      "Epoch 49: loss improved from 1.23154 to 1.22422, saving model to vgg16_unet_model.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m826s\u001b[0m 4s/step - dice_coefficient: 0.4969 - loss: 1.2322 - learning_rate: 3.9811e-07\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 3.5481338923357537e-07.\n",
      "Epoch 50/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.4965 - loss: 1.2383\n",
      "Epoch 50: loss did not improve from 1.22422\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m816s\u001b[0m 4s/step - dice_coefficient: 0.4965 - loss: 1.2384 - learning_rate: 3.5481e-07\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 3.1622776601683797e-07.\n",
      "Epoch 51/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.4971 - loss: 1.2384\n",
      "Epoch 51: loss did not improve from 1.22422\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m819s\u001b[0m 4s/step - dice_coefficient: 0.4971 - loss: 1.2384 - learning_rate: 3.1623e-07\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 2.8183829312644554e-07.\n",
      "Epoch 52/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.4957 - loss: 1.2434\n",
      "Epoch 52: loss did not improve from 1.22422\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m827s\u001b[0m 4s/step - dice_coefficient: 0.4957 - loss: 1.2433 - learning_rate: 2.8184e-07\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 2.51188643150958e-07.\n",
      "Epoch 53/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.5039 - loss: 1.2125\n",
      "Epoch 53: loss improved from 1.22422 to 1.21351, saving model to vgg16_unet_model.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m826s\u001b[0m 4s/step - dice_coefficient: 0.5039 - loss: 1.2125 - learning_rate: 2.5119e-07\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 2.2387211385683404e-07.\n",
      "Epoch 54/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.5008 - loss: 1.2287\n",
      "Epoch 54: loss did not improve from 1.21351\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m816s\u001b[0m 4s/step - dice_coefficient: 0.5008 - loss: 1.2286 - learning_rate: 2.2387e-07\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 1.995262314968879e-07.\n",
      "Epoch 55/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.4967 - loss: 1.2359\n",
      "Epoch 55: loss did not improve from 1.21351\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m816s\u001b[0m 4s/step - dice_coefficient: 0.4967 - loss: 1.2359 - learning_rate: 1.9953e-07\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 1.778279410038923e-07.\n",
      "Epoch 56/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.4970 - loss: 1.2440\n",
      "Epoch 56: loss did not improve from 1.21351\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m817s\u001b[0m 4s/step - dice_coefficient: 0.4970 - loss: 1.2440 - learning_rate: 1.7783e-07\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 1.5848931924611143e-07.\n",
      "Epoch 57/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.4991 - loss: 1.2199\n",
      "Epoch 57: loss did not improve from 1.21351\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m817s\u001b[0m 4s/step - dice_coefficient: 0.4991 - loss: 1.2200 - learning_rate: 1.5849e-07\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 1.4125375446227541e-07.\n",
      "Epoch 58/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.4974 - loss: 1.2242\n",
      "Epoch 58: loss did not improve from 1.21351\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m819s\u001b[0m 4s/step - dice_coefficient: 0.4974 - loss: 1.2242 - learning_rate: 1.4125e-07\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 1.2589254117941678e-07.\n",
      "Epoch 59/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.5008 - loss: 1.2099\n",
      "Epoch 59: loss did not improve from 1.21351\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m828s\u001b[0m 4s/step - dice_coefficient: 0.5008 - loss: 1.2100 - learning_rate: 1.2589e-07\n",
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 53.\n",
      "Epoch times saved to '/home/pranav/DeepLearning/mobilenettimes.txt'.\n"
     ]
    }
   ],
   "source": [
    "steps_per_epoch=200\n",
    "history = vgg16_unet.fit(\n",
    "    TrainAugmentGenerator(train_images_dir = train_images, train_masks_dir = train_masks,batch_sizess=8, target_sizess = (512, 512)), \n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs = 100,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "192bed48-6c98-466a-94c2-671b8c7c5952",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T07:44:10.864283Z",
     "iopub.status.busy": "2024-11-15T07:44:10.864059Z",
     "iopub.status.idle": "2024-11-15T07:44:11.294617Z",
     "shell.execute_reply": "2024-11-15T07:44:11.294044Z"
    }
   },
   "outputs": [],
   "source": [
    "vgg16_unet.save('/home/pranav/DeepLearning/100epochswithouttraining/mobilenet.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1b34d8e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T07:44:11.296781Z",
     "iopub.status.busy": "2024-11-15T07:44:11.296547Z",
     "iopub.status.idle": "2024-11-15T07:44:11.299830Z",
     "shell.execute_reply": "2024-11-15T07:44:11.299397Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('/home/pranav/DeepLearning/100epochswithouttraining/trainHistoryMobileNetDict', 'wb') as file_pi:\n",
    "    pickle.dump(history.history, file_pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bca4c8",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(30, 5))\n",
    "ax = ax.ravel()\n",
    "metrics = ['Dice Coefficient', 'Loss', 'Learning Rate']\n",
    "\n",
    "for i, met in enumerate(['dice_coefficient','loss','learning_rate']): \n",
    "    if met != 'lr':\n",
    "        ax[i].plot(history.history[met], 'o-')\n",
    "        #ax[i].plot(history.history['val_' + met], 'o-')\n",
    "        ax[i].set_title('{} vs Epochs'.format(metrics[i]), fontsize=16)\n",
    "        ax[i].set_xlabel('Epochs')\n",
    "        ax[i].set_ylabel(metrics[i])\n",
    "        ax[i].set_xticks(np.arange(1,3,2))\n",
    "        ax[i].legend(['Train', 'Validation'])\n",
    "        ax[i].xaxis.grid(True, color = \"lightgray\", linewidth = \"0.8\", linestyle = \"-\")\n",
    "        ax[i].yaxis.grid(True, color = \"lightgray\", linewidth = \"0.8\", linestyle = \"-\")\n",
    "    else:\n",
    "        ax[i].plot(history.history[met], 'o-')\n",
    "        ax[i].set_title('{} vs Epochs'.format(metrics[i]), fontsize=16)\n",
    "        ax[i].set_xlabel('Epochs')\n",
    "        ax[i].set_ylabel(metrics[i])\n",
    "        ax[i].set_xticks(np.arange(1,3,2))\n",
    "        ax[i].xaxis.grid(True, color = \"lightgray\", linewidth = \"0.8\", linestyle = \"-\")\n",
    "        ax[i].yaxis.grid(True, color = \"lightgray\", linewidth = \"0.8\", linestyle = \"-\")\n",
    "        \n",
    "plt.savefig('model_metrics_plot.png', facecolor= 'w',transparent= False, bbox_inches= 'tight', dpi= 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ace43565",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T07:44:11.301688Z",
     "iopub.status.busy": "2024-11-15T07:44:11.301537Z",
     "iopub.status.idle": "2024-11-15T07:44:11.303614Z",
     "shell.execute_reply": "2024-11-15T07:44:11.303183Z"
    }
   },
   "outputs": [],
   "source": [
    "#vgg16_unet.load_weights(\"./vgg16_unet_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d0e41c85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T07:44:11.305268Z",
     "iopub.status.busy": "2024-11-15T07:44:11.305051Z",
     "iopub.status.idle": "2024-11-15T07:44:11.307740Z",
     "shell.execute_reply": "2024-11-15T07:44:11.307316Z"
    }
   },
   "outputs": [],
   "source": [
    "# testing_gen = ValAugmentGenerator(val_images_dr = val_images, masksvaldr = masksval, target_sizess = (512, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bbd8f1a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T07:44:11.309348Z",
     "iopub.status.busy": "2024-11-15T07:44:11.309203Z",
     "iopub.status.idle": "2024-11-15T07:44:11.312469Z",
     "shell.execute_reply": "2024-11-15T07:44:11.312046Z"
    }
   },
   "outputs": [],
   "source": [
    "# batch_img,batch_mask = ( \"C:/Users/prana/Deep Learning - Segmentation/val_train_images/another/aug_1_000.jpg\"  ,\"C:/Users/prana/Deep Learning - Segmentation/masksvalimages/another/aug_1_000.png\" )\n",
    "# image_path = \"C:/Users/prana/Deep Learning - Segmentation/val_train_images/another/aug_1_001.jpg\" \n",
    "# img = cv2.imread(image_path)\n",
    "\n",
    "# # Step 2: Resize and preprocess the image\n",
    "# input_shape = (512, 512)  # Example input size for your model\n",
    "# img_resized = cv2.resize(img, input_shape)\n",
    "# img_normalized = img_resized / 255.0  # Normalize to [0, 1]\n",
    "# img_batch = np.expand_dims(img_normalized, axis=0)  # Add batch dimension\n",
    "\n",
    "# image_path = \"C:/Users/prana/Deep Learning - Segmentation/masksvalimages/another/aug_1_001.png\"\n",
    "# img = cv2.imread(image_path)\n",
    "\n",
    "# # Step 2: Resize and preprocess the image\n",
    "# input_shape = (512, 512)  # Example input size for your model\n",
    "# img_resized = cv2.resize(img, input_shape)\n",
    "# img_normalized = img_resized / 255.0  # Normalize to [0, 1]\n",
    "# img_mask = np.expand_dims(img_normalized, axis=0)  # Add batch dimension\n",
    "\n",
    "# print(img_batch.shape)\n",
    "\n",
    "# pred_all= vgg16_unet.predict(img_batch)\n",
    "# np.shape(pred_all)\n",
    "    \n",
    "\n",
    "# fig = plt.figure(figsize=(20,8))\n",
    "\n",
    "# ax1 = fig.add_subplot(1,3,1)\n",
    "# ax1.imshow(np.squeeze(img_batch))\n",
    "# ax1.title.set_text('Original Image')\n",
    "# ax1.grid(False)\n",
    "\n",
    "# ax2 = fig.add_subplot(1,3,2)\n",
    "# ax2.set_title('Ground Truth Mask')\n",
    "# img_mask=np.squeeze(img_mask)\n",
    "# ax2.imshow(onehot_to_rgb(img_mask,id2code))\n",
    "# ax2.grid(False)\n",
    "\n",
    "# ax3 = fig.add_subplot(1,3,3)\n",
    "# ax3.set_title('Predicted Mask')\n",
    "# pred_all=np.squeeze(pred_all)           \n",
    "# ax3.imshow(onehot_to_rgb(pred_all,id2code))\n",
    "# ax3.grid(False)\n",
    "\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d2b3db75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T07:44:11.314121Z",
     "iopub.status.busy": "2024-11-15T07:44:11.313871Z",
     "iopub.status.idle": "2024-11-15T07:44:11.316471Z",
     "shell.execute_reply": "2024-11-15T07:44:11.316055Z"
    }
   },
   "outputs": [],
   "source": [
    "# !zip -r predictions.zip './predictions/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15031d1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
