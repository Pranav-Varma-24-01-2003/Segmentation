{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c862a332",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T07:29:27.764846Z",
     "iopub.status.busy": "2024-11-15T07:29:27.764434Z",
     "iopub.status.idle": "2024-11-15T07:29:28.432043Z",
     "shell.execute_reply": "2024-11-15T07:29:28.431460Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pranav/.local/lib/python3.10/site-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import albumentations as A\n",
    "# with open(\"/home/pranav/DeepLearning/new.txt\",\"w\") as wr:\n",
    "#     wr.write(\"Completed first cell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f9d1d76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T07:29:28.434339Z",
     "iopub.status.busy": "2024-11-15T07:29:28.433872Z",
     "iopub.status.idle": "2024-11-15T07:29:28.764865Z",
     "shell.execute_reply": "2024-11-15T07:29:28.764145Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import random\n",
    "import albumentations as A\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "# with open(\"/home/pranav/DeepLearning/new.txt\",\"a\") as wr:\n",
    "#     wr.write(\"The second\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a8fa630",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T07:29:28.767565Z",
     "iopub.status.busy": "2024-11-15T07:29:28.766992Z",
     "iopub.status.idle": "2024-11-15T07:29:28.773685Z",
     "shell.execute_reply": "2024-11-15T07:29:28.773190Z"
    }
   },
   "outputs": [],
   "source": [
    "transform = A.Compose([\n",
    "    A.RandomCrop(width=4500, height=3000, p=1.0),\n",
    "    A.HorizontalFlip(p=1.0),\n",
    "    A.VerticalFlip(p=1.0),\n",
    "    A.Rotate(limit=[60, 240], p=1.0, interpolation=cv2.INTER_NEAREST),\n",
    "    A.RandomBrightnessContrast(brightness_limit=[-0.2, 0.4], contrast_limit=0.2, p=1.0),\n",
    "    A.OneOf([\n",
    "        A.CLAHE (clip_limit=2.0, tile_grid_size=(8, 8), p=0.5),\n",
    "        A.GridDistortion(p=0.5),\n",
    "        A.OpticalDistortion(distort_limit=1, shift_limit=0.5, interpolation=cv2.INTER_NEAREST, p=0.5),\n",
    "    ], p=1.0),\n",
    "], p=1.0)\n",
    "# with open(\"/home/pranav/DeepLearning/new.txt\",\"a\") as wr:\n",
    "#     wr.write(\"The third\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a111cc1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T07:29:28.775467Z",
     "iopub.status.busy": "2024-11-15T07:29:28.775219Z",
     "iopub.status.idle": "2024-11-15T07:29:28.781289Z",
     "shell.execute_reply": "2024-11-15T07:29:28.780853Z"
    }
   },
   "outputs": [],
   "source": [
    "def visualize(image, mask, original_image=None, original_mask=None):\n",
    "    fontsize = 16\n",
    "\n",
    "    if original_image is None and original_mask is None:\n",
    "        f, ax = plt.subplots(2, 1, figsize=(16, 16), squeeze=True)\n",
    "        f.set_tight_layout(h_pad=5, w_pad=5)\n",
    "\n",
    "        ax[0].imshow(image)\n",
    "        ax[1].imshow(mask)\n",
    "    else:\n",
    "        f, ax = plt.subplots(2, 2, figsize=(16, 16), squeeze=True)\n",
    "        plt.tight_layout(pad=0.2, w_pad=1.0, h_pad=0.01)\n",
    "\n",
    "        ax[0, 0].imshow(original_image)\n",
    "        ax[0, 0].set_title('Original Image', fontsize=fontsize)\n",
    "\n",
    "        ax[1, 0].imshow(original_mask)\n",
    "        ax[1, 0].set_title('Original Mask', fontsize=fontsize)\n",
    "\n",
    "        ax[0, 1].imshow(image)\n",
    "        ax[0, 1].set_title('Transformed Image', fontsize=fontsize)\n",
    "\n",
    "        ax[1, 1].imshow(mask)\n",
    "        ax[1, 1].set_title('Transformed Mask', fontsize=fontsize)\n",
    "        \n",
    "    plt.savefig('sample_augmented_image.png', facecolor= 'w', transparent= False, bbox_inches= 'tight', dpi= 100)\n",
    "# with open(\"/home/pranav/DeepLearning/new.txt\",\"a\") as wr:\n",
    "#     wr.write(\"The fourth\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d29385de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T07:29:28.783175Z",
     "iopub.status.busy": "2024-11-15T07:29:28.782904Z",
     "iopub.status.idle": "2024-11-15T07:29:28.785344Z",
     "shell.execute_reply": "2024-11-15T07:29:28.784926Z"
    }
   },
   "outputs": [],
   "source": [
    "# image = cv2.imread(\"/home/pranav/DeepLearning/semantic_drone_dataset/training_set/images/040.jpg\")\n",
    "# image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "# mask = cv2.imread(\"/home/pranav/DeepLearning/semantic_drone_dataset/training_set/gt/semantic/label_images/040.png\")\n",
    "# mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB\n",
    "#                    )\n",
    "\n",
    "# transformed = transform(image=image, mask=mask)\n",
    "# transformed_image = transformed['image']\n",
    "# transformed_mask = transformed['mask']\n",
    "\n",
    "# cv2.imwrite('./image.png',cv2.cvtColor(transformed_image, cv2.COLOR_BGR2RGB))\n",
    "# cv2.imwrite('./mask.png',cv2.cvtColor(transformed_mask, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "# visualize(transformed_image, transformed_mask, image, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1164e557",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T07:29:28.786954Z",
     "iopub.status.busy": "2024-11-15T07:29:28.786708Z",
     "iopub.status.idle": "2024-11-15T07:29:28.789041Z",
     "shell.execute_reply": "2024-11-15T07:29:28.788628Z"
    }
   },
   "outputs": [],
   "source": [
    "images_dir = '/home/pranav/DeepLearning/train_images'\n",
    "masks_dir = '/home/pranav/DeepLearning/train_masks'\n",
    "# val_images = 'C:/Users/prana/Deep Learning - Segmentation/val_train_images'\n",
    "# masksval = \"C:/Users/prana/Deep Learning - Segmentation/masksvalimages\"\n",
    "# with open(\"/home/pranav/DeepLearning/new.txt\",\"a\") as wr:\n",
    "#     wr.write(\"The third\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8325568",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T07:29:28.790609Z",
     "iopub.status.busy": "2024-11-15T07:29:28.790388Z",
     "iopub.status.idle": "2024-11-15T07:29:28.792659Z",
     "shell.execute_reply": "2024-11-15T07:29:28.792228Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f54275a4-181a-4c95-8525-b3626e679e07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T07:29:28.794238Z",
     "iopub.status.busy": "2024-11-15T07:29:28.794093Z",
     "iopub.status.idle": "2024-11-15T07:29:28.799377Z",
     "shell.execute_reply": "2024-11-15T07:29:28.798914Z"
    }
   },
   "outputs": [],
   "source": [
    "file_names = np.sort(os.listdir(\"/home/pranav/DeepLearning/semantic_drone_dataset/training_set/images\")) \n",
    "file_names = np.char.split(file_names, '.')\n",
    "filenames = np.array([])\n",
    "for i in range(len(file_names)):\n",
    "    filenames = np.append(filenames, file_names[i][0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77a3be44-b1d6-416b-bd47-0f1f20889777",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T07:29:28.801172Z",
     "iopub.status.busy": "2024-11-15T07:29:28.801025Z",
     "iopub.status.idle": "2024-11-15T07:29:28.806450Z",
     "shell.execute_reply": "2024-11-15T07:29:28.805923Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000' '001' '002' '003' '004' '005' '006' '008' '011' '013' '014' '015'\n",
      " '016' '018' '019' '021' '022' '023' '026' '028' '031' '035' '038' '040'\n",
      " '041' '042' '043' '044' '045' '047' '049' '051' '052' '053' '055' '056'\n",
      " '057' '058' '059' '060' '062' '063' '065' '068' '070' '071' '073' '074'\n",
      " '075' '077' '078' '079' '080' '081' '083' '086' '088' '089' '092' '095'\n",
      " '098' '099' '100' '101' '102' '103' '104' '106' '107' '109' '110' '111'\n",
      " '112' '113' '116' '117' '118' '119' '120' '121' '122' '123' '124' '126'\n",
      " '128' '130' '133' '134' '135' '136' '137' '138' '139' '140' '141' '145'\n",
      " '146' '147' '148' '149' '150' '153' '154' '155' '156' '157' '158' '159'\n",
      " '160' '161' '162' '163' '164' '165' '166' '167' '170' '171' '172' '173'\n",
      " '174' '175' '176' '177' '178' '179' '180' '181' '182' '185' '186' '188'\n",
      " '190' '192' '193' '194' '195' '198' '199' '200' '202' '204' '206' '207'\n",
      " '208' '209' '213' '214' '215' '216' '217' '219' '220' '221' '222' '223'\n",
      " '225' '226' '228' '229' '230' '232' '233' '234' '235' '236' '237' '238'\n",
      " '239' '240' '243' '244' '246' '248' '250' '251' '252' '255' '257' '258'\n",
      " '259' '260' '261' '262' '263' '265' '266' '271' '272' '273' '275' '276'\n",
      " '277' '281' '283' '287' '288' '289' '290' '292' '294' '295' '296' '298'\n",
      " '299' '301' '302' '303' '304' '305' '306' '309' '310' '311' '312' '313'\n",
      " '314' '316' '318' '320' '321' '322' '323' '324' '325' '326' '329' '330'\n",
      " '331' '332' '334' '335' '338' '339' '341' '342' '344' '345' '346' '347'\n",
      " '348' '349' '351' '355' '356' '361' '363' '366' '367' '372' '373' '375'\n",
      " '376' '378' '380' '381' '382' '383' '385' '386' '388' '389' '390' '391'\n",
      " '393' '397' '398' '403' '406' '408' '409' '410' '411' '412' '413' '414'\n",
      " '416' '419' '420' '421' '423' '424' '425' '426' '427' '428' '429' '430'\n",
      " '431' '433' '434' '435' '437' '438' '439' '440' '442' '443' '444' '445'\n",
      " '446' '447' '451' '452' '454' '455' '457' '458' '460' '461' '462' '463'\n",
      " '464' '465' '467' '470' '472' '473' '474' '475' '476' '478' '479' '480'\n",
      " '484' '485' '488' '489' '491' '493' '494' '497' '498' '499' '500' '501'\n",
      " '502' '507' '508' '509' '510' '512' '513' '514' '515' '517' '518' '521'\n",
      " '524' '525' '526' '529' '530' '531' '532' '533' '535' '536' '537' '538'\n",
      " '540' '543' '544' '545' '549' '551' '554' '556' '558' '559' '560' '561'\n",
      " '563' '564' '565' '566' '567' '568' '569' '570' '572' '573' '574' '576'\n",
      " '579' '580' '582' '583' '584' '585' '586' '587' '588' '590' '591' '592'\n",
      " '593' '594' '596' '598']\n",
      "000\n",
      "001\n",
      "002\n",
      "003\n",
      "004\n",
      "005\n",
      "006\n",
      "008\n",
      "011\n",
      "013\n",
      "014\n",
      "015\n",
      "016\n",
      "018\n",
      "019\n",
      "021\n",
      "022\n",
      "023\n",
      "026\n",
      "028\n",
      "031\n",
      "035\n",
      "038\n",
      "040\n",
      "041\n",
      "042\n",
      "043\n",
      "044\n",
      "045\n",
      "047\n",
      "049\n",
      "051\n",
      "052\n",
      "053\n",
      "055\n",
      "056\n",
      "057\n",
      "058\n",
      "059\n",
      "060\n",
      "062\n",
      "063\n",
      "065\n",
      "068\n",
      "070\n",
      "071\n",
      "073\n",
      "074\n",
      "075\n",
      "077\n",
      "078\n",
      "079\n",
      "080\n",
      "081\n",
      "083\n",
      "086\n",
      "088\n",
      "089\n",
      "092\n",
      "095\n",
      "098\n",
      "099\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "106\n",
      "107\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "126\n",
      "128\n",
      "130\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "185\n",
      "186\n",
      "188\n",
      "190\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "198\n",
      "199\n",
      "200\n",
      "202\n",
      "204\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "225\n",
      "226\n",
      "228\n",
      "229\n",
      "230\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "243\n",
      "244\n",
      "246\n",
      "248\n",
      "250\n",
      "251\n",
      "252\n",
      "255\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "265\n",
      "266\n",
      "271\n",
      "272\n",
      "273\n",
      "275\n",
      "276\n",
      "277\n",
      "281\n",
      "283\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "292\n",
      "294\n",
      "295\n",
      "296\n",
      "298\n",
      "299\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "316\n",
      "318\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "334\n",
      "335\n",
      "338\n",
      "339\n",
      "341\n",
      "342\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "351\n",
      "355\n",
      "356\n",
      "361\n",
      "363\n",
      "366\n",
      "367\n",
      "372\n",
      "373\n",
      "375\n",
      "376\n",
      "378\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "385\n",
      "386\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "393\n",
      "397\n",
      "398\n",
      "403\n",
      "406\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "416\n",
      "419\n",
      "420\n",
      "421\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "433\n",
      "434\n",
      "435\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "451\n",
      "452\n",
      "454\n",
      "455\n",
      "457\n",
      "458\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "467\n",
      "470\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "478\n",
      "479\n",
      "480\n",
      "484\n",
      "485\n",
      "488\n",
      "489\n",
      "491\n",
      "493\n",
      "494\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "517\n",
      "518\n",
      "521\n",
      "524\n",
      "525\n",
      "526\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "540\n",
      "543\n",
      "544\n",
      "545\n",
      "549\n",
      "551\n",
      "554\n",
      "556\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "572\n",
      "573\n",
      "574\n",
      "576\n",
      "579\n",
      "580\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "596\n",
      "598\n"
     ]
    }
   ],
   "source": [
    "print(filenames)\n",
    "for file in filenames:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4f76120",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T07:29:28.808414Z",
     "iopub.status.busy": "2024-11-15T07:29:28.808190Z",
     "iopub.status.idle": "2024-11-15T07:29:28.812636Z",
     "shell.execute_reply": "2024-11-15T07:29:28.812190Z"
    }
   },
   "outputs": [],
   "source": [
    "def augment_dataset(count):\n",
    "    '''Function for data augmentation\n",
    "        Input:\n",
    "            count - total no. of images after augmentation = initial no. of images * count\n",
    "        Output:\n",
    "            writes augmented images (input images & segmentation masks) to the working directory\n",
    "    '''\n",
    "    i = 0\n",
    "    for i in range(count):\n",
    "        for file in filenames:\n",
    "            img = cv2.imread(\"/home/pranav/DeepLearning/semantic_drone_dataset/training_set/images/\"+file+'.jpg')\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            mask = cv2.imread(\"/home/pranav/DeepLearning/semantic_drone_dataset/training_set/gt/semantic/label_images/\"+file+'.png')\n",
    "            mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
    "            transformed = transform(image=img, mask=mask)\n",
    "            transformed_image = transformed['image']\n",
    "            transformed_mask = transformed['mask']\n",
    "\n",
    "            cv2.imwrite('/home/pranav/DeepLearning/train_images/aug_images/aug_{}_'.format(str(i+1))+file+'.jpg',cv2.cvtColor(transformed_image, cv2.COLOR_BGR2RGB))\n",
    "            cv2.imwrite('/home/pranav/DeepLearning/train_masks/aug_masks/aug_{}_'.format(str(i+1))+file+'.png',cv2.cvtColor(transformed_mask, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10e91429",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T07:29:28.814261Z",
     "iopub.status.busy": "2024-11-15T07:29:28.814039Z",
     "iopub.status.idle": "2024-11-15T07:29:28.816127Z",
     "shell.execute_reply": "2024-11-15T07:29:28.815703Z"
    }
   },
   "outputs": [],
   "source": [
    "# !mkdir aug_images\n",
    "# !mkdir aug_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e748a763",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T07:29:28.817749Z",
     "iopub.status.busy": "2024-11-15T07:29:28.817518Z",
     "iopub.status.idle": "2024-11-15T07:29:28.819856Z",
     "shell.execute_reply": "2024-11-15T07:29:28.819424Z"
    }
   },
   "outputs": [],
   "source": [
    "#augment_dataset(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75a903c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T07:29:28.821450Z",
     "iopub.status.busy": "2024-11-15T07:29:28.821308Z",
     "iopub.status.idle": "2024-11-15T07:29:28.823254Z",
     "shell.execute_reply": "2024-11-15T07:29:28.822839Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install keract\n",
    "# import keract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46922be1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T07:29:28.824854Z",
     "iopub.status.busy": "2024-11-15T07:29:28.824626Z",
     "iopub.status.idle": "2024-11-15T07:29:30.781931Z",
     "shell.execute_reply": "2024-11-15T07:29:30.781271Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-15 12:59:29.175764: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1731655769.196017  612444 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1731655769.202089  612444 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-15 12:59:29.222475: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import keract\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85e0ce88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T07:29:30.785001Z",
     "iopub.status.busy": "2024-11-15T07:29:30.784374Z",
     "iopub.status.idle": "2024-11-15T07:29:30.797432Z",
     "shell.execute_reply": "2024-11-15T07:29:30.796938Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from IPython.display import SVG\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os, re, sys, random, shutil, cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import applications, optimizers\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.utils import model_to_dot, plot_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, CSVLogger, LearningRateScheduler, TensorBoard\n",
    "from tensorflow.keras.layers import Input, Lambda, Activation, Conv2D, MaxPooling2D, BatchNormalization, Add, concatenate, Conv2DTranspose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb4900b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T07:29:30.799317Z",
     "iopub.status.busy": "2024-11-15T07:29:30.799087Z",
     "iopub.status.idle": "2024-11-15T07:29:30.801964Z",
     "shell.execute_reply": "2024-11-15T07:29:30.801552Z"
    }
   },
   "outputs": [],
   "source": [
    "train_images = '/home/pranav/DeepLearning/train_images'\n",
    "train_masks = '/home/pranav/DeepLearning/train_masks'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c39ce3b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T07:29:30.803591Z",
     "iopub.status.busy": "2024-11-15T07:29:30.803346Z",
     "iopub.status.idle": "2024-11-15T07:29:30.809458Z",
     "shell.execute_reply": "2024-11-15T07:29:30.809030Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aug_1_000' 'aug_1_001' 'aug_1_002' 'aug_1_003' 'aug_1_004']\n"
     ]
    }
   ],
   "source": [
    "file_names = np.sort(os.listdir(train_images+\"/aug_images\")) \n",
    "file_names = np.char.split(file_names, '.')\n",
    "filenames = np.array([])\n",
    "for i in range(len(file_names[:5])):\n",
    "    filenames = np.append(filenames, file_names[i][0])\n",
    "print(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc4c7053",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T07:29:30.811162Z",
     "iopub.status.busy": "2024-11-15T07:29:30.810907Z",
     "iopub.status.idle": "2024-11-15T07:29:30.813919Z",
     "shell.execute_reply": "2024-11-15T07:29:30.813503Z"
    }
   },
   "outputs": [],
   "source": [
    "# def show_data(files, original_images_dir, label_images_dir):\n",
    "\n",
    "#     for file in files:\n",
    "#         fig, axs = plt.subplots(1, 2, figsize=(20, 10), constrained_layout=True)\n",
    "\n",
    "#         axs[0].imshow(Image.open(original_images_dir+\"/aug_images/\"+str(file)+'.jpg'))\n",
    "#         axs[0].set_title('Original Image', fontdict = {'fontsize':20})\n",
    "#         axs[0].set_xticks(np.arange(0, 6500, 1000))\n",
    "#         axs[0].set_yticks(np.arange(0, 4500, 1000))\n",
    "#         axs[0].grid(False)\n",
    "#         axs[0].axis(True)\n",
    "\n",
    "#         semantic_label_image = Image.open(label_images_dir+\"/aug_masks/\"+str(file)+'.png')\n",
    "#         semantic_label_image = np.asarray(semantic_label_image)\n",
    "#         axs[1].imshow(semantic_label_image)\n",
    "#         axs[1].set_title('Semantic Segmentation Mask', fontdict = {'fontsize':20})\n",
    "#         axs[1].set_xticks(np.arange(0, 6500, 1000))\n",
    "#         axs[1].set_yticks(np.arange(0, 4500, 1000))\n",
    "#         axs[1].grid(False)\n",
    "#         axs[1].axis(True)\n",
    "\n",
    "#         plt.savefig('image_'+file, facecolor= 'w', transparent= False, bbox_inches= 'tight', dpi= 100)\n",
    "#         plt.show()\n",
    "    \n",
    "# show_data(filenames[:5], train_images, train_masks)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "77b01405",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T07:29:30.815551Z",
     "iopub.status.busy": "2024-11-15T07:29:30.815306Z",
     "iopub.status.idle": "2024-11-15T07:29:30.823834Z",
     "shell.execute_reply": "2024-11-15T07:29:30.823418Z"
    }
   },
   "outputs": [],
   "source": [
    "augmented_files = ['092','118', '228', '277', '376']\n",
    "\n",
    "def show_augmented_images(files, original_images_dir):\n",
    "    for file in files:\n",
    "        fig, axs = plt.subplots(1, 5, figsize=(30, 6), constrained_layout=True)\n",
    "        for i in range(5):\n",
    "            if i == 0:\n",
    "                axs[i].imshow(Image.open(original_images_dir+str(file)+'.jpg'))\n",
    "                axs[i].set_title('Original Image: {}.jpg'.format(file), fontdict = {'fontsize':20})\n",
    "                axs[i].set_xticks(np.arange(0, 6500, 1000))\n",
    "                axs[i].set_yticks(np.arange(0, 4500, 1000))\n",
    "                axs[i].grid(False)\n",
    "                axs[i].axis(True)\n",
    "            else:\n",
    "                axs[i].imshow(Image.open(\"C:/Users/prana/Deep Learning - Segmentation/aug_images/\"+'aug_'+str(i)+'_'+str(file)+'.jpg'))\n",
    "                axs[i].set_title('Augmented Image: aug_'+str(i)+'_'+str(file)+'.jpg', fontdict = {'fontsize':20})\n",
    "                axs[i].set_xticks(np.arange(0, 4500, 1000))\n",
    "                axs[i].set_yticks(np.arange(0, 3001, 1000))\n",
    "                axs[i].grid(False)\n",
    "                axs[i].axis(True)\n",
    "\n",
    "        plt.savefig('aug_image_'+file, facecolor= 'w', transparent= False, bbox_inches= 'tight', dpi= 100)\n",
    "        plt.show()\n",
    "    \n",
    "def show_augmented_masks(files, label_images_dir):\n",
    "    for file in files:\n",
    "        fig, axs = plt.subplots(1, 5, figsize=(30, 6), constrained_layout=True)\n",
    "        for i in range(5):\n",
    "            if i == 0:\n",
    "                axs[i].imshow(Image.open(label_images_dir+str(file)+'.png'))\n",
    "                axs[i].set_title('Original Mask: {}.png'.format(file), fontdict = {'fontsize':20})\n",
    "                axs[i].set_xticks(np.arange(0, 6500, 1000))\n",
    "                axs[i].set_yticks(np.arange(0, 4500, 1000))\n",
    "                axs[i].grid(False)\n",
    "                axs[i].axis(True)\n",
    "            else:\n",
    "                axs[i].imshow(Image.open(\"C:/Users/prana/Deep Learning - Segmentation/aug_masks/\"+\"aug_\"+str(i)+'_'+str(file)+'.png'))\n",
    "                axs[i].set_title('Augmented Mask: aug_'+str(i)+'_'+str(file)+'.png', fontdict = {'fontsize':20})\n",
    "                axs[i].set_xticks(np.arange(0, 4500, 1000))\n",
    "                axs[i].set_yticks(np.arange(0, 3001, 1000))\n",
    "                axs[i].grid(False)\n",
    "                axs[i].axis(True)\n",
    "\n",
    "        plt.savefig('aug_mask_'+file, facecolor= 'w', transparent= False, bbox_inches= 'tight', dpi= 100)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8150d615",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T07:29:30.825517Z",
     "iopub.status.busy": "2024-11-15T07:29:30.825264Z",
     "iopub.status.idle": "2024-11-15T07:29:30.827976Z",
     "shell.execute_reply": "2024-11-15T07:29:30.827568Z"
    }
   },
   "outputs": [],
   "source": [
    "# show_augmented_images(augmented_files, train_images)\n",
    "# show_augmented_masks(augmented_files, train_masks)\n",
    "# print(train_images)\n",
    "# print(train_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8eac3e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T07:29:30.829640Z",
     "iopub.status.busy": "2024-11-15T07:29:30.829388Z",
     "iopub.status.idle": "2024-11-15T07:29:30.836141Z",
     "shell.execute_reply": "2024-11-15T07:29:30.835724Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       unlabeled\n",
      "1      paved-area\n",
      "2            dirt\n",
      "3           grass\n",
      "4          gravel\n",
      "5           water\n",
      "6           rocks\n",
      "7            pool\n",
      "8      vegetation\n",
      "9            roof\n",
      "10           wall\n",
      "11         window\n",
      "12           door\n",
      "13          fence\n",
      "14     fence-pole\n",
      "15         person\n",
      "16            dog\n",
      "17            car\n",
      "18        bicycle\n",
      "19           tree\n",
      "20      bald-tree\n",
      "21      ar-marker\n",
      "22       obstacle\n",
      "23    conflicting\n",
      "Name: name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "class_dict_df = pd.read_csv(\"/home/pranav/DeepLearning/semantic_drone_dataset/training_set/gt/semantic/class_dict.csv\", index_col=False, skipinitialspace=True)\n",
    "print(class_dict_df[\"name\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6244d9b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T07:29:30.837782Z",
     "iopub.status.busy": "2024-11-15T07:29:30.837557Z",
     "iopub.status.idle": "2024-11-15T07:29:30.843874Z",
     "shell.execute_reply": "2024-11-15T07:29:30.843449Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(np.int64(0), np.int64(0), np.int64(0)),\n",
       "  (np.int64(128), np.int64(64), np.int64(128)),\n",
       "  (np.int64(130), np.int64(76), np.int64(0)),\n",
       "  (np.int64(0), np.int64(102), np.int64(0)),\n",
       "  (np.int64(112), np.int64(103), np.int64(87))],\n",
       " ['unlabeled', 'paved-area', 'dirt', 'grass', 'gravel'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_names= list(class_dict_df.name)\n",
    "label_codes = []\n",
    "r= np.asarray(class_dict_df.r)\n",
    "g= np.asarray(class_dict_df.g)\n",
    "b= np.asarray(class_dict_df.b)\n",
    "\n",
    "for i in range(len(class_dict_df)):\n",
    "    label_codes.append(tuple([r[i], g[i], b[i]]))\n",
    "    \n",
    "label_codes[:5], label_names[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9dec177c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T07:29:30.845520Z",
     "iopub.status.busy": "2024-11-15T07:29:30.845257Z",
     "iopub.status.idle": "2024-11-15T07:29:30.850480Z",
     "shell.execute_reply": "2024-11-15T07:29:30.850083Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(np.int64(0), np.int64(0), np.int64(0)),\n",
       "  (np.int64(128), np.int64(64), np.int64(128)),\n",
       "  (np.int64(130), np.int64(76), np.int64(0)),\n",
       "  (np.int64(0), np.int64(102), np.int64(0)),\n",
       "  (np.int64(112), np.int64(103), np.int64(87)),\n",
       "  (np.int64(28), np.int64(42), np.int64(168)),\n",
       "  (np.int64(48), np.int64(41), np.int64(30)),\n",
       "  (np.int64(0), np.int64(50), np.int64(89)),\n",
       "  (np.int64(107), np.int64(142), np.int64(35)),\n",
       "  (np.int64(70), np.int64(70), np.int64(70)),\n",
       "  (np.int64(102), np.int64(102), np.int64(156)),\n",
       "  (np.int64(254), np.int64(228), np.int64(12)),\n",
       "  (np.int64(254), np.int64(148), np.int64(12)),\n",
       "  (np.int64(190), np.int64(153), np.int64(153)),\n",
       "  (np.int64(153), np.int64(153), np.int64(153)),\n",
       "  (np.int64(255), np.int64(22), np.int64(96)),\n",
       "  (np.int64(102), np.int64(51), np.int64(0)),\n",
       "  (np.int64(9), np.int64(143), np.int64(150)),\n",
       "  (np.int64(119), np.int64(11), np.int64(32)),\n",
       "  (np.int64(51), np.int64(51), np.int64(0)),\n",
       "  (np.int64(190), np.int64(250), np.int64(190)),\n",
       "  (np.int64(112), np.int64(150), np.int64(146)),\n",
       "  (np.int64(2), np.int64(135), np.int64(115)),\n",
       "  (np.int64(255), np.int64(0), np.int64(0))],\n",
       " ['unlabeled',\n",
       "  'paved-area',\n",
       "  'dirt',\n",
       "  'grass',\n",
       "  'gravel',\n",
       "  'water',\n",
       "  'rocks',\n",
       "  'pool',\n",
       "  'vegetation',\n",
       "  'roof',\n",
       "  'wall',\n",
       "  'window',\n",
       "  'door',\n",
       "  'fence',\n",
       "  'fence-pole',\n",
       "  'person',\n",
       "  'dog',\n",
       "  'car',\n",
       "  'bicycle',\n",
       "  'tree',\n",
       "  'bald-tree',\n",
       "  'ar-marker',\n",
       "  'obstacle',\n",
       "  'conflicting'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_codes, label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "550fd76a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T07:29:30.852070Z",
     "iopub.status.busy": "2024-11-15T07:29:30.851822Z",
     "iopub.status.idle": "2024-11-15T07:29:30.855080Z",
     "shell.execute_reply": "2024-11-15T07:29:30.854677Z"
    }
   },
   "outputs": [],
   "source": [
    "code2id = {v:k for k,v in enumerate(label_codes)}\n",
    "id2code = {k:v for k,v in enumerate(label_codes)}\n",
    "\n",
    "name2id = {v:k for k,v in enumerate(label_names)}\n",
    "id2name = {k:v for k,v in enumerate(label_names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e692a82b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T07:29:30.856678Z",
     "iopub.status.busy": "2024-11-15T07:29:30.856434Z",
     "iopub.status.idle": "2024-11-15T07:29:30.861002Z",
     "shell.execute_reply": "2024-11-15T07:29:30.860600Z"
    }
   },
   "outputs": [],
   "source": [
    "def rgb_to_onehot(rgb_image, colormap = id2code):\n",
    "    '''Function to one hot encode RGB mask labels\n",
    "        Inputs: \n",
    "            rgb_image - image matrix (eg. 256 x 256 x 3 dimension numpy ndarray)\n",
    "            colormap - dictionary of color to label id\n",
    "        Output: One hot encoded image of dimensions (height x width x num_classes) where num_classes = len(colormap)\n",
    "    '''\n",
    "    num_classes = len(colormap)\n",
    "    shape = rgb_image.shape[:2]+(num_classes,)\n",
    "    encoded_image = np.zeros( shape, dtype=np.int8 )\n",
    "    for i, cls in enumerate(colormap):\n",
    "        encoded_image[:,:,i] = np.all(rgb_image.reshape( (-1,3) ) == colormap[i], axis=1).reshape(shape[:2])\n",
    "    return encoded_image\n",
    "\n",
    "\n",
    "def onehot_to_rgb(onehot, colormap = id2code):\n",
    "    '''Function to decode encoded mask labels\n",
    "        Inputs: \n",
    "            onehot - one hot encoded image matrix (height x width x num_classes)\n",
    "            colormap - dictionary of color to label id\n",
    "        Output: Decoded RGB image (height x width x 3) \n",
    "    '''\n",
    "    single_layer = np.argmax(onehot, axis=-1)\n",
    "    output = np.zeros( onehot.shape[:2]+(3,) )\n",
    "    for k in colormap.keys():\n",
    "        output[single_layer==k] = colormap[k]\n",
    "    return np.uint8(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2201c24f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T07:29:30.862554Z",
     "iopub.status.busy": "2024-11-15T07:29:30.862308Z",
     "iopub.status.idle": "2024-11-15T07:29:30.865146Z",
     "shell.execute_reply": "2024-11-15T07:29:30.864724Z"
    }
   },
   "outputs": [],
   "source": [
    "# Normalizing only frame images, since masks contain label info\n",
    "data_gen_args = dict(rescale=1./255)\n",
    "mask_gen_args = dict()\n",
    "\n",
    "train_frames_datagen = ImageDataGenerator(**data_gen_args)\n",
    "train_masks_datagen = ImageDataGenerator(**mask_gen_args)\n",
    "val_frames_datagen = ImageDataGenerator(**data_gen_args)\n",
    "val_masks_datagen = ImageDataGenerator(**mask_gen_args)\n",
    "# Seed defined for aligning images and their masks\n",
    "seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2e7a8657",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T07:29:30.866917Z",
     "iopub.status.busy": "2024-11-15T07:29:30.866656Z",
     "iopub.status.idle": "2024-11-15T07:29:30.873134Z",
     "shell.execute_reply": "2024-11-15T07:29:30.872715Z"
    }
   },
   "outputs": [],
   "source": [
    "def TrainAugmentGenerator(train_images_dir, train_masks_dir, seed = 1, batch_sizess = 8, target_sizess = (512, 512)):\n",
    "    '''Train Image data generator\n",
    "        Inputs: \n",
    "            seed - seed provided to the flow_from_directory function to ensure aligned data flow\n",
    "            batch_size - number of images to import at a time\n",
    "            train_images_dir - train images directory\n",
    "            train_masks_dir - train masks directory\n",
    "            target_size - tuple of integers (height, width)\n",
    "            \n",
    "        Output: Decoded RGB image (height x width x 3) \n",
    "    '''\n",
    "    train_image_generator = train_frames_datagen.flow_from_directory(\n",
    "   train_images_dir,\n",
    "    batch_size= batch_sizess, \n",
    "    seed = seed, \n",
    "    target_size = target_sizess)\n",
    "\n",
    "    train_mask_generator = train_masks_datagen.flow_from_directory(\n",
    "    train_masks_dir,\n",
    "    batch_size = batch_sizess, \n",
    "    seed = seed, \n",
    "    target_size = target_sizess)\n",
    "\n",
    "    while True:\n",
    "        X1i = next(train_image_generator)\n",
    "        X2i = next(train_mask_generator)\n",
    "        \n",
    "        #One hot encoding RGB images\n",
    "        mask_encoded = [rgb_to_onehot(X2i[0][x,:,:,:], id2code) for x in range(X2i[0].shape[0])]\n",
    "        if(X1i[0] is None or mask_encoded is None):\n",
    "            print(\"I am sending Null object to you\")\n",
    "        yield X1i[0], np.asarray(mask_encoded)\n",
    "\n",
    "def ValAugmentGenerator(val_images_dr, masksvaldr, seed = 1, batch_sizess = 8, target_sizess = (512, 512)):\n",
    "    '''Train Image data generator\n",
    "        Inputs: \n",
    "            seed - seed provided to the flow_from_directory function to ensure aligned data flow\n",
    "            batch_size - number of images to import at a time\n",
    "            train_images_dir - train images directory\n",
    "            train_masks_dir - train masks directory\n",
    "            target_size - tuple of integers (height, width)\n",
    "            \n",
    "        Output: Decoded RGB image (height x width x 3) \n",
    "    '''\n",
    "    val_image_generator = val_frames_datagen.flow_from_directory(\n",
    "   val_images_dr,\n",
    "    batch_size= batch_sizess, \n",
    "    seed = seed, \n",
    "    target_size = target_sizess)\n",
    "\n",
    "    val_mask_generator = val_masks_datagen.flow_from_directory(\n",
    "    masksvaldr,\n",
    "    batch_size = batch_sizess, \n",
    "    seed = seed, \n",
    "    target_size = target_sizess)\n",
    "\n",
    "    while True:\n",
    "        X1i = next(val_image_generator)\n",
    "        X2i = next(val_mask_generator)\n",
    "        \n",
    "        #One hot encoding RGB images\n",
    "        mask_encoded = [rgb_to_onehot(X2i[0][x,:,:,:], id2code) for x in range(X2i[0].shape[0])]\n",
    "        if(X1i[0] is None or mask_encoded is None):\n",
    "            print(\"I am sending Null object to you\")\n",
    "        yield X1i[0], np.asarray(mask_encoded)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "80e04025",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T07:29:30.874823Z",
     "iopub.status.busy": "2024-11-15T07:29:30.874572Z",
     "iopub.status.idle": "2024-11-15T07:29:30.877324Z",
     "shell.execute_reply": "2024-11-15T07:29:30.876907Z"
    }
   },
   "outputs": [],
   "source": [
    "# !mkdir pretrained_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f4effbf4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T07:29:30.878970Z",
     "iopub.status.busy": "2024-11-15T07:29:30.878725Z",
     "iopub.status.idle": "2024-11-15T07:29:30.882852Z",
     "shell.execute_reply": "2024-11-15T07:29:30.882247Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps_per_epoch:  1.0\n",
      "/home/pranav/DeepLearning/train_images\n",
      "/home/pranav/DeepLearning/train_masks\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "batch_size = 8\n",
    "num_train_samples = len(np.sort(os.listdir(train_images)))\n",
    "steps_per_epoch = np.ceil(float(num_train_samples) / float(batch_size))\n",
    "print('steps_per_epoch: ', steps_per_epoch)\n",
    "print(train_images)\n",
    "print(train_masks)\n",
    "with open(\"/home/pranav/DeepLearning/new.txt\",\"a\") as wr:\n",
    "    wr.write(\"The sixth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4b1bc7d8-54c6-41c1-8024-980e3325329a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T07:29:30.884497Z",
     "iopub.status.busy": "2024-11-15T07:29:30.884353Z",
     "iopub.status.idle": "2024-11-15T07:29:30.887791Z",
     "shell.execute_reply": "2024-11-15T07:29:30.887376Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/pranav/DeepLearning/train_images\n",
      "/home/pranav/DeepLearning/train_masks\n",
      "hh\n",
      "hhh\n"
     ]
    }
   ],
   "source": [
    "print(train_images)\n",
    "print(train_masks)\n",
    "os.environ['XLA_FLAGS'] = '--xla_gpu_strict_conv_algorithm_picker=false'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2,3,4,5,6,7\"\n",
    "print(\"hh\")\n",
    "print(\"hhh\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a10b8670-a352-4db7-8844-cdc15416f40f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T07:29:30.889400Z",
     "iopub.status.busy": "2024-11-15T07:29:30.889147Z",
     "iopub.status.idle": "2024-11-15T07:29:30.891876Z",
     "shell.execute_reply": "2024-11-15T07:29:30.891465Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5d57208",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T07:29:30.893839Z",
     "iopub.status.busy": "2024-11-15T07:29:30.893473Z",
     "iopub.status.idle": "2024-11-15T07:29:30.913055Z",
     "shell.execute_reply": "2024-11-15T07:29:30.912602Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPooling2D\n",
    "from tensorflow.keras.layers import Conv2DTranspose, concatenate, DepthwiseConv2D, Add\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# def dice_score(y_true, y_pred, smooth=1e-6):\n",
    "#     # Convert y_pred from probabilities to class predictions\n",
    "#      tf.print(y_true_f.shape)\n",
    "#     tf.print(y_pred_f.shape)\n",
    "#     y_pred_classes = tf.argmax(y_pred, axis=-1)\n",
    "\n",
    "#     # Convert y_true to the same type and shape as y_pred_classes\n",
    "#     y_true = tf.cast(y_true, tf.int64)\n",
    "#     print(y_true)\n",
    "#     print(y_pred_classes)\n",
    "#     # Ensure both y_true and y_pred_classes have the same shape (flatten them)\n",
    "#     y_true_f = tf.reshape(y_true, [-1])\n",
    "#     y_pred_f = tf.reshape(y_pred_classes, [-1])\n",
    "\n",
    "#     # Calculate the Dice score\n",
    "#     intersection = tf.reduce_sum(tf.cast(y_true_f == y_pred_f, tf.float32))\n",
    "#     dice = (2. * intersection + smooth) / (tf.reduce_sum(tf.cast(y_true_f != -1, tf.float32)) + \n",
    "#                                             tf.reduce_sum(tf.cast(y_pred_f != -1, tf.float32)) + smooth)\n",
    "#     print(y_true_f.shape)\n",
    "#     print(y_pred_f.shape)\n",
    "#     return dice\n",
    "# def simplemetric(y_true, y_pred):\n",
    "#     return tf.constant(0.5)  \n",
    "def dice_coef(y_true, y_pred):\n",
    "    return (2. * K.sum(y_true * y_pred) + 1.) / (K.sum(y_true) + K.sum(y_pred) + 1.)\n",
    "\n",
    "# class SimpleMetric(tf.keras.metrics.Metric):\n",
    "#     def __init__(self, name='simple_constant_metric', **kwargs):\n",
    "#         super(SimpleConstantMetric, self).__init__(name=name, **kwargs)\n",
    "#         self.value = self.add_weight(name=\"value\", initializer=\"zeros\")\n",
    "\n",
    "#     def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "#         # Update state with the constant value (0.5)\n",
    "#         self.value.assign(0.5)\n",
    "\n",
    "#     def result(self):\n",
    "#         # Return the current value of the metric\n",
    "#         return self.value\n",
    "\n",
    "#     def reset_states(self):\n",
    "#         # Reset metric state\n",
    "#         self.value.assign(0.0)\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "class DiceCoefficient(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='dice_coefficient', smooth=1e-6, **kwargs):\n",
    "        super(DiceCoefficient, self).__init__(name=name, **kwargs)\n",
    "        self.smooth = smooth\n",
    "        self.intersection = self.add_weight(name='intersection', initializer='zeros')\n",
    "        self.union = self.add_weight(name='union', initializer='zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        # Flatten the tensors to calculate the Dice coefficient\n",
    "        y_true_f = tf.cast(tf.reshape(y_true, [-1]), tf.float32)\n",
    "        y_pred_f = tf.cast(tf.reshape(y_pred, [-1]), tf.float32)\n",
    "        \n",
    "        # Calculate the intersection (true positives)\n",
    "        intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
    "        \n",
    "        # Calculate the union (sum of both sets)\n",
    "        union = tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f)\n",
    "        \n",
    "        # Update the total intersection and union state\n",
    "        self.intersection.assign_add(intersection)\n",
    "        self.union.assign_add(union)\n",
    "\n",
    "    def result(self):\n",
    "        # Return the Dice coefficient\n",
    "        dice = (2. * self.intersection + self.smooth) / (self.union + self.smooth)\n",
    "        return dice  # This will return a 'tf.Tensor' (EagerTensor in eager mode)\n",
    "\n",
    "    def reset_states(self):\n",
    "        # Reset the intersection and union for the next epoch\n",
    "        self.intersection.assign(0.0)\n",
    "        self.union.assign(0.0)\n",
    "    def get_config(self):  # Renamed from `get_config()` to `get_dice_config()`\n",
    "        dt = super(DiceCoefficient, self).get_config()\n",
    "        dt.update({\n",
    "            \"smooth\": self.smooth,\n",
    "        })\n",
    "        return dt   \n",
    "class TimeHistory(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, file_path=\"epoch_times.txt\"):\n",
    "        super(TimeHistory, self).__init__()\n",
    "        self.file_path = file_path  # Custom file path for saving the times\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.epoch_times = []  # Initialize a list to store times for each epoch\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.start_time = time.time()  # Record the start time of the epoch\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        epoch_duration = time.time() - self.start_time  # Calculate the duration of the epoch\n",
    "        self.epoch_times.append(epoch_duration)  # Append to the list\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        # Ensure the directory exists\n",
    "        os.makedirs(os.path.dirname(self.file_path), exist_ok=True)\n",
    "        \n",
    "        # Store the epoch times list in the specified file path\n",
    "        with open(self.file_path, \"w\") as file:\n",
    "            file.write(str(self.epoch_times))\n",
    "        print(f\"Epoch times saved to '{self.file_path}'.\")        \n",
    "def conv_block(inputs, filters, alpha=1.0, kernel=(3, 3), strides=(1, 1)):\n",
    "    \"\"\"Basic conv block for MobileNet\"\"\"\n",
    "    filters = int(filters * alpha)\n",
    "    x = Conv2D(filters, kernel, padding='same', use_bias=False, strides=strides)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    return Activation('relu')(x)\n",
    "def mobilenetv2_block(x, filters, strides=1, expansion=6):\n",
    "    \"\"\"MobileNetV2 block with depthwise separable convolution.\"\"\"\n",
    "    input_channels = x.shape[-1]\n",
    "    expanded_channels = input_channels * expansion\n",
    "    \n",
    "    # Expansion\n",
    "    if expansion > 1:\n",
    "        x = Conv2D(expanded_channels, (1, 1), padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "    \n",
    "    # Depthwise convolution\n",
    "    x = DepthwiseConv2D((3, 3), strides=strides, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # Projection\n",
    "    x = Conv2D(filters, (1, 1), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    # Residual connection\n",
    "    if strides == 1 and input_channels == filters:\n",
    "        x = Add()([x, x])\n",
    "\n",
    "    return x\n",
    "def depthwise_separable_conv(x, filters, kernel_size=(3, 3), padding='same', strides=(1, 1)):\n",
    "    x = DepthwiseConv2D(kernel_size, padding=padding, strides=strides, use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv2D(filters, (1, 1), padding='same', use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    return x\n",
    "def MobileNetUNet(input_shape=(512, 512, 3), num_classes=24, alpha=1.0, lr_init=0.001):\n",
    "    img_input = Input(input_shape)\n",
    "\n",
    "    x = depthwise_separable_conv(img_input, 32)\n",
    "    block_1_out = depthwise_separable_conv(x, 32)\n",
    "    x = MaxPooling2D()(block_1_out)\n",
    "\n",
    "    # Block 2\n",
    "    x = depthwise_separable_conv(x, 64)\n",
    "    block_2_out = depthwise_separable_conv(x, 64)\n",
    "    x = MaxPooling2D()(block_2_out)\n",
    "\n",
    "    # Block 3\n",
    "    x = depthwise_separable_conv(x, 128)\n",
    "    block_3_out = depthwise_separable_conv(x, 128)\n",
    "    x = MaxPooling2D()(block_3_out)\n",
    "\n",
    "    # Block 4\n",
    "    x = depthwise_separable_conv(x, 256)\n",
    "    block_4_out = depthwise_separable_conv(x, 256)\n",
    "    x = MaxPooling2D()(block_4_out)\n",
    "\n",
    "    # Block 5\n",
    "    x = depthwise_separable_conv(x, 512)\n",
    "    x = depthwise_separable_conv(x, 512)\n",
    "    \n",
    "    for_pretrained_weight = MaxPooling2D()(x)\n",
    "\n",
    "\n",
    "    # UP 1\n",
    "    x = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(x)\n",
    "    x = concatenate([x, block_4_out])\n",
    "    x = depthwise_separable_conv(x, 256)\n",
    "\n",
    "    # UP 2\n",
    "    x = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(x)\n",
    "    x = concatenate([x, block_3_out])\n",
    "    x = depthwise_separable_conv(x, 128)\n",
    "\n",
    "    # UP 3\n",
    "    x = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(x)\n",
    "    x = concatenate([x, block_2_out])\n",
    "    x = depthwise_separable_conv(x, 64)\n",
    "\n",
    "    # UP 4\n",
    "    x = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(x)\n",
    "    x = concatenate([x, block_1_out])\n",
    "    x = depthwise_separable_conv(x, 32)\n",
    "\n",
    "    # last conv\n",
    "    x = Conv2D(num_classes, (3, 3), activation='softmax', padding='same')(x)\n",
    "\n",
    "    model = Model(img_input, x)\n",
    "    model.compile(Adam(learning_rate=lr_init),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=[DiceCoefficient()])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bf6e407",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T07:29:30.914858Z",
     "iopub.status.busy": "2024-11-15T07:29:30.914601Z",
     "iopub.status.idle": "2024-11-15T07:29:36.400121Z",
     "shell.execute_reply": "2024-11-15T07:29:36.399530Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)                  </span><span style=\"font-weight: bold\"> Output Shape              </span><span style=\"font-weight: bold\">         Param # </span><span style=\"font-weight: bold\"> Connected to               </span>\n",
       "\n",
       " input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                          \n",
       "\n",
       " depthwise_conv2d               (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>  input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)                                                                                     \n",
       "\n",
       " batch_normalization            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>  depthwise_conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                                  \n",
       "\n",
       " activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
       "\n",
       " conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>  activation[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           \n",
       "\n",
       " batch_normalization_1          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>  conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                                  \n",
       "\n",
       " activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
       "\n",
       " depthwise_conv2d_1             (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>  activation_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)                                                                                     \n",
       "\n",
       " batch_normalization_2          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>  depthwise_conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                                  \n",
       "\n",
       " activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
       "\n",
       " conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span>  activation_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         \n",
       "\n",
       " batch_normalization_3          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>  conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                                  \n",
       "\n",
       " activation_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
       "\n",
       " max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  activation_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         \n",
       "\n",
       " depthwise_conv2d_2             (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>  max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)                                                                                     \n",
       "\n",
       " batch_normalization_4          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>  depthwise_conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                                  \n",
       "\n",
       " activation_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
       "\n",
       " conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span>  activation_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         \n",
       "\n",
       " batch_normalization_5          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>  conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                                  \n",
       "\n",
       " activation_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
       "\n",
       " depthwise_conv2d_3             (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>  activation_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)                                                                                     \n",
       "\n",
       " batch_normalization_6          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>  depthwise_conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                                  \n",
       "\n",
       " activation_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
       "\n",
       " conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span>  activation_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         \n",
       "\n",
       " batch_normalization_7          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>  conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                                  \n",
       "\n",
       " activation_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
       "\n",
       " max_pooling2d_1                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  activation_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)                                                                                        \n",
       "\n",
       " depthwise_conv2d_4             (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>  max_pooling2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)                                                                                     \n",
       "\n",
       " batch_normalization_8          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>  depthwise_conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                                  \n",
       "\n",
       " activation_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
       "\n",
       " conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span>  activation_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         \n",
       "\n",
       " batch_normalization_9          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>  conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                                  \n",
       "\n",
       " activation_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
       "\n",
       " depthwise_conv2d_5             (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">1,152</span>  activation_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)                                                                                     \n",
       "\n",
       " batch_normalization_10         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>  depthwise_conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                                  \n",
       "\n",
       " activation_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "\n",
       " conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">16,384</span>  activation_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        \n",
       "\n",
       " batch_normalization_11         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>  conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                                  \n",
       "\n",
       " activation_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "\n",
       " max_pooling2d_2                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  activation_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)                                                                                        \n",
       "\n",
       " depthwise_conv2d_6             (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,152</span>  max_pooling2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)                                                                                     \n",
       "\n",
       " batch_normalization_12         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>  depthwise_conv2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                                  \n",
       "\n",
       " activation_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "\n",
       " conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">32,768</span>  activation_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        \n",
       "\n",
       " batch_normalization_13         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span>  conv2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                                  \n",
       "\n",
       " activation_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "\n",
       " depthwise_conv2d_7             (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,304</span>  activation_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)                                                                                     \n",
       "\n",
       " batch_normalization_14         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span>  depthwise_conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                                  \n",
       "\n",
       " activation_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "\n",
       " conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">65,536</span>  activation_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        \n",
       "\n",
       " batch_normalization_15         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span>  conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                                  \n",
       "\n",
       " activation_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "\n",
       " max_pooling2d_3                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  activation_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)                                                                                        \n",
       "\n",
       " depthwise_conv2d_8             (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,304</span>  max_pooling2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)                                                                                     \n",
       "\n",
       " batch_normalization_16         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span>  depthwise_conv2d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                                  \n",
       "\n",
       " activation_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "\n",
       " conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">131,072</span>  activation_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        \n",
       "\n",
       " batch_normalization_17         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span>  conv2d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                                  \n",
       "\n",
       " activation_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "\n",
       " depthwise_conv2d_9             (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">4,608</span>  activation_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)                                                                                     \n",
       "\n",
       " batch_normalization_18         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span>  depthwise_conv2d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                                  \n",
       "\n",
       " activation_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "\n",
       " conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">262,144</span>  activation_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        \n",
       "\n",
       " batch_normalization_19         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span>  conv2d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                                  \n",
       "\n",
       " activation_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "\n",
       " conv2d_transpose               (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">524,544</span>  activation_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)                                                                                     \n",
       "\n",
       " concatenate (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  conv2d_transpose[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    \n",
       "                                                                            activation_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        \n",
       "\n",
       " depthwise_conv2d_10            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">4,608</span>  concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)                                                                                     \n",
       "\n",
       " batch_normalization_20         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span>  depthwise_conv2d_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                                  \n",
       "\n",
       " activation_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "\n",
       " conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">131,072</span>  activation_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        \n",
       "\n",
       " batch_normalization_21         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span>  conv2d_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                                  \n",
       "\n",
       " activation_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "\n",
       " conv2d_transpose_1             (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              <span style=\"color: #00af00; text-decoration-color: #00af00\">131,200</span>  activation_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)                                                                                     \n",
       "\n",
       " concatenate_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  conv2d_transpose_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  \n",
       "                                                                            activation_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        \n",
       "\n",
       " depthwise_conv2d_11            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">2,304</span>  concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)                                                                                     \n",
       "\n",
       " batch_normalization_22         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span>  depthwise_conv2d_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                                  \n",
       "\n",
       " activation_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "\n",
       " conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">32,768</span>  activation_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        \n",
       "\n",
       " batch_normalization_23         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>  conv2d_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                                  \n",
       "\n",
       " activation_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "\n",
       " conv2d_transpose_2             (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">32,832</span>  activation_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)                                                                                     \n",
       "\n",
       " concatenate_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  conv2d_transpose_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  \n",
       "                                                                            activation_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         \n",
       "\n",
       " depthwise_conv2d_12            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">1,152</span>  concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)                                                                                     \n",
       "\n",
       " batch_normalization_24         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>  depthwise_conv2d_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                                  \n",
       "\n",
       " activation_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "\n",
       " conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span>  activation_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        \n",
       "\n",
       " batch_normalization_25         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>  conv2d_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                                  \n",
       "\n",
       " activation_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "\n",
       " conv2d_transpose_3             (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">8,224</span>  activation_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)                                                                                     \n",
       "\n",
       " concatenate_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  conv2d_transpose_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  \n",
       "                                                                            activation_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         \n",
       "\n",
       " depthwise_conv2d_13            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>  concatenate_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)                                                                                     \n",
       "\n",
       " batch_normalization_26         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>  depthwise_conv2d_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                                  \n",
       "\n",
       " activation_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "\n",
       " conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span>  activation_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        \n",
       "\n",
       " batch_normalization_27         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>  conv2d_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                                                  \n",
       "\n",
       " activation_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  batch_normalization_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "\n",
       " conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">6,936</span>  activation_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " input_layer (\u001b[38;5;33mInputLayer\u001b[0m)       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m3\u001b[0m)                      \u001b[38;5;34m0\u001b[0m  -                          \n",
       "\n",
       " depthwise_conv2d               (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m3\u001b[0m)                     \u001b[38;5;34m27\u001b[0m  input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
       " (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)                                                                                     \n",
       "\n",
       " batch_normalization            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m3\u001b[0m)                     \u001b[38;5;34m12\u001b[0m  depthwise_conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " activation (\u001b[38;5;33mActivation\u001b[0m)        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m3\u001b[0m)                      \u001b[38;5;34m0\u001b[0m  batch_normalization[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
       "\n",
       " conv2d (\u001b[38;5;33mConv2D\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m32\u001b[0m)                    \u001b[38;5;34m96\u001b[0m  activation[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           \n",
       "\n",
       " batch_normalization_1          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m32\u001b[0m)                   \u001b[38;5;34m128\u001b[0m  conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " activation_1 (\u001b[38;5;33mActivation\u001b[0m)      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m32\u001b[0m)                     \u001b[38;5;34m0\u001b[0m  batch_normalization_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m\u001b[0m \n",
       "\n",
       " depthwise_conv2d_1             (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m32\u001b[0m)                   \u001b[38;5;34m288\u001b[0m  activation_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         \n",
       " (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)                                                                                     \n",
       "\n",
       " batch_normalization_2          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m32\u001b[0m)                   \u001b[38;5;34m128\u001b[0m  depthwise_conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " activation_2 (\u001b[38;5;33mActivation\u001b[0m)      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m32\u001b[0m)                     \u001b[38;5;34m0\u001b[0m  batch_normalization_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m\u001b[0m \n",
       "\n",
       " conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m32\u001b[0m)                 \u001b[38;5;34m1,024\u001b[0m  activation_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         \n",
       "\n",
       " batch_normalization_3          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m32\u001b[0m)                   \u001b[38;5;34m128\u001b[0m  conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " activation_3 (\u001b[38;5;33mActivation\u001b[0m)      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m32\u001b[0m)                     \u001b[38;5;34m0\u001b[0m  batch_normalization_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m\u001b[0m \n",
       "\n",
       " max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m32\u001b[0m)                     \u001b[38;5;34m0\u001b[0m  activation_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         \n",
       "\n",
       " depthwise_conv2d_2             (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m32\u001b[0m)                   \u001b[38;5;34m288\u001b[0m  max_pooling2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        \n",
       " (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)                                                                                     \n",
       "\n",
       " batch_normalization_4          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m32\u001b[0m)                   \u001b[38;5;34m128\u001b[0m  depthwise_conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " activation_4 (\u001b[38;5;33mActivation\u001b[0m)      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m32\u001b[0m)                     \u001b[38;5;34m0\u001b[0m  batch_normalization_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m\u001b[0m \n",
       "\n",
       " conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)                 \u001b[38;5;34m2,048\u001b[0m  activation_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         \n",
       "\n",
       " batch_normalization_5          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)                   \u001b[38;5;34m256\u001b[0m  conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " activation_5 (\u001b[38;5;33mActivation\u001b[0m)      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)                     \u001b[38;5;34m0\u001b[0m  batch_normalization_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m\u001b[0m \n",
       "\n",
       " depthwise_conv2d_3             (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)                   \u001b[38;5;34m576\u001b[0m  activation_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         \n",
       " (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)                                                                                     \n",
       "\n",
       " batch_normalization_6          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)                   \u001b[38;5;34m256\u001b[0m  depthwise_conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " activation_6 (\u001b[38;5;33mActivation\u001b[0m)      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)                     \u001b[38;5;34m0\u001b[0m  batch_normalization_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m\u001b[0m \n",
       "\n",
       " conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)                 \u001b[38;5;34m4,096\u001b[0m  activation_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         \n",
       "\n",
       " batch_normalization_7          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)                   \u001b[38;5;34m256\u001b[0m  conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " activation_7 (\u001b[38;5;33mActivation\u001b[0m)      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)                     \u001b[38;5;34m0\u001b[0m  batch_normalization_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m\u001b[0m \n",
       "\n",
       " max_pooling2d_1                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)                     \u001b[38;5;34m0\u001b[0m  activation_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         \n",
       " (\u001b[38;5;33mMaxPooling2D\u001b[0m)                                                                                        \n",
       "\n",
       " depthwise_conv2d_4             (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)                   \u001b[38;5;34m576\u001b[0m  max_pooling2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n",
       " (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)                                                                                     \n",
       "\n",
       " batch_normalization_8          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)                   \u001b[38;5;34m256\u001b[0m  depthwise_conv2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " activation_8 (\u001b[38;5;33mActivation\u001b[0m)      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)                     \u001b[38;5;34m0\u001b[0m  batch_normalization_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m\u001b[0m \n",
       "\n",
       " conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)                \u001b[38;5;34m8,192\u001b[0m  activation_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         \n",
       "\n",
       " batch_normalization_9          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)                  \u001b[38;5;34m512\u001b[0m  conv2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " activation_9 (\u001b[38;5;33mActivation\u001b[0m)      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)                    \u001b[38;5;34m0\u001b[0m  batch_normalization_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m\u001b[0m \n",
       "\n",
       " depthwise_conv2d_5             (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)                \u001b[38;5;34m1,152\u001b[0m  activation_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         \n",
       " (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)                                                                                     \n",
       "\n",
       " batch_normalization_10         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)                  \u001b[38;5;34m512\u001b[0m  depthwise_conv2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " activation_10 (\u001b[38;5;33mActivation\u001b[0m)     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)                    \u001b[38;5;34m0\u001b[0m  batch_normalization_10[\u001b[38;5;34m0\u001b[0m] \n",
       "\n",
       " conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)               \u001b[38;5;34m16,384\u001b[0m  activation_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        \n",
       "\n",
       " batch_normalization_11         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)                  \u001b[38;5;34m512\u001b[0m  conv2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " activation_11 (\u001b[38;5;33mActivation\u001b[0m)     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)                    \u001b[38;5;34m0\u001b[0m  batch_normalization_11[\u001b[38;5;34m0\u001b[0m] \n",
       "\n",
       " max_pooling2d_2                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)                      \u001b[38;5;34m0\u001b[0m  activation_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        \n",
       " (\u001b[38;5;33mMaxPooling2D\u001b[0m)                                                                                        \n",
       "\n",
       " depthwise_conv2d_6             (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)                  \u001b[38;5;34m1,152\u001b[0m  max_pooling2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n",
       " (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)                                                                                     \n",
       "\n",
       " batch_normalization_12         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)                    \u001b[38;5;34m512\u001b[0m  depthwise_conv2d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " activation_12 (\u001b[38;5;33mActivation\u001b[0m)     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)                      \u001b[38;5;34m0\u001b[0m  batch_normalization_12[\u001b[38;5;34m0\u001b[0m] \n",
       "\n",
       " conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 \u001b[38;5;34m32,768\u001b[0m  activation_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        \n",
       "\n",
       " batch_normalization_13         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)                  \u001b[38;5;34m1,024\u001b[0m  conv2d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " activation_13 (\u001b[38;5;33mActivation\u001b[0m)     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)                      \u001b[38;5;34m0\u001b[0m  batch_normalization_13[\u001b[38;5;34m0\u001b[0m] \n",
       "\n",
       " depthwise_conv2d_7             (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)                  \u001b[38;5;34m2,304\u001b[0m  activation_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        \n",
       " (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)                                                                                     \n",
       "\n",
       " batch_normalization_14         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)                  \u001b[38;5;34m1,024\u001b[0m  depthwise_conv2d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " activation_14 (\u001b[38;5;33mActivation\u001b[0m)     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)                      \u001b[38;5;34m0\u001b[0m  batch_normalization_14[\u001b[38;5;34m0\u001b[0m] \n",
       "\n",
       " conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 \u001b[38;5;34m65,536\u001b[0m  activation_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        \n",
       "\n",
       " batch_normalization_15         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)                  \u001b[38;5;34m1,024\u001b[0m  conv2d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " activation_15 (\u001b[38;5;33mActivation\u001b[0m)     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)                      \u001b[38;5;34m0\u001b[0m  batch_normalization_15[\u001b[38;5;34m0\u001b[0m] \n",
       "\n",
       " max_pooling2d_3                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)                      \u001b[38;5;34m0\u001b[0m  activation_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        \n",
       " (\u001b[38;5;33mMaxPooling2D\u001b[0m)                                                                                        \n",
       "\n",
       " depthwise_conv2d_8             (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)                  \u001b[38;5;34m2,304\u001b[0m  max_pooling2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n",
       " (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)                                                                                     \n",
       "\n",
       " batch_normalization_16         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)                  \u001b[38;5;34m1,024\u001b[0m  depthwise_conv2d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " activation_16 (\u001b[38;5;33mActivation\u001b[0m)     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)                      \u001b[38;5;34m0\u001b[0m  batch_normalization_16[\u001b[38;5;34m0\u001b[0m] \n",
       "\n",
       " conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)                \u001b[38;5;34m131,072\u001b[0m  activation_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        \n",
       "\n",
       " batch_normalization_17         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)                  \u001b[38;5;34m2,048\u001b[0m  conv2d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " activation_17 (\u001b[38;5;33mActivation\u001b[0m)     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)                      \u001b[38;5;34m0\u001b[0m  batch_normalization_17[\u001b[38;5;34m0\u001b[0m] \n",
       "\n",
       " depthwise_conv2d_9             (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)                  \u001b[38;5;34m4,608\u001b[0m  activation_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        \n",
       " (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)                                                                                     \n",
       "\n",
       " batch_normalization_18         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)                  \u001b[38;5;34m2,048\u001b[0m  depthwise_conv2d_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " activation_18 (\u001b[38;5;33mActivation\u001b[0m)     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)                      \u001b[38;5;34m0\u001b[0m  batch_normalization_18[\u001b[38;5;34m0\u001b[0m] \n",
       "\n",
       " conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)                \u001b[38;5;34m262,144\u001b[0m  activation_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        \n",
       "\n",
       " batch_normalization_19         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)                  \u001b[38;5;34m2,048\u001b[0m  conv2d_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " activation_19 (\u001b[38;5;33mActivation\u001b[0m)     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)                      \u001b[38;5;34m0\u001b[0m  batch_normalization_19[\u001b[38;5;34m0\u001b[0m] \n",
       "\n",
       " conv2d_transpose               (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)                \u001b[38;5;34m524,544\u001b[0m  activation_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        \n",
       " (\u001b[38;5;33mConv2DTranspose\u001b[0m)                                                                                     \n",
       "\n",
       " concatenate (\u001b[38;5;33mConcatenate\u001b[0m)      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)                      \u001b[38;5;34m0\u001b[0m  conv2d_transpose[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    \n",
       "                                                                            activation_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        \n",
       "\n",
       " depthwise_conv2d_10            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)                  \u001b[38;5;34m4,608\u001b[0m  concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
       " (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)                                                                                     \n",
       "\n",
       " batch_normalization_20         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)                  \u001b[38;5;34m2,048\u001b[0m  depthwise_conv2d_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " activation_20 (\u001b[38;5;33mActivation\u001b[0m)     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)                      \u001b[38;5;34m0\u001b[0m  batch_normalization_20[\u001b[38;5;34m0\u001b[0m] \n",
       "\n",
       " conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)             (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)                \u001b[38;5;34m131,072\u001b[0m  activation_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        \n",
       "\n",
       " batch_normalization_21         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)                  \u001b[38;5;34m1,024\u001b[0m  conv2d_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " activation_21 (\u001b[38;5;33mActivation\u001b[0m)     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)                      \u001b[38;5;34m0\u001b[0m  batch_normalization_21[\u001b[38;5;34m0\u001b[0m] \n",
       "\n",
       " conv2d_transpose_1             (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)              \u001b[38;5;34m131,200\u001b[0m  activation_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        \n",
       " (\u001b[38;5;33mConv2DTranspose\u001b[0m)                                                                                     \n",
       "\n",
       " concatenate_1 (\u001b[38;5;33mConcatenate\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)                    \u001b[38;5;34m0\u001b[0m  conv2d_transpose_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  \n",
       "                                                                            activation_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        \n",
       "\n",
       " depthwise_conv2d_11            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)                \u001b[38;5;34m2,304\u001b[0m  concatenate_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        \n",
       " (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)                                                                                     \n",
       "\n",
       " batch_normalization_22         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)                \u001b[38;5;34m1,024\u001b[0m  depthwise_conv2d_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " activation_22 (\u001b[38;5;33mActivation\u001b[0m)     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)                    \u001b[38;5;34m0\u001b[0m  batch_normalization_22[\u001b[38;5;34m0\u001b[0m] \n",
       "\n",
       " conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)             (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)               \u001b[38;5;34m32,768\u001b[0m  activation_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        \n",
       "\n",
       " batch_normalization_23         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)                  \u001b[38;5;34m512\u001b[0m  conv2d_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " activation_23 (\u001b[38;5;33mActivation\u001b[0m)     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)                    \u001b[38;5;34m0\u001b[0m  batch_normalization_23[\u001b[38;5;34m0\u001b[0m] \n",
       "\n",
       " conv2d_transpose_2             (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)                \u001b[38;5;34m32,832\u001b[0m  activation_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        \n",
       " (\u001b[38;5;33mConv2DTranspose\u001b[0m)                                                                                     \n",
       "\n",
       " concatenate_2 (\u001b[38;5;33mConcatenate\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)                    \u001b[38;5;34m0\u001b[0m  conv2d_transpose_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  \n",
       "                                                                            activation_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         \n",
       "\n",
       " depthwise_conv2d_12            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)                \u001b[38;5;34m1,152\u001b[0m  concatenate_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        \n",
       " (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)                                                                                     \n",
       "\n",
       " batch_normalization_24         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)                  \u001b[38;5;34m512\u001b[0m  depthwise_conv2d_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " activation_24 (\u001b[38;5;33mActivation\u001b[0m)     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)                    \u001b[38;5;34m0\u001b[0m  batch_normalization_24[\u001b[38;5;34m0\u001b[0m] \n",
       "\n",
       " conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)             (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)                 \u001b[38;5;34m8,192\u001b[0m  activation_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        \n",
       "\n",
       " batch_normalization_25         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)                   \u001b[38;5;34m256\u001b[0m  conv2d_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " activation_25 (\u001b[38;5;33mActivation\u001b[0m)     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)                     \u001b[38;5;34m0\u001b[0m  batch_normalization_25[\u001b[38;5;34m0\u001b[0m] \n",
       "\n",
       " conv2d_transpose_3             (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m32\u001b[0m)                 \u001b[38;5;34m8,224\u001b[0m  activation_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        \n",
       " (\u001b[38;5;33mConv2DTranspose\u001b[0m)                                                                                     \n",
       "\n",
       " concatenate_3 (\u001b[38;5;33mConcatenate\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)                     \u001b[38;5;34m0\u001b[0m  conv2d_transpose_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  \n",
       "                                                                            activation_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         \n",
       "\n",
       " depthwise_conv2d_13            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)                   \u001b[38;5;34m576\u001b[0m  concatenate_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        \n",
       " (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)                                                                                     \n",
       "\n",
       " batch_normalization_26         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)                   \u001b[38;5;34m256\u001b[0m  depthwise_conv2d_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " activation_26 (\u001b[38;5;33mActivation\u001b[0m)     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)                     \u001b[38;5;34m0\u001b[0m  batch_normalization_26[\u001b[38;5;34m0\u001b[0m] \n",
       "\n",
       " conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)             (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m32\u001b[0m)                 \u001b[38;5;34m2,048\u001b[0m  activation_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        \n",
       "\n",
       " batch_normalization_27         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m32\u001b[0m)                   \u001b[38;5;34m128\u001b[0m  conv2d_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                                                  \n",
       "\n",
       " activation_27 (\u001b[38;5;33mActivation\u001b[0m)     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m32\u001b[0m)                     \u001b[38;5;34m0\u001b[0m  batch_normalization_27[\u001b[38;5;34m0\u001b[0m] \n",
       "\n",
       " conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)             (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m24\u001b[0m)                 \u001b[38;5;34m6,936\u001b[0m  activation_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,442,687</span> (5.50 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,442,687\u001b[0m (5.50 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,432,889</span> (5.47 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,432,889\u001b[0m (5.47 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,798</span> (38.27 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m9,798\u001b[0m (38.27 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vgg16_unet = MobileNetUNet(num_classes = 24, input_shape = (512, 512, 3), lr_init = 0.0001)\n",
    "#vgg16_unet.load_weights(\"vgg16_unet_model.keras\")\n",
    "#vgg16_unet=tf.keras.models.load_model(\"mobilenet22.keras\",custom_objects={'DiceCoefficient': DiceCoefficient})\n",
    "vgg16_unet.summary()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "54c25878",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T07:29:36.401884Z",
     "iopub.status.busy": "2024-11-15T07:29:36.401659Z",
     "iopub.status.idle": "2024-11-15T07:29:36.406623Z",
     "shell.execute_reply": "2024-11-15T07:29:36.406198Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 512, 512, 24)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg16_unet.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "75280939",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T07:29:36.408328Z",
     "iopub.status.busy": "2024-11-15T07:29:36.408069Z",
     "iopub.status.idle": "2024-11-15T07:29:36.410329Z",
     "shell.execute_reply": "2024-11-15T07:29:36.409901Z"
    }
   },
   "outputs": [],
   "source": [
    "# pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2b52be92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T07:29:36.411848Z",
     "iopub.status.busy": "2024-11-15T07:29:36.411707Z",
     "iopub.status.idle": "2024-11-15T07:29:36.414082Z",
     "shell.execute_reply": "2024-11-15T07:29:36.413671Z"
    }
   },
   "outputs": [],
   "source": [
    "# pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "18c01c1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T07:29:36.415649Z",
     "iopub.status.busy": "2024-11-15T07:29:36.415428Z",
     "iopub.status.idle": "2024-11-15T07:29:36.417697Z",
     "shell.execute_reply": "2024-11-15T07:29:36.417254Z"
    }
   },
   "outputs": [],
   "source": [
    "# from IPython.display import SVG\n",
    "# from tensorflow.keras.utils import model_to_dot\n",
    "\n",
    "# SVG(model_to_dot(vgg16_unet).create(prog='dot', format='svg'))\n",
    "# plot_model(vgg16_unet, to_file='vgg16_unet_plot.png', show_shapes=True, show_layer_names=True, expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f04ac0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "02be711c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T07:29:36.419434Z",
     "iopub.status.busy": "2024-11-15T07:29:36.419179Z",
     "iopub.status.idle": "2024-11-15T07:29:36.428172Z",
     "shell.execute_reply": "2024-11-15T07:29:36.427647Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "class DebugBatchCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__()  # Initialize the base Callback class\n",
    "    \n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        # Safely get the 'loss' and 'accuracy' with a default value\n",
    "        loss = logs.get('loss', 'N/A')\n",
    "        accuracy = logs.get('accuracy', 'N/A')\n",
    "        \n",
    "        # Check if loss and accuracy are floats before formatting\n",
    "        if isinstance(loss, float):\n",
    "            loss_str = f\"{loss:.4f}\"\n",
    "        else:\n",
    "            loss_str = str(loss)\n",
    "            print(\"h\")\n",
    "\n",
    "        if isinstance(accuracy, float):\n",
    "            accuracy_str = f\"{accuracy:.4f}\"\n",
    "        else:\n",
    "            accuracy_str = str(accuracy)\n",
    "        \n",
    "\n",
    "        # Print batch number, loss, and accuracy (if available)\n",
    "        print(f\"Batch {batch + 1} - Loss: {loss_str}, Accuracy: {accuracy_str}\")\n",
    "        \n",
    "        # Example of accessing the model (if needed)\n",
    "        first_layer_weights = self.model.layers[0].get_weights()\n",
    "        print(f\"    - First layer weights shape: {first_layer_weights[0].shape}\")\n",
    "db=DebugBatchCallback()        \n",
    "def exponential_decay(lr0, s):\n",
    "    def exponential_decay_fn(epoch):\n",
    "        return lr0 * 0.1 **(epoch / s)\n",
    "    return exponential_decay_fn\n",
    "\n",
    "exponential_decay_fn = exponential_decay(0.0001, 20)\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(\n",
    "    exponential_decay_fn,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath = 'vgg16_unet_model.keras',\n",
    "    save_best_only = True, \n",
    "#     save_weights_only = False,\n",
    "    monitor = 'loss', \n",
    "    mode = 'auto', \n",
    "    verbose = 1\n",
    ")\n",
    "\n",
    "earlystop = EarlyStopping(\n",
    "    monitor = 'loss', \n",
    "    min_delta = 0.001, \n",
    "    patience = 6, \n",
    "    mode = 'auto', \n",
    "    verbose = 1,\n",
    "    restore_best_weights = True\n",
    ")\n",
    "\n",
    "\n",
    "csvlogger = CSVLogger(\n",
    "    filename= \"model_training_csv.log\",\n",
    "    separator = \",\",\n",
    "    append = False\n",
    ")\n",
    "class timeshistory(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, file_path=\"epoch_times.txt\"):\n",
    "        super(timeshistory, self).__init__()\n",
    "        self.file_path = file_path  # Custom file path for saving the times\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.epoch_times = []  # Initialize a list to store times for each epoch\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.start_time = time.time()  # Record the start time of the epoch\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        epoch_duration = time.time() - self.start_time  # Calculate the duration of the epoch\n",
    "        self.epoch_times.append(epoch_duration)  # Append to the list\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        # Ensure the directory exists\n",
    "        os.makedirs(os.path.dirname(self.file_path), exist_ok=True)\n",
    "        \n",
    "        # Store the epoch times list in the specified file path\n",
    "        with open(self.file_path, \"w\") as file:\n",
    "            file.write(str(self.epoch_times))\n",
    "        print(f\"Epoch times saved to '{self.file_path}'.\")\n",
    "times_callback = timeshistory(file_path='/home/pranav/DeepLearning/mobilenet2times.txt')\n",
    "callbacks = [checkpoint, earlystop, csvlogger, lr_scheduler,times_callback]\n",
    "with open(\"/home/pranav/DeepLearning/new.txt\",\"a\") as wr:\n",
    "    wr.write(\"The eigth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "92839967",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T07:29:36.429872Z",
     "iopub.status.busy": "2024-11-15T07:29:36.429631Z",
     "iopub.status.idle": "2024-11-15T07:29:36.432520Z",
     "shell.execute_reply": "2024-11-15T07:29:36.432089Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/pranav/DeepLearning/train_images\n",
      "/home/pranav/DeepLearning/train_masks\n"
     ]
    }
   ],
   "source": [
    "print(train_images)\n",
    "print(train_masks)\n",
    "# print(val_images)\n",
    "# print(masksval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9c17400d-6d95-4611-ad46-c18dd8288e91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T07:29:36.434151Z",
     "iopub.status.busy": "2024-11-15T07:29:36.433899Z",
     "iopub.status.idle": "2024-11-15T07:29:36.436632Z",
     "shell.execute_reply": "2024-11-15T07:29:36.436200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hh\n"
     ]
    }
   ],
   "source": [
    "print(\"hh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "be6014e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T07:29:36.438324Z",
     "iopub.status.busy": "2024-11-15T07:29:36.438105Z",
     "iopub.status.idle": "2024-11-15T17:30:20.229573Z",
     "shell.execute_reply": "2024-11-15T17:30:20.228858Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1600 images belonging to 1 classes.\n",
      "Found 1600 images belonging to 1 classes.\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1731655798.306668  612619 service.cc:148] XLA service 0x7ffbb00711c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1731655798.306723  612619 service.cc:156]   StreamExecutor device (0): NVIDIA A100-SXM4-80GB, Compute Capability 8.0\n",
      "I0000 00:00:1731655798.306727  612619 service.cc:156]   StreamExecutor device (1): NVIDIA A100-SXM4-80GB, Compute Capability 8.0\n",
      "I0000 00:00:1731655798.306730  612619 service.cc:156]   StreamExecutor device (2): NVIDIA A100-SXM4-80GB, Compute Capability 8.0\n",
      "I0000 00:00:1731655798.306734  612619 service.cc:156]   StreamExecutor device (3): NVIDIA A100-SXM4-80GB, Compute Capability 8.0\n",
      "I0000 00:00:1731655798.306736  612619 service.cc:156]   StreamExecutor device (4): NVIDIA A100-SXM4-80GB, Compute Capability 8.0\n",
      "I0000 00:00:1731655798.306738  612619 service.cc:156]   StreamExecutor device (5): NVIDIA A100-SXM4-80GB, Compute Capability 8.0\n",
      "2024-11-15 12:59:58.763704: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1731655800.628037  612619 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2024-11-15 13:00:01.952202: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_4875', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "E0000 00:00:1731655813.887505  612619 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1731655814.058764  612619 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1731655814.230795  612619 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "Could not load symbol cuFuncGetName. Error: /lib/x86_64-linux-gnu/libcuda.so.1: undefined symbol: cuFuncGetName\n",
      "E0000 00:00:1731655817.948565  612619 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1731655818.362971  612619 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1731655820.759183  612619 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1731655821.060869  612619 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1731655821.987722  612619 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1731655822.151613  612619 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1731655824.236937  612619 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1731655824.423202  612619 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1731655824.978577  612619 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1731655825.156975  612619 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1731655825.329871  612619 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1731655825.512410  612619 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1731655825.691733  612619 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2024-11-15 13:00:25.782349: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng4{} for conv (f32[8,128,64,64]{3,2,1,0}, u8[0]{0}) custom-call(f32[8,128,64,64]{3,2,1,0}, f32[128,1,3,3]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, feature_group_count=128, custom_call_target=\"__cudnn$convForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "E0000 00:00:1731655825.861879  612619 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1731655826.042635  612619 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1731655826.217268  612619 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1731655826.388049  612619 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1731655826.569107  612619 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2024-11-15 13:00:26.602486: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.820240891s\n",
      "Trying algorithm eng4{} for conv (f32[8,128,64,64]{3,2,1,0}, u8[0]{0}) custom-call(f32[8,128,64,64]{3,2,1,0}, f32[128,1,3,3]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, feature_group_count=128, custom_call_target=\"__cudnn$convForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "E0000 00:00:1731655827.165132  612619 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1731655827.340377  612619 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1731655828.889416  612619 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1731655829.045594  612619 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1731655830.106340  612619 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1731655830.309445  612619 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1731655832.714035  612619 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1731655832.988841  612619 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1731655836.085284  612619 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1731655836.316457  612619 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1731655836.546823  612619 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1731655841.264026  612619 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1731655841.550548  612619 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2024-11-15 13:00:45.085126: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng46{k2=0,k5=2,k14=3} for conv (f32[8,64,512,512]{3,2,1,0}, u8[0]{0}) custom-call(f32[8,64,512,512]{3,2,1,0}, f32[64,1,3,3]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, feature_group_count=64, custom_call_target=\"__cudnn$convForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2024-11-15 13:00:45.567641: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.482627508s\n",
      "Trying algorithm eng46{k2=0,k5=2,k14=3} for conv (f32[8,64,512,512]{3,2,1,0}, u8[0]{0}) custom-call(f32[8,64,512,512]{3,2,1,0}, f32[64,1,3,3]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, feature_group_count=64, custom_call_target=\"__cudnn$convForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2024-11-15 13:00:47.318462: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng46{k2=5,k5=3,k14=4} for conv (f32[8,64,512,512]{3,2,1,0}, u8[0]{0}) custom-call(f32[8,64,512,512]{3,2,1,0}, f32[64,1,3,3]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, feature_group_count=64, custom_call_target=\"__cudnn$convForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2024-11-15 13:00:48.617260: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 2.298865132s\n",
      "Trying algorithm eng46{k2=5,k5=3,k14=4} for conv (f32[8,64,512,512]{3,2,1,0}, u8[0]{0}) custom-call(f32[8,64,512,512]{3,2,1,0}, f32[64,1,3,3]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, feature_group_count=64, custom_call_target=\"__cudnn$convForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2024-11-15 13:00:49.617491: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng46{k2=7,k5=3,k14=2} for conv (f32[8,64,512,512]{3,2,1,0}, u8[0]{0}) custom-call(f32[8,64,512,512]{3,2,1,0}, f32[64,1,3,3]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, feature_group_count=64, custom_call_target=\"__cudnn$convForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2024-11-15 13:00:50.946484: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 2.329078728s\n",
      "Trying algorithm eng46{k2=7,k5=3,k14=2} for conv (f32[8,64,512,512]{3,2,1,0}, u8[0]{0}) custom-call(f32[8,64,512,512]{3,2,1,0}, f32[64,1,3,3]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, feature_group_count=64, custom_call_target=\"__cudnn$convForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "E0000 00:00:1731655851.835346  612619 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2024-11-15 13:00:51.946687: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng4{} for conv (f32[8,64,512,512]{3,2,1,0}, u8[0]{0}) custom-call(f32[8,64,512,512]{3,2,1,0}, f32[64,1,3,3]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, feature_group_count=64, custom_call_target=\"__cudnn$convForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "E0000 00:00:1731655852.471811  612619 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1731655853.010093  612619 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1731655853.409954  612619 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1731655854.014175  612619 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1731655854.654828  612619 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1731655855.259599  612619 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1731655855.659140  612619 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2024-11-15 13:00:55.668948: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 4.722323496s\n",
      "Trying algorithm eng4{} for conv (f32[8,64,512,512]{3,2,1,0}, u8[0]{0}) custom-call(f32[8,64,512,512]{3,2,1,0}, f32[64,1,3,3]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, feature_group_count=64, custom_call_target=\"__cudnn$convForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2024-11-15 13:01:04.015397: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng23{k2=0,k13=2,k14=3,k18=1,k23=1} for conv (f32[32,3,1,1]{3,2,1,0}, u8[0]{0}) custom-call(f32[8,3,512,512]{3,2,1,0}, f32[8,32,512,512]{3,2,1,0}), window={size=1x1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2024-11-15 13:01:04.027108: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.011811881s\n",
      "Trying algorithm eng23{k2=0,k13=2,k14=3,k18=1,k23=1} for conv (f32[32,3,1,1]{3,2,1,0}, u8[0]{0}) custom-call(f32[8,3,512,512]{3,2,1,0}, f32[8,32,512,512]{3,2,1,0}), window={size=1x1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2024-11-15 13:01:07.399708: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng48{k0=2,k2=1,k5=2,k14=5} for conv (f32[32,1,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[8,32,512,512]{3,2,1,0}, f32[8,32,512,512]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, feature_group_count=32, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2024-11-15 13:01:07.442594: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.042975875s\n",
      "Trying algorithm eng48{k0=2,k2=1,k5=2,k14=5} for conv (f32[32,1,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[8,32,512,512]{3,2,1,0}, f32[8,32,512,512]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, feature_group_count=32, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2024-11-15 13:01:08.442767: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng48{k0=2,k2=3,k5=2,k14=2} for conv (f32[32,1,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[8,32,512,512]{3,2,1,0}, f32[8,32,512,512]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, feature_group_count=32, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2024-11-15 13:01:08.629602: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.186901851s\n",
      "Trying algorithm eng48{k0=2,k2=3,k5=2,k14=2} for conv (f32[32,1,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[8,32,512,512]{3,2,1,0}, f32[8,32,512,512]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, feature_group_count=32, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2024-11-15 13:01:10.675408: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng23{k2=6,k13=0,k14=2,k18=1,k23=0} for conv (f32[32,32,1,1]{3,2,1,0}, u8[0]{0}) custom-call(f32[8,32,512,512]{3,2,1,0}, f32[8,32,512,512]{3,2,1,0}), window={size=1x1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2024-11-15 13:01:11.875810: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 2.200465331s\n",
      "Trying algorithm eng23{k2=6,k13=0,k14=2,k18=1,k23=0} for conv (f32[32,32,1,1]{3,2,1,0}, u8[0]{0}) custom-call(f32[8,32,512,512]{3,2,1,0}, f32[8,32,512,512]{3,2,1,0}), window={size=1x1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2024-11-15 13:01:15.459189: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng48{k0=1,k2=3,k5=2,k14=2} for conv (f32[64,1,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[8,64,256,256]{3,2,1,0}, f32[8,64,256,256]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, feature_group_count=64, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2024-11-15 13:01:16.216682: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.757555409s\n",
      "Trying algorithm eng48{k0=1,k2=3,k5=2,k14=2} for conv (f32[64,1,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[8,64,256,256]{3,2,1,0}, f32[8,64,256,256]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, feature_group_count=64, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2024-11-15 13:01:23.002964: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng48{k0=1,k2=3,k5=2,k14=2} for conv (f32[256,1,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[8,256,64,64]{3,2,1,0}, f32[8,256,64,64]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, feature_group_count=256, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2024-11-15 13:01:23.245421: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.242524479s\n",
      "Trying algorithm eng48{k0=1,k2=3,k5=2,k14=2} for conv (f32[256,1,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[8,256,64,64]{3,2,1,0}, f32[8,256,64,64]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, feature_group_count=256, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2024-11-15 13:01:27.250846: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng48{k0=1,k2=1,k5=2,k14=5} for conv (f32[512,1,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[8,512,64,64]{3,2,1,0}, f32[8,512,64,64]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, feature_group_count=512, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2024-11-15 13:01:27.408442: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.157683732s\n",
      "Trying algorithm eng48{k0=1,k2=1,k5=2,k14=5} for conv (f32[512,1,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[8,512,64,64]{3,2,1,0}, f32[8,512,64,64]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, feature_group_count=512, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2024-11-15 13:01:32.139878: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng48{k0=1,k2=3,k5=2,k14=2} for conv (f32[256,1,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[8,256,128,128]{3,2,1,0}, f32[8,256,128,128]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, feature_group_count=256, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2024-11-15 13:01:32.468306: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.328526517s\n",
      "Trying algorithm eng48{k0=1,k2=3,k5=2,k14=2} for conv (f32[256,1,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[8,256,128,128]{3,2,1,0}, f32[8,256,128,128]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, feature_group_count=256, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2024-11-15 13:01:35.879196: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng48{k0=1,k2=1,k5=2,k14=5} for conv (f32[128,1,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[8,128,256,256]{3,2,1,0}, f32[8,128,256,256]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, feature_group_count=128, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2024-11-15 13:01:39.199363: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 4.3202535s\n",
      "Trying algorithm eng48{k0=1,k2=1,k5=2,k14=5} for conv (f32[128,1,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[8,128,256,256]{3,2,1,0}, f32[8,128,256,256]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, feature_group_count=128, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2024-11-15 13:01:40.199605: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng48{k0=1,k2=3,k5=2,k14=2} for conv (f32[128,1,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[8,128,256,256]{3,2,1,0}, f32[8,128,256,256]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, feature_group_count=128, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2024-11-15 13:01:44.173982: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 4.974473665s\n",
      "Trying algorithm eng48{k0=1,k2=3,k5=2,k14=2} for conv (f32[128,1,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[8,128,256,256]{3,2,1,0}, f32[8,128,256,256]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, feature_group_count=128, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2024-11-15 13:01:48.876662: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng50{k0=5,k2=7,k5=3,k14=2} for conv (f32[64,1,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[8,64,512,512]{3,2,1,0}, f32[8,64,512,512]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, feature_group_count=64, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2024-11-15 13:01:50.117143: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 2.240583004s\n",
      "Trying algorithm eng50{k0=5,k2=7,k5=3,k14=2} for conv (f32[64,1,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[8,64,512,512]{3,2,1,0}, f32[8,64,512,512]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, feature_group_count=64, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2024-11-15 13:01:51.117362: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng34{k0=5,k2=0,k5=2,k14=3} for conv (f32[64,1,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[8,64,512,512]{3,2,1,0}, f32[8,64,512,512]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, feature_group_count=64, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2024-11-15 13:01:52.378723: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 2.261442691s\n",
      "Trying algorithm eng34{k0=5,k2=0,k5=2,k14=3} for conv (f32[64,1,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[8,64,512,512]{3,2,1,0}, f32[8,64,512,512]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, feature_group_count=64, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2024-11-15 13:01:53.378952: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng20{k2=3,k3=0} for conv (f32[64,1,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[8,64,512,512]{3,2,1,0}, f32[8,64,512,512]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, feature_group_count=64, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2024-11-15 13:01:54.669763: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 2.290884427s\n",
      "Trying algorithm eng20{k2=3,k3=0} for conv (f32[64,1,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[8,64,512,512]{3,2,1,0}, f32[8,64,512,512]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, feature_group_count=64, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2024-11-15 13:01:55.669996: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng48{k0=1,k2=1,k5=2,k14=5} for conv (f32[64,1,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[8,64,512,512]{3,2,1,0}, f32[8,64,512,512]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, feature_group_count=64, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2024-11-15 13:02:03.104963: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 8.435036862s\n",
      "Trying algorithm eng48{k0=1,k2=1,k5=2,k14=5} for conv (f32[64,1,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[8,64,512,512]{3,2,1,0}, f32[8,64,512,512]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, feature_group_count=64, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2024-11-15 13:02:04.105243: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng48{k0=1,k2=3,k5=2,k14=2} for conv (f32[64,1,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[8,64,512,512]{3,2,1,0}, f32[8,64,512,512]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, feature_group_count=64, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2024-11-15 13:02:13.391141: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 10.2859813s\n",
      "Trying algorithm eng48{k0=1,k2=3,k5=2,k14=2} for conv (f32[64,1,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[8,64,512,512]{3,2,1,0}, f32[8,64,512,512]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, feature_group_count=64, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2024-11-15 13:02:18.056439: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng23{k2=6,k13=0,k14=2,k18=1,k23=0} for conv (f32[24,32,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[8,32,512,512]{3,2,1,0}, f32[8,24,512,512]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2024-11-15 13:02:19.392105: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 2.335747427s\n",
      "Trying algorithm eng23{k2=6,k13=0,k14=2,k18=1,k23=0} for conv (f32[24,32,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[8,32,512,512]{3,2,1,0}, f32[8,24,512,512]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  1/200\u001b[0m \u001b[37m\u001b[0m \u001b[1m9:14:28\u001b[0m 167s/step - dice_coefficient: 0.0425 - loss: 3.2074"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1731655952.494053  612619 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.0763 - loss: 2.8226\n",
      "Epoch 1: loss improved from inf to 2.49151, saving model to vgg16_unet_model.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1001s\u001b[0m 4s/step - dice_coefficient: 0.0766 - loss: 2.8210 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 8.912509381337456e-05.\n",
      "Epoch 2/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.2750 - loss: 1.8461\n",
      "Epoch 2: loss improved from 2.49151 to 1.76580, saving model to vgg16_unet_model.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m827s\u001b[0m 4s/step - dice_coefficient: 0.2752 - loss: 1.8457 - learning_rate: 8.9125e-05\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 7.943282347242815e-05.\n",
      "Epoch 3/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.3771 - loss: 1.6012\n",
      "Epoch 3: loss improved from 1.76580 to 1.57930, saving model to vgg16_unet_model.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m825s\u001b[0m 4s/step - dice_coefficient: 0.3772 - loss: 1.6011 - learning_rate: 7.9433e-05\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 7.07945784384138e-05.\n",
      "Epoch 4/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.4176 - loss: 1.4984\n",
      "Epoch 4: loss improved from 1.57930 to 1.50733, saving model to vgg16_unet_model.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m826s\u001b[0m 4s/step - dice_coefficient: 0.4176 - loss: 1.4985 - learning_rate: 7.0795e-05\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 6.309573444801933e-05.\n",
      "Epoch 5/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.4282 - loss: 1.4683\n",
      "Epoch 5: loss improved from 1.50733 to 1.44931, saving model to vgg16_unet_model.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m830s\u001b[0m 4s/step - dice_coefficient: 0.4283 - loss: 1.4682 - learning_rate: 6.3096e-05\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 5.623413251903491e-05.\n",
      "Epoch 6/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.4514 - loss: 1.4113\n",
      "Epoch 6: loss improved from 1.44931 to 1.39911, saving model to vgg16_unet_model.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m829s\u001b[0m 4s/step - dice_coefficient: 0.4515 - loss: 1.4112 - learning_rate: 5.6234e-05\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 5.011872336272724e-05.\n",
      "Epoch 7/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.4611 - loss: 1.3720\n",
      "Epoch 7: loss improved from 1.39911 to 1.36317, saving model to vgg16_unet_model.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m827s\u001b[0m 4s/step - dice_coefficient: 0.4612 - loss: 1.3720 - learning_rate: 5.0119e-05\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 4.4668359215096314e-05.\n",
      "Epoch 8/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.4745 - loss: 1.3357\n",
      "Epoch 8: loss improved from 1.36317 to 1.33759, saving model to vgg16_unet_model.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m827s\u001b[0m 4s/step - dice_coefficient: 0.4745 - loss: 1.3357 - learning_rate: 4.4668e-05\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 3.981071705534973e-05.\n",
      "Epoch 9/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.4809 - loss: 1.3187\n",
      "Epoch 9: loss improved from 1.33759 to 1.31043, saving model to vgg16_unet_model.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m828s\u001b[0m 4s/step - dice_coefficient: 0.4809 - loss: 1.3186 - learning_rate: 3.9811e-05\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 3.548133892335755e-05.\n",
      "Epoch 10/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.4836 - loss: 1.3125\n",
      "Epoch 10: loss improved from 1.31043 to 1.29328, saving model to vgg16_unet_model.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m828s\u001b[0m 4s/step - dice_coefficient: 0.4836 - loss: 1.3124 - learning_rate: 3.5481e-05\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 3.1622776601683795e-05.\n",
      "Epoch 11/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.4912 - loss: 1.2861\n",
      "Epoch 11: loss improved from 1.29328 to 1.28141, saving model to vgg16_unet_model.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m822s\u001b[0m 4s/step - dice_coefficient: 0.4912 - loss: 1.2861 - learning_rate: 3.1623e-05\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 2.818382931264454e-05.\n",
      "Epoch 12/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.4917 - loss: 1.2799\n",
      "Epoch 12: loss improved from 1.28141 to 1.26424, saving model to vgg16_unet_model.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m825s\u001b[0m 4s/step - dice_coefficient: 0.4917 - loss: 1.2799 - learning_rate: 2.8184e-05\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 2.51188643150958e-05.\n",
      "Epoch 13/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.5003 - loss: 1.2433\n",
      "Epoch 13: loss improved from 1.26424 to 1.24638, saving model to vgg16_unet_model.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m872s\u001b[0m 4s/step - dice_coefficient: 0.5003 - loss: 1.2433 - learning_rate: 2.5119e-05\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 2.2387211385683396e-05.\n",
      "Epoch 14/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.4966 - loss: 1.2699\n",
      "Epoch 14: loss improved from 1.24638 to 1.23377, saving model to vgg16_unet_model.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m838s\u001b[0m 4s/step - dice_coefficient: 0.4966 - loss: 1.2697 - learning_rate: 2.2387e-05\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 1.99526231496888e-05.\n",
      "Epoch 15/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.5177 - loss: 1.1958\n",
      "Epoch 15: loss improved from 1.23377 to 1.21857, saving model to vgg16_unet_model.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m831s\u001b[0m 4s/step - dice_coefficient: 0.5177 - loss: 1.1959 - learning_rate: 1.9953e-05\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 1.778279410038923e-05.\n",
      "Epoch 16/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.5030 - loss: 1.2480\n",
      "Epoch 16: loss did not improve from 1.21857\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m829s\u001b[0m 4s/step - dice_coefficient: 0.5030 - loss: 1.2479 - learning_rate: 1.7783e-05\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 1.5848931924611134e-05.\n",
      "Epoch 17/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.5132 - loss: 1.2184\n",
      "Epoch 17: loss improved from 1.21857 to 1.19227, saving model to vgg16_unet_model.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m837s\u001b[0m 4s/step - dice_coefficient: 0.5132 - loss: 1.2183 - learning_rate: 1.5849e-05\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 1.4125375446227545e-05.\n",
      "Epoch 18/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.5199 - loss: 1.1885\n",
      "Epoch 18: loss did not improve from 1.19227\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m833s\u001b[0m 4s/step - dice_coefficient: 0.5199 - loss: 1.1885 - learning_rate: 1.4125e-05\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 1.2589254117941673e-05.\n",
      "Epoch 19/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.5183 - loss: 1.2023\n",
      "Epoch 19: loss did not improve from 1.19227\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m834s\u001b[0m 4s/step - dice_coefficient: 0.5183 - loss: 1.2023 - learning_rate: 1.2589e-05\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 1.1220184543019637e-05.\n",
      "Epoch 20/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.5213 - loss: 1.1830\n",
      "Epoch 20: loss improved from 1.19227 to 1.18233, saving model to vgg16_unet_model.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m832s\u001b[0m 4s/step - dice_coefficient: 0.5213 - loss: 1.1830 - learning_rate: 1.1220e-05\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 1e-05.\n",
      "Epoch 21/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.5283 - loss: 1.1650\n",
      "Epoch 21: loss improved from 1.18233 to 1.17252, saving model to vgg16_unet_model.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m834s\u001b[0m 4s/step - dice_coefficient: 0.5283 - loss: 1.1651 - learning_rate: 1.0000e-05\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 8.912509381337456e-06.\n",
      "Epoch 22/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.5318 - loss: 1.1548\n",
      "Epoch 22: loss improved from 1.17252 to 1.16219, saving model to vgg16_unet_model.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m837s\u001b[0m 4s/step - dice_coefficient: 0.5318 - loss: 1.1549 - learning_rate: 8.9125e-06\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 7.943282347242815e-06.\n",
      "Epoch 23/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.5237 - loss: 1.1864\n",
      "Epoch 23: loss did not improve from 1.16219\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m839s\u001b[0m 4s/step - dice_coefficient: 0.5237 - loss: 1.1864 - learning_rate: 7.9433e-06\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 7.079457843841382e-06.\n",
      "Epoch 24/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.5259 - loss: 1.1814\n",
      "Epoch 24: loss did not improve from 1.16219\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m838s\u001b[0m 4s/step - dice_coefficient: 0.5259 - loss: 1.1813 - learning_rate: 7.0795e-06\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 6.309573444801933e-06.\n",
      "Epoch 25/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.5388 - loss: 1.1435\n",
      "Epoch 25: loss improved from 1.16219 to 1.16036, saving model to vgg16_unet_model.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m840s\u001b[0m 4s/step - dice_coefficient: 0.5388 - loss: 1.1436 - learning_rate: 6.3096e-06\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 5.623413251903491e-06.\n",
      "Epoch 26/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.5247 - loss: 1.1775\n",
      "Epoch 26: loss did not improve from 1.16036\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m840s\u001b[0m 4s/step - dice_coefficient: 0.5247 - loss: 1.1775 - learning_rate: 5.6234e-06\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 5.011872336272723e-06.\n",
      "Epoch 27/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.5337 - loss: 1.1445\n",
      "Epoch 27: loss improved from 1.16036 to 1.15855, saving model to vgg16_unet_model.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m839s\u001b[0m 4s/step - dice_coefficient: 0.5337 - loss: 1.1446 - learning_rate: 5.0119e-06\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 4.466835921509631e-06.\n",
      "Epoch 28/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.5352 - loss: 1.1424\n",
      "Epoch 28: loss improved from 1.15855 to 1.15558, saving model to vgg16_unet_model.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m837s\u001b[0m 4s/step - dice_coefficient: 0.5352 - loss: 1.1424 - learning_rate: 4.4668e-06\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 3.981071705534973e-06.\n",
      "Epoch 29/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.5284 - loss: 1.1698\n",
      "Epoch 29: loss improved from 1.15558 to 1.15181, saving model to vgg16_unet_model.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m836s\u001b[0m 4s/step - dice_coefficient: 0.5284 - loss: 1.1697 - learning_rate: 3.9811e-06\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 3.5481338923357555e-06.\n",
      "Epoch 30/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.5289 - loss: 1.1580\n",
      "Epoch 30: loss did not improve from 1.15181\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m835s\u001b[0m 4s/step - dice_coefficient: 0.5289 - loss: 1.1580 - learning_rate: 3.5481e-06\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 3.16227766016838e-06.\n",
      "Epoch 31/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.5369 - loss: 1.1310\n",
      "Epoch 31: loss improved from 1.15181 to 1.14391, saving model to vgg16_unet_model.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m837s\u001b[0m 4s/step - dice_coefficient: 0.5369 - loss: 1.1311 - learning_rate: 3.1623e-06\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 2.818382931264454e-06.\n",
      "Epoch 32/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.5273 - loss: 1.1685\n",
      "Epoch 32: loss improved from 1.14391 to 1.13430, saving model to vgg16_unet_model.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m837s\u001b[0m 4s/step - dice_coefficient: 0.5273 - loss: 1.1684 - learning_rate: 2.8184e-06\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 2.5118864315095797e-06.\n",
      "Epoch 33/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.5354 - loss: 1.1345\n",
      "Epoch 33: loss did not improve from 1.13430\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m835s\u001b[0m 4s/step - dice_coefficient: 0.5354 - loss: 1.1345 - learning_rate: 2.5119e-06\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 2.2387211385683405e-06.\n",
      "Epoch 34/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.5280 - loss: 1.1697\n",
      "Epoch 34: loss did not improve from 1.13430\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m835s\u001b[0m 4s/step - dice_coefficient: 0.5280 - loss: 1.1697 - learning_rate: 2.2387e-06\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 1.99526231496888e-06.\n",
      "Epoch 35/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.5396 - loss: 1.1326\n",
      "Epoch 35: loss did not improve from 1.13430\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m834s\u001b[0m 4s/step - dice_coefficient: 0.5396 - loss: 1.1327 - learning_rate: 1.9953e-06\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 1.7782794100389231e-06.\n",
      "Epoch 36/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.5322 - loss: 1.1551\n",
      "Epoch 36: loss did not improve from 1.13430\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m834s\u001b[0m 4s/step - dice_coefficient: 0.5322 - loss: 1.1551 - learning_rate: 1.7783e-06\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 1.5848931924611134e-06.\n",
      "Epoch 37/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.5411 - loss: 1.1224\n",
      "Epoch 37: loss improved from 1.13430 to 1.13259, saving model to vgg16_unet_model.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m832s\u001b[0m 4s/step - dice_coefficient: 0.5411 - loss: 1.1225 - learning_rate: 1.5849e-06\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 1.4125375446227544e-06.\n",
      "Epoch 38/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.5352 - loss: 1.1449\n",
      "Epoch 38: loss did not improve from 1.13259\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m832s\u001b[0m 4s/step - dice_coefficient: 0.5352 - loss: 1.1448 - learning_rate: 1.4125e-06\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 1.2589254117941678e-06.\n",
      "Epoch 39/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.5393 - loss: 1.1283\n",
      "Epoch 39: loss did not improve from 1.13259\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m837s\u001b[0m 4s/step - dice_coefficient: 0.5393 - loss: 1.1283 - learning_rate: 1.2589e-06\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 1.1220184543019637e-06.\n",
      "Epoch 40/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.5421 - loss: 1.1222\n",
      "Epoch 40: loss did not improve from 1.13259\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m836s\u001b[0m 4s/step - dice_coefficient: 0.5421 - loss: 1.1223 - learning_rate: 1.1220e-06\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 1.0000000000000002e-06.\n",
      "Epoch 41/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.5413 - loss: 1.1302\n",
      "Epoch 41: loss did not improve from 1.13259\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m835s\u001b[0m 4s/step - dice_coefficient: 0.5413 - loss: 1.1302 - learning_rate: 1.0000e-06\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 8.912509381337461e-07.\n",
      "Epoch 42/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.5365 - loss: 1.1417\n",
      "Epoch 42: loss did not improve from 1.13259\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m837s\u001b[0m 4s/step - dice_coefficient: 0.5365 - loss: 1.1418 - learning_rate: 8.9125e-07\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 7.943282347242815e-07.\n",
      "Epoch 43/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - dice_coefficient: 0.5446 - loss: 1.1123\n",
      "Epoch 43: loss did not improve from 1.13259\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m836s\u001b[0m 4s/step - dice_coefficient: 0.5446 - loss: 1.1124 - learning_rate: 7.9433e-07\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Epoch times saved to '/home/pranav/DeepLearning/mobilenet2times.txt'.\n"
     ]
    }
   ],
   "source": [
    "steps_per_epoch=200\n",
    "history = vgg16_unet.fit(\n",
    "    TrainAugmentGenerator(train_images_dir = train_images, train_masks_dir = train_masks,batch_sizess=8, target_sizess = (512, 512)), \n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs = 100,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "192bed48-6c98-466a-94c2-671b8c7c5952",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T17:30:20.232233Z",
     "iopub.status.busy": "2024-11-15T17:30:20.232012Z",
     "iopub.status.idle": "2024-11-15T17:30:20.617419Z",
     "shell.execute_reply": "2024-11-15T17:30:20.616866Z"
    }
   },
   "outputs": [],
   "source": [
    "vgg16_unet.save('/home/pranav/DeepLearning/100epochswithouttraining/mobilenetv22.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1b34d8e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T17:30:20.619631Z",
     "iopub.status.busy": "2024-11-15T17:30:20.619362Z",
     "iopub.status.idle": "2024-11-15T17:30:21.014721Z",
     "shell.execute_reply": "2024-11-15T17:30:21.014133Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'home/pranav/DeepLearning/100epochswithouttraining/TrainHistoryMobileNet22Dictionary'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhome/pranav/DeepLearning/100epochswithouttraining/TrainHistoryMobileNet22Dictionary\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file_pi:\n\u001b[1;32m      2\u001b[0m     pickle\u001b[38;5;241m.\u001b[39mdump(history\u001b[38;5;241m.\u001b[39mhistory, file_pi)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'home/pranav/DeepLearning/100epochswithouttraining/TrainHistoryMobileNet22Dictionary'"
     ]
    }
   ],
   "source": [
    "with open('home/pranav/DeepLearning/100epochswithouttraining/TrainHistoryMobileNet22Dictionary', 'wb') as file_pi:\n",
    "    pickle.dump(history.history, file_pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bca4c8",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(30, 5))\n",
    "ax = ax.ravel()\n",
    "metrics = ['Dice Coefficient', 'Loss', 'Learning Rate']\n",
    "\n",
    "for i, met in enumerate(['dice_coefficient','loss','learning_rate']): \n",
    "    if met != 'lr':\n",
    "        ax[i].plot(history.history[met], 'o-')\n",
    "        #ax[i].plot(history.history['val_' + met], 'o-')\n",
    "        ax[i].set_title('{} vs Epochs'.format(metrics[i]), fontsize=16)\n",
    "        ax[i].set_xlabel('Epochs')\n",
    "        ax[i].set_ylabel(metrics[i])\n",
    "        ax[i].set_xticks(np.arange(1,3,2))\n",
    "        ax[i].legend(['Train', 'Validation'])\n",
    "        ax[i].xaxis.grid(True, color = \"lightgray\", linewidth = \"0.8\", linestyle = \"-\")\n",
    "        ax[i].yaxis.grid(True, color = \"lightgray\", linewidth = \"0.8\", linestyle = \"-\")\n",
    "    else:\n",
    "        ax[i].plot(history.history[met], 'o-')\n",
    "        ax[i].set_title('{} vs Epochs'.format(metrics[i]), fontsize=16)\n",
    "        ax[i].set_xlabel('Epochs')\n",
    "        ax[i].set_ylabel(metrics[i])\n",
    "        ax[i].set_xticks(np.arange(1,3,2))\n",
    "        ax[i].xaxis.grid(True, color = \"lightgray\", linewidth = \"0.8\", linestyle = \"-\")\n",
    "        ax[i].yaxis.grid(True, color = \"lightgray\", linewidth = \"0.8\", linestyle = \"-\")\n",
    "        \n",
    "plt.savefig('model_metrics_plot.png', facecolor= 'w',transparent= False, bbox_inches= 'tight', dpi= 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ace43565",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T17:30:21.016632Z",
     "iopub.status.busy": "2024-11-15T17:30:21.016361Z",
     "iopub.status.idle": "2024-11-15T17:30:21.018798Z",
     "shell.execute_reply": "2024-11-15T17:30:21.018359Z"
    }
   },
   "outputs": [],
   "source": [
    "#vgg16_unet.load_weights(\"./vgg16_unet_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d0e41c85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T17:30:21.020955Z",
     "iopub.status.busy": "2024-11-15T17:30:21.020641Z",
     "iopub.status.idle": "2024-11-15T17:30:21.024517Z",
     "shell.execute_reply": "2024-11-15T17:30:21.023849Z"
    }
   },
   "outputs": [],
   "source": [
    "# testing_gen = ValAugmentGenerator(val_images_dr = val_images, masksvaldr = masksval, target_sizess = (512, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bbd8f1a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T17:30:21.027109Z",
     "iopub.status.busy": "2024-11-15T17:30:21.026800Z",
     "iopub.status.idle": "2024-11-15T17:30:21.029943Z",
     "shell.execute_reply": "2024-11-15T17:30:21.029505Z"
    }
   },
   "outputs": [],
   "source": [
    "# batch_img,batch_mask = ( \"C:/Users/prana/Deep Learning - Segmentation/val_train_images/another/aug_1_000.jpg\"  ,\"C:/Users/prana/Deep Learning - Segmentation/masksvalimages/another/aug_1_000.png\" )\n",
    "# image_path = \"C:/Users/prana/Deep Learning - Segmentation/val_train_images/another/aug_1_001.jpg\" \n",
    "# img = cv2.imread(image_path)\n",
    "\n",
    "# # Step 2: Resize and preprocess the image\n",
    "# input_shape = (512, 512)  # Example input size for your model\n",
    "# img_resized = cv2.resize(img, input_shape)\n",
    "# img_normalized = img_resized / 255.0  # Normalize to [0, 1]\n",
    "# img_batch = np.expand_dims(img_normalized, axis=0)  # Add batch dimension\n",
    "\n",
    "# image_path = \"C:/Users/prana/Deep Learning - Segmentation/masksvalimages/another/aug_1_001.png\"\n",
    "# img = cv2.imread(image_path)\n",
    "\n",
    "# # Step 2: Resize and preprocess the image\n",
    "# input_shape = (512, 512)  # Example input size for your model\n",
    "# img_resized = cv2.resize(img, input_shape)\n",
    "# img_normalized = img_resized / 255.0  # Normalize to [0, 1]\n",
    "# img_mask = np.expand_dims(img_normalized, axis=0)  # Add batch dimension\n",
    "\n",
    "# print(img_batch.shape)\n",
    "\n",
    "# pred_all= vgg16_unet.predict(img_batch)\n",
    "# np.shape(pred_all)\n",
    "    \n",
    "\n",
    "# fig = plt.figure(figsize=(20,8))\n",
    "\n",
    "# ax1 = fig.add_subplot(1,3,1)\n",
    "# ax1.imshow(np.squeeze(img_batch))\n",
    "# ax1.title.set_text('Original Image')\n",
    "# ax1.grid(False)\n",
    "\n",
    "# ax2 = fig.add_subplot(1,3,2)\n",
    "# ax2.set_title('Ground Truth Mask')\n",
    "# img_mask=np.squeeze(img_mask)\n",
    "# ax2.imshow(onehot_to_rgb(img_mask,id2code))\n",
    "# ax2.grid(False)\n",
    "\n",
    "# ax3 = fig.add_subplot(1,3,3)\n",
    "# ax3.set_title('Predicted Mask')\n",
    "# pred_all=np.squeeze(pred_all)           \n",
    "# ax3.imshow(onehot_to_rgb(pred_all,id2code))\n",
    "# ax3.grid(False)\n",
    "\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d2b3db75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T17:30:21.031473Z",
     "iopub.status.busy": "2024-11-15T17:30:21.031328Z",
     "iopub.status.idle": "2024-11-15T17:30:21.033841Z",
     "shell.execute_reply": "2024-11-15T17:30:21.033405Z"
    }
   },
   "outputs": [],
   "source": [
    "# !zip -r predictions.zip './predictions/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15031d1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
